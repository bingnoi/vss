nohup: ignoring input
/bin/sh: 1: /usr/lib/cuda/bin/nvcc: not found
2023-09-21 22:20:00,020 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/lib/cuda
NVCC: 
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.7.0
MMCV: 1.2.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: not available
MMSegmentation: 0.11.0+209b8f3
------------------------------------------------------------

2023-09-21 22:20:00,020 - mmseg - INFO - Distributed training: True
2023-09-21 22:20:00,156 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder_clips',
    pretrained='/home/lixinhao/mit_b2.pth',
    backbone=dict(type='mit_b2', style='pytorch'),
    decode_head=dict(
        type='SegFormerHead_ZeroShot',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=124,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(embed_dim=256),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        num_clips=4,
        hypercorre=True,
        backbone='b2'),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'VSPWDataset3'
data_root = '/home/lixinhao/vss/data/test/vspw/VSPW_480p'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (480, 480)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='Resize',
        img_scale=(853, 480),
        ratio_range=(0.5, 2.0),
        process_clips=True),
    dict(type='RandomCrop_clips', crop_size=(480, 480), cat_max_ratio=0.75),
    dict(type='RandomFlip_clips', prob=0.5),
    dict(type='PhotoMetricDistortion_clips'),
    dict(
        type='Normalize_clips',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad_clips', size=(480, 480), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle_clips'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(853, 480),
        flip=False,
        transforms=[
            dict(type='AlignedResize_clips', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip_clips'),
            dict(
                type='Normalize_clips',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor_clips', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='RepeatDataset',
        times=50,
        dataset=dict(
            type='VSPWDataset3',
            data_root='/home/lixinhao/vss/data/test/vspw/VSPW_480p',
            img_dir='images/training',
            ann_dir='annotations/training',
            split='train',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(853, 480),
                    ratio_range=(0.5, 2.0),
                    process_clips=True),
                dict(
                    type='RandomCrop_clips',
                    crop_size=(480, 480),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip_clips', prob=0.5),
                dict(type='PhotoMetricDistortion_clips'),
                dict(
                    type='Normalize_clips',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(
                    type='Pad_clips',
                    size=(480, 480),
                    pad_val=0,
                    seg_pad_val=255),
                dict(type='DefaultFormatBundle_clips'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ],
            dilation=[-9, -6, -3])),
    val=dict(
        type='VSPWDataset3',
        data_root='/home/lixinhao/vss/data/test/vspw/VSPW_480p',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        split='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(853, 480),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize_clips',
                        keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip_clips'),
                    dict(
                        type='Normalize_clips',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor_clips', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        dilation=[-9, -6, -3]),
    test=dict(
        type='VSPWDataset3',
        data_root='/home/lixinhao/vss/data/test/vspw/VSPW_480p',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        split='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(853, 480),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize_clips',
                        keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip_clips'),
                    dict(
                        type='Normalize_clips',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor_clips', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        dilation=[-9, -6, -3]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.0001,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=4000)
evaluation = dict(interval=160000, metric='mIoU')
work_dir = 'model_path/vspw2/work_dirs_4g_b4/'
gpu_ids = range(0, 1)

2023-09-21 22:20:11,165 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: head.weight, head.bias

2023-09-21 22:20:11,167 - mmseg - INFO - EncoderDecoder_clips(
  (backbone): mit_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): SegFormerHead_ZeroShot(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(128, 124, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (linear_c4): MLP(
      (proj): Linear(in_features=512, out_features=256, bias=True)
    )
    (linear_c3): MLP(
      (proj): Linear(in_features=320, out_features=256, bias=True)
    )
    (linear_c2): MLP(
      (proj): Linear(in_features=128, out_features=256, bias=True)
    )
    (linear_c1): MLP(
      (proj): Linear(in_features=64, out_features=256, bias=True)
    )
    (pooling_mhsa_c1): pooling_mhsa(
      (pools): ModuleList()
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (d_convs): ModuleList(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      )
    )
    (pooling_mhsa_c2): pooling_mhsa(
      (pools): ModuleList()
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (d_convs): ModuleList(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
      )
    )
    (pooling_mhsa_c3): pooling_mhsa(
      (pools): ModuleList()
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      (d_convs): ModuleList(
        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
      )
    )
    (pooling_mhsa_c4): pooling_mhsa(
      (pools): ModuleList()
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (d_convs): ModuleList(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
      )
    )
    (pooling_linear): Linear(in_features=1024, out_features=256, bias=True)
    (linear_fuse): ConvModule(
      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (linear_pred): Conv2d(256, 111, kernel_size=(1, 1), stride=(1, 1))
    (deco1): small_decoder2(
      (smalldecoder): Sequential(
        (0): Dropout2d(p=0.1, inplace=False)
        (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (deco2): small_decoder2(
      (smalldecoder): Sequential(
        (0): Dropout2d(p=0.1, inplace=False)
        (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (deco3): small_decoder2(
      (smalldecoder): Sequential(
        (0): Dropout2d(p=0.1, inplace=False)
        (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (deco4): small_decoder2(
      (smalldecoder): Sequential(
        (0): Dropout2d(p=0.1, inplace=False)
        (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (hypercorre_module): hypercorre_topk2(
      (q1): Linear(in_features=64, out_features=64, bias=True)
      (q2): Linear(in_features=128, out_features=128, bias=True)
      (q3): Linear(in_features=320, out_features=320, bias=True)
      (q4): Linear(in_features=512, out_features=512, bias=True)
      (k1): Linear(in_features=64, out_features=64, bias=True)
      (k2): Linear(in_features=128, out_features=128, bias=True)
      (k3): Linear(in_features=320, out_features=320, bias=True)
      (k4): Linear(in_features=512, out_features=512, bias=True)
      (i4): Linear(in_features=64, out_features=64, bias=True)
      (i3): Linear(in_features=128, out_features=128, bias=True)
      (i2): Linear(in_features=320, out_features=320, bias=True)
      (i1): Linear(in_features=512, out_features=512, bias=True)
      (iv4): Linear(in_features=64, out_features=64, bias=True)
      (iv3): Linear(in_features=128, out_features=128, bias=True)
      (iv2): Linear(in_features=320, out_features=320, bias=True)
      (iv1): Linear(in_features=512, out_features=512, bias=True)
      (pooling_mhsa_fk4): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
      )
      (pooling_mhsa_fk3): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
      )
      (pooling_mhsa_fk2): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
      )
      (pooling_mhsa_fk1): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        )
      )
      (pooling_mhsa_sk4): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
      )
      (pooling_mhsa_sk3): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
      )
      (pooling_mhsa_sk2): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
      )
      (pooling_mhsa_sk1): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        )
      )
      (pooling_mhsa_f4): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
      )
      (pooling_mhsa_f3): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
      )
      (pooling_mhsa_f2): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
      )
      (pooling_mhsa_f1): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        )
      )
      (f4): Linear(in_features=64, out_features=64, bias=True)
      (f3): Linear(in_features=128, out_features=128, bias=True)
      (f2): Linear(in_features=320, out_features=320, bias=True)
      (f1): Linear(in_features=512, out_features=512, bias=True)
      (v4): Linear(in_features=64, out_features=64, bias=True)
      (v3): Linear(in_features=128, out_features=128, bias=True)
      (v2): Linear(in_features=320, out_features=320, bias=True)
      (v1): Linear(in_features=512, out_features=512, bias=True)
      (fs4): Linear(in_features=64, out_features=64, bias=True)
      (fs3): Linear(in_features=128, out_features=128, bias=True)
      (fs2): Linear(in_features=320, out_features=320, bias=True)
      (fs1): Linear(in_features=512, out_features=512, bias=True)
      (vs4): Linear(in_features=64, out_features=64, bias=True)
      (vs3): Linear(in_features=128, out_features=128, bias=True)
      (vs2): Linear(in_features=320, out_features=320, bias=True)
      (vs1): Linear(in_features=512, out_features=512, bias=True)
      (pk4): Linear(in_features=64, out_features=64, bias=True)
      (pk3): Linear(in_features=128, out_features=128, bias=True)
      (pk2): Linear(in_features=320, out_features=320, bias=True)
      (pk1): Linear(in_features=512, out_features=512, bias=True)
      (f4p): Linear(in_features=64, out_features=64, bias=True)
      (f3p): Linear(in_features=128, out_features=128, bias=True)
      (f2p): Linear(in_features=320, out_features=320, bias=True)
      (f1p): Linear(in_features=512, out_features=512, bias=True)
      (pooling_proj_linear): Linear(in_features=1024, out_features=256, bias=True)
      (pooling_proj_linear_1): Linear(in_features=1024, out_features=256, bias=True)
      (pooling_proj_linear_2): Linear(in_features=1024, out_features=256, bias=True)
      (pooling_proj_linear_3): Linear(in_features=1024, out_features=256, bias=True)
      (hpn): HPNLearner_topk2(
        (encoder_layer4): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer4to3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3to2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
      (hpn1): HPNLearner_topk2(
        (encoder_layer4): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer4to3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3to2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
      (hpn2): HPNLearner_topk2(
        (encoder_layer4): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer4to3): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layer3to2): Sequential(
          (0): CenterPivotConv4d_half(
            (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): GroupNorm(1, 1, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
    )
    (sr2): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
    (sr3): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
    (sr1_feat): Conv2d(256, 256, kernel_size=(4, 4), stride=(4, 4))
    (predictor): TransformerZeroshotPredictor(
      (projection_layer): Linear(in_features=256, out_features=512, bias=True)
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): MultiheadAttention(
                  (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Sequential()
      (class_embed): Linear(in_features=256, out_features=112, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
    (linearconv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): ConvModule(
        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (layer_1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (adapter_2): ConvModule(
        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (layer_2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (adapter_3): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (layer_3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (layer_4): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)
2023-09-21 22:20:11,197 - mmseg - INFO - 
Number of parameters (in millions): 195.895
2023-09-21 22:20:11,201 - mmseg - INFO - 
Number of parameters (in millions): 24.196
2023-09-21 22:20:11,211 - mmseg - INFO - Number of parameters (in millions) for decoder: 171.699

flip video:  True
flip video:  True
2023-09-21 22:20:15,438 - mmseg - INFO - Start running, host: lixinhao@user-SYS-4029GP-TRT, work_dir: /home/lixinhao/vss/model_path/vspw2/work_dirs_4g_b4
2023-09-21 22:20:15,438 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
[W reducer.cpp:346] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [2048, 1, 3, 3], strides() = [9, 9, 3, 1] (function operator())
2023-09-21 22:20:53,646 - mmseg - INFO - Iter [50/160000]	lr: 3.266e-06, eta: 23:47:11, time: 0.535, data_time: 0.011, memory: 13718, decode.loss_ce: 3.7200, decode.loss_mask: 1.3281, decode.loss_dice: 0.7856, decode.loss_ce_0: 3.4668, decode.loss_mask_0: 1.5583, decode.loss_dice_0: 0.7914, decode.loss_ce_1: 3.3348, decode.loss_mask_1: 1.4736, decode.loss_dice_1: 0.7937, decode.loss_ce_2: 3.3483, decode.loss_mask_2: 1.4641, decode.loss_dice_2: 0.7896, decode.loss_ce_3: 3.6235, decode.loss_mask_3: 1.4811, decode.loss_dice_3: 0.7950, decode.loss_ce_4: 3.7546, decode.loss_mask_4: 1.3749, decode.loss_dice_4: 0.7909, loss: 34.6742
2023-09-21 22:21:19,437 - mmseg - INFO - Iter [100/160000]	lr: 6.596e-06, eta: 23:20:39, time: 0.516, data_time: 0.007, memory: 13718, decode.loss_ce: 2.4173, decode.loss_mask: 0.8882, decode.loss_dice: 0.7814, decode.loss_ce_0: 2.4407, decode.loss_mask_0: 0.9287, decode.loss_dice_0: 0.7832, decode.loss_ce_1: 2.3578, decode.loss_mask_1: 0.9238, decode.loss_dice_1: 0.7804, decode.loss_ce_2: 2.3075, decode.loss_mask_2: 0.9056, decode.loss_dice_2: 0.7813, decode.loss_ce_3: 2.3995, decode.loss_mask_3: 0.9157, decode.loss_dice_3: 0.7818, decode.loss_ce_4: 2.4046, decode.loss_mask_4: 0.9067, decode.loss_dice_4: 0.7815, loss: 24.4857
2023-09-21 22:21:45,625 - mmseg - INFO - Iter [150/160000]	lr: 9.924e-06, eta: 23:18:35, time: 0.524, data_time: 0.007, memory: 13718, decode.loss_ce: 2.1311, decode.loss_mask: 0.7392, decode.loss_dice: 0.7800, decode.loss_ce_0: 2.1350, decode.loss_mask_0: 0.7476, decode.loss_dice_0: 0.7776, decode.loss_ce_1: 2.1484, decode.loss_mask_1: 0.7495, decode.loss_dice_1: 0.7768, decode.loss_ce_2: 2.1532, decode.loss_mask_2: 0.7372, decode.loss_dice_2: 0.7778, decode.loss_ce_3: 2.1446, decode.loss_mask_3: 0.7421, decode.loss_dice_3: 0.7786, decode.loss_ce_4: 2.0981, decode.loss_mask_4: 0.7466, decode.loss_dice_4: 0.7800, loss: 21.9434
2023-09-21 22:22:11,871 - mmseg - INFO - Iter [200/160000]	lr: 1.325e-05, eta: 23:18:07, time: 0.525, data_time: 0.007, memory: 13718, decode.loss_ce: 2.2634, decode.loss_mask: 0.7802, decode.loss_dice: 0.8152, decode.loss_ce_0: 2.2519, decode.loss_mask_0: 0.6741, decode.loss_dice_0: 0.8075, decode.loss_ce_1: 2.2603, decode.loss_mask_1: 0.7089, decode.loss_dice_1: 0.8099, decode.loss_ce_2: 2.2759, decode.loss_mask_2: 0.7430, decode.loss_dice_2: 0.8114, decode.loss_ce_3: 2.2690, decode.loss_mask_3: 0.7647, decode.loss_dice_3: 0.8108, decode.loss_ce_4: 2.2638, decode.loss_mask_4: 0.8034, decode.loss_dice_4: 0.8160, loss: 22.9293
2023-09-21 22:22:38,072 - mmseg - INFO - Iter [250/160000]	lr: 1.657e-05, eta: 23:17:10, time: 0.524, data_time: 0.007, memory: 13718, decode.loss_ce: 2.3245, decode.loss_mask: 0.9554, decode.loss_dice: 0.7992, decode.loss_ce_0: 2.2999, decode.loss_mask_0: 0.8662, decode.loss_dice_0: 0.7885, decode.loss_ce_1: 2.2784, decode.loss_mask_1: 0.8861, decode.loss_dice_1: 0.7897, decode.loss_ce_2: 2.2932, decode.loss_mask_2: 0.8698, decode.loss_dice_2: 0.7913, decode.loss_ce_3: 2.3095, decode.loss_mask_3: 0.8676, decode.loss_dice_3: 0.7911, decode.loss_ce_4: 2.2778, decode.loss_mask_4: 0.9277, decode.loss_dice_4: 0.7951, loss: 23.9111
2023-09-21 22:23:04,072 - mmseg - INFO - Iter [300/160000]	lr: 1.990e-05, eta: 23:14:37, time: 0.520, data_time: 0.007, memory: 13718, decode.loss_ce: 2.2048, decode.loss_mask: 0.6681, decode.loss_dice: 0.7729, decode.loss_ce_0: 2.2032, decode.loss_mask_0: 0.6224, decode.loss_dice_0: 0.7660, decode.loss_ce_1: 2.2109, decode.loss_mask_1: 0.6244, decode.loss_dice_1: 0.7654, decode.loss_ce_2: 2.2075, decode.loss_mask_2: 0.6301, decode.loss_dice_2: 0.7650, decode.loss_ce_3: 2.2106, decode.loss_mask_3: 0.6259, decode.loss_dice_3: 0.7645, decode.loss_ce_4: 2.2138, decode.loss_mask_4: 0.6359, decode.loss_dice_4: 0.7710, loss: 21.6625
2023-09-21 22:23:30,130 - mmseg - INFO - Iter [350/160000]	lr: 2.322e-05, eta: 23:13:07, time: 0.521, data_time: 0.007, memory: 13718, decode.loss_ce: 2.0957, decode.loss_mask: 0.4796, decode.loss_dice: 0.7075, decode.loss_ce_0: 2.0857, decode.loss_mask_0: 0.4909, decode.loss_dice_0: 0.7026, decode.loss_ce_1: 2.0929, decode.loss_mask_1: 0.4895, decode.loss_dice_1: 0.7086, decode.loss_ce_2: 2.0545, decode.loss_mask_2: 0.5050, decode.loss_dice_2: 0.7020, decode.loss_ce_3: 2.0813, decode.loss_mask_3: 0.5074, decode.loss_dice_3: 0.7072, decode.loss_ce_4: 2.0726, decode.loss_mask_4: 0.5498, decode.loss_dice_4: 0.7167, loss: 19.7497
2023-09-21 22:23:57,387 - mmseg - INFO - Iter [400/160000]	lr: 2.653e-05, eta: 23:19:50, time: 0.545, data_time: 0.007, memory: 13718, decode.loss_ce: 2.1335, decode.loss_mask: 0.6823, decode.loss_dice: 0.6974, decode.loss_ce_0: 2.1277, decode.loss_mask_0: 0.7066, decode.loss_dice_0: 0.7044, decode.loss_ce_1: 2.0979, decode.loss_mask_1: 0.7677, decode.loss_dice_1: 0.7070, decode.loss_ce_2: 2.1092, decode.loss_mask_2: 0.9611, decode.loss_dice_2: 0.7156, decode.loss_ce_3: 2.1145, decode.loss_mask_3: 0.9023, decode.loss_dice_3: 0.7001, decode.loss_ce_4: 2.1163, decode.loss_mask_4: 0.5343, decode.loss_dice_4: 0.6920, loss: 21.4697
2023-09-21 22:24:24,722 - mmseg - INFO - Iter [450/160000]	lr: 2.985e-05, eta: 23:25:26, time: 0.547, data_time: 0.007, memory: 13718, decode.loss_ce: 2.1487, decode.loss_mask: 0.5904, decode.loss_dice: 0.7375, decode.loss_ce_0: 2.1354, decode.loss_mask_0: 0.6483, decode.loss_dice_0: 0.7477, decode.loss_ce_1: 2.0779, decode.loss_mask_1: 0.5952, decode.loss_dice_1: 0.7379, decode.loss_ce_2: 2.1492, decode.loss_mask_2: 0.6520, decode.loss_dice_2: 0.7445, decode.loss_ce_3: 2.1066, decode.loss_mask_3: 0.6546, decode.loss_dice_3: 0.7437, decode.loss_ce_4: 2.0888, decode.loss_mask_4: 0.5744, decode.loss_dice_4: 0.7316, loss: 20.8644
2023-09-21 22:24:50,450 - mmseg - INFO - Iter [500/160000]	lr: 3.316e-05, eta: 23:21:17, time: 0.515, data_time: 0.007, memory: 13718, decode.loss_ce: 1.9809, decode.loss_mask: 0.5636, decode.loss_dice: 0.6657, decode.loss_ce_0: 1.9464, decode.loss_mask_0: 0.5418, decode.loss_dice_0: 0.6697, decode.loss_ce_1: 1.9289, decode.loss_mask_1: 0.5057, decode.loss_dice_1: 0.6467, decode.loss_ce_2: 1.9397, decode.loss_mask_2: 0.5056, decode.loss_dice_2: 0.6560, decode.loss_ce_3: 1.8956, decode.loss_mask_3: 0.4991, decode.loss_dice_3: 0.6543, decode.loss_ce_4: 1.9438, decode.loss_mask_4: 0.8715, decode.loss_dice_4: 0.6658, loss: 19.0808
2023-09-21 22:25:16,827 - mmseg - INFO - Iter [550/160000]	lr: 3.647e-05, eta: 23:20:56, time: 0.528, data_time: 0.007, memory: 13718, decode.loss_ce: 2.0489, decode.loss_mask: 0.5555, decode.loss_dice: 0.6971, decode.loss_ce_0: 2.0246, decode.loss_mask_0: 0.4934, decode.loss_dice_0: 0.6817, decode.loss_ce_1: 2.0065, decode.loss_mask_1: 0.4982, decode.loss_dice_1: 0.6685, decode.loss_ce_2: 2.0397, decode.loss_mask_2: 0.4826, decode.loss_dice_2: 0.6761, decode.loss_ce_3: 1.9772, decode.loss_mask_3: 0.5313, decode.loss_dice_3: 0.6855, decode.loss_ce_4: 1.9505, decode.loss_mask_4: 0.6077, decode.loss_dice_4: 0.7001, loss: 19.3250
2023-09-21 22:25:42,677 - mmseg - INFO - Iter [600/160000]	lr: 3.978e-05, eta: 23:18:15, time: 0.517, data_time: 0.007, memory: 13718, decode.loss_ce: 2.1114, decode.loss_mask: 0.4836, decode.loss_dice: 0.6579, decode.loss_ce_0: 2.0889, decode.loss_mask_0: 0.4604, decode.loss_dice_0: 0.6534, decode.loss_ce_1: 2.0966, decode.loss_mask_1: 0.5112, decode.loss_dice_1: 0.6558, decode.loss_ce_2: 2.1313, decode.loss_mask_2: 0.4514, decode.loss_dice_2: 0.6435, decode.loss_ce_3: 2.0945, decode.loss_mask_3: 0.4801, decode.loss_dice_3: 0.6554, decode.loss_ce_4: 2.0868, decode.loss_mask_4: 0.4481, decode.loss_dice_4: 0.6532, loss: 19.3633
2023-09-21 22:26:08,640 - mmseg - INFO - Iter [650/160000]	lr: 4.309e-05, eta: 23:16:22, time: 0.519, data_time: 0.007, memory: 13718, decode.loss_ce: 1.9411, decode.loss_mask: 0.4334, decode.loss_dice: 0.6231, decode.loss_ce_0: 1.9055, decode.loss_mask_0: 0.4724, decode.loss_dice_0: 0.6332, decode.loss_ce_1: 1.8921, decode.loss_mask_1: 0.5962, decode.loss_dice_1: 0.6359, decode.loss_ce_2: 1.9241, decode.loss_mask_2: 0.4419, decode.loss_dice_2: 0.6246, decode.loss_ce_3: 1.9210, decode.loss_mask_3: 0.4426, decode.loss_dice_3: 0.6274, decode.loss_ce_4: 1.9237, decode.loss_mask_4: 0.4371, decode.loss_dice_4: 0.6190, loss: 18.0940
2023-09-21 22:26:34,460 - mmseg - INFO - Iter [700/160000]	lr: 4.640e-05, eta: 23:14:09, time: 0.516, data_time: 0.007, memory: 13718, decode.loss_ce: 1.9815, decode.loss_mask: 0.5186, decode.loss_dice: 0.6410, decode.loss_ce_0: 1.9840, decode.loss_mask_0: 0.4806, decode.loss_dice_0: 0.6371, decode.loss_ce_1: 1.9684, decode.loss_mask_1: 0.4861, decode.loss_dice_1: 0.6345, decode.loss_ce_2: 1.9867, decode.loss_mask_2: 0.4478, decode.loss_dice_2: 0.6349, decode.loss_ce_3: 1.9786, decode.loss_mask_3: 0.4690, decode.loss_dice_3: 0.6337, decode.loss_ce_4: 1.9759, decode.loss_mask_4: 0.5847, decode.loss_dice_4: 0.6424, loss: 18.6856
2023-09-21 22:27:00,131 - mmseg - INFO - Iter [750/160000]	lr: 4.970e-05, eta: 23:11:38, time: 0.513, data_time: 0.007, memory: 13718, decode.loss_ce: 2.0566, decode.loss_mask: 0.4738, decode.loss_dice: 0.6246, decode.loss_ce_0: 2.0648, decode.loss_mask_0: 0.4667, decode.loss_dice_0: 0.6120, decode.loss_ce_1: 2.0607, decode.loss_mask_1: 0.4493, decode.loss_dice_1: 0.6137, decode.loss_ce_2: 2.0495, decode.loss_mask_2: 0.4508, decode.loss_dice_2: 0.6220, decode.loss_ce_3: 2.0897, decode.loss_mask_3: 0.4852, decode.loss_dice_3: 0.6200, decode.loss_ce_4: 2.0636, decode.loss_mask_4: 0.4595, decode.loss_dice_4: 0.6197, loss: 18.8822
2023-09-21 22:27:28,770 - mmseg - INFO - Iter [800/160000]	lr: 5.300e-05, eta: 23:19:14, time: 0.573, data_time: 0.012, memory: 13718, decode.loss_ce: 2.0005, decode.loss_mask: 0.4052, decode.loss_dice: 0.6339, decode.loss_ce_0: 2.0458, decode.loss_mask_0: 0.4590, decode.loss_dice_0: 0.6403, decode.loss_ce_1: 2.0074, decode.loss_mask_1: 0.4774, decode.loss_dice_1: 0.6492, decode.loss_ce_2: 2.0511, decode.loss_mask_2: 0.8596, decode.loss_dice_2: 0.6742, decode.loss_ce_3: 1.9778, decode.loss_mask_3: 0.4287, decode.loss_dice_3: 0.6413, decode.loss_ce_4: 1.9978, decode.loss_mask_4: 0.4025, decode.loss_dice_4: 0.6293, loss: 18.9811
2023-09-21 22:28:00,510 - mmseg - INFO - Iter [850/160000]	lr: 5.630e-05, eta: 23:35:34, time: 0.635, data_time: 0.009, memory: 13718, decode.loss_ce: 2.0170, decode.loss_mask: 0.5036, decode.loss_dice: 0.6374, decode.loss_ce_0: 1.9958, decode.loss_mask_0: 0.4470, decode.loss_dice_0: 0.6344, decode.loss_ce_1: 1.9772, decode.loss_mask_1: 0.4783, decode.loss_dice_1: 0.6367, decode.loss_ce_2: 2.0111, decode.loss_mask_2: 0.4744, decode.loss_dice_2: 0.6652, decode.loss_ce_3: 1.9911, decode.loss_mask_3: 0.4780, decode.loss_dice_3: 0.6389, decode.loss_ce_4: 2.0263, decode.loss_mask_4: 0.7728, decode.loss_dice_4: 0.6454, loss: 19.0306
2023-09-21 22:28:32,105 - mmseg - INFO - Iter [900/160000]	lr: 5.960e-05, eta: 23:49:35, time: 0.632, data_time: 0.010, memory: 13718, decode.loss_ce: 1.9851, decode.loss_mask: 0.5758, decode.loss_dice: 0.6691, decode.loss_ce_0: 1.9986, decode.loss_mask_0: 0.5016, decode.loss_dice_0: 0.6564, decode.loss_ce_1: 1.9737, decode.loss_mask_1: 0.5898, decode.loss_dice_1: 0.6747, decode.loss_ce_2: 2.0064, decode.loss_mask_2: 0.5471, decode.loss_dice_2: 0.6754, decode.loss_ce_3: 1.9453, decode.loss_mask_3: 0.5513, decode.loss_dice_3: 0.6733, decode.loss_ce_4: 1.9873, decode.loss_mask_4: 0.6161, decode.loss_dice_4: 0.6725, loss: 19.2994
2023-09-21 22:29:03,163 - mmseg - INFO - Iter [950/160000]	lr: 6.289e-05, eta: 1 day, 0:00:34, time: 0.621, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8954, decode.loss_mask: 0.4705, decode.loss_dice: 0.6075, decode.loss_ce_0: 1.9420, decode.loss_mask_0: 0.4951, decode.loss_dice_0: 0.6030, decode.loss_ce_1: 1.9023, decode.loss_mask_1: 0.4441, decode.loss_dice_1: 0.6054, decode.loss_ce_2: 1.9286, decode.loss_mask_2: 0.4895, decode.loss_dice_2: 0.6144, decode.loss_ce_3: 1.9204, decode.loss_mask_3: 0.5428, decode.loss_dice_3: 0.6133, decode.loss_ce_4: 1.8936, decode.loss_mask_4: 0.4866, decode.loss_dice_4: 0.6099, loss: 18.0646
2023-09-21 22:29:34,785 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 22:29:34,785 - mmseg - INFO - Iter [1000/160000]	lr: 6.618e-05, eta: 1 day, 0:11:55, time: 0.632, data_time: 0.009, memory: 13718, decode.loss_ce: 2.1012, decode.loss_mask: 0.4431, decode.loss_dice: 0.6244, decode.loss_ce_0: 2.1290, decode.loss_mask_0: 0.4913, decode.loss_dice_0: 0.6376, decode.loss_ce_1: 2.0981, decode.loss_mask_1: 0.4658, decode.loss_dice_1: 0.6331, decode.loss_ce_2: 2.1143, decode.loss_mask_2: 0.4638, decode.loss_dice_2: 0.6393, decode.loss_ce_3: 2.0934, decode.loss_mask_3: 0.4469, decode.loss_dice_3: 0.6294, decode.loss_ce_4: 2.0901, decode.loss_mask_4: 0.4377, decode.loss_dice_4: 0.6277, loss: 19.1662
2023-09-21 22:30:06,903 - mmseg - INFO - Iter [1050/160000]	lr: 6.947e-05, eta: 1 day, 0:23:22, time: 0.642, data_time: 0.010, memory: 13718, decode.loss_ce: 2.0472, decode.loss_mask: 0.4074, decode.loss_dice: 0.6141, decode.loss_ce_0: 2.0721, decode.loss_mask_0: 0.4087, decode.loss_dice_0: 0.6166, decode.loss_ce_1: 2.0508, decode.loss_mask_1: 0.4210, decode.loss_dice_1: 0.6216, decode.loss_ce_2: 2.0870, decode.loss_mask_2: 0.4005, decode.loss_dice_2: 0.6172, decode.loss_ce_3: 2.0422, decode.loss_mask_3: 0.4050, decode.loss_dice_3: 0.6138, decode.loss_ce_4: 2.0464, decode.loss_mask_4: 0.4220, decode.loss_dice_4: 0.6141, loss: 18.5076
2023-09-21 22:30:39,014 - mmseg - INFO - Iter [1100/160000]	lr: 7.276e-05, eta: 1 day, 0:33:43, time: 0.642, data_time: 0.010, memory: 13718, decode.loss_ce: 2.0354, decode.loss_mask: 0.5952, decode.loss_dice: 0.6401, decode.loss_ce_0: 2.0426, decode.loss_mask_0: 0.4182, decode.loss_dice_0: 0.6160, decode.loss_ce_1: 2.0333, decode.loss_mask_1: 0.4908, decode.loss_dice_1: 0.6297, decode.loss_ce_2: 2.0779, decode.loss_mask_2: 0.4610, decode.loss_dice_2: 0.6259, decode.loss_ce_3: 2.0228, decode.loss_mask_3: 0.4678, decode.loss_dice_3: 0.6227, decode.loss_ce_4: 2.0413, decode.loss_mask_4: 0.4548, decode.loss_dice_4: 0.6262, loss: 18.9017
2023-09-21 22:31:11,109 - mmseg - INFO - Iter [1150/160000]	lr: 7.605e-05, eta: 1 day, 0:43:05, time: 0.642, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8918, decode.loss_mask: 0.5162, decode.loss_dice: 0.5897, decode.loss_ce_0: 1.9012, decode.loss_mask_0: 0.4490, decode.loss_dice_0: 0.5823, decode.loss_ce_1: 1.9010, decode.loss_mask_1: 0.4446, decode.loss_dice_1: 0.5871, decode.loss_ce_2: 1.9100, decode.loss_mask_2: 0.4300, decode.loss_dice_2: 0.5845, decode.loss_ce_3: 1.8991, decode.loss_mask_3: 0.5605, decode.loss_dice_3: 0.6030, decode.loss_ce_4: 1.8829, decode.loss_mask_4: 0.4511, decode.loss_dice_4: 0.5879, loss: 17.7720
2023-09-21 22:31:43,222 - mmseg - INFO - Iter [1200/160000]	lr: 7.933e-05, eta: 1 day, 0:51:40, time: 0.642, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8982, decode.loss_mask: 0.3787, decode.loss_dice: 0.5662, decode.loss_ce_0: 1.9206, decode.loss_mask_0: 0.4087, decode.loss_dice_0: 0.5614, decode.loss_ce_1: 1.9104, decode.loss_mask_1: 0.3957, decode.loss_dice_1: 0.5627, decode.loss_ce_2: 1.9196, decode.loss_mask_2: 0.4175, decode.loss_dice_2: 0.5658, decode.loss_ce_3: 1.9086, decode.loss_mask_3: 0.3839, decode.loss_dice_3: 0.5649, decode.loss_ce_4: 1.8998, decode.loss_mask_4: 0.3749, decode.loss_dice_4: 0.5664, loss: 17.2039
2023-09-21 22:32:15,649 - mmseg - INFO - Iter [1250/160000]	lr: 8.262e-05, eta: 1 day, 1:00:11, time: 0.649, data_time: 0.009, memory: 13718, decode.loss_ce: 1.9462, decode.loss_mask: 0.5928, decode.loss_dice: 0.5885, decode.loss_ce_0: 1.9729, decode.loss_mask_0: 0.4724, decode.loss_dice_0: 0.5597, decode.loss_ce_1: 1.9298, decode.loss_mask_1: 0.4655, decode.loss_dice_1: 0.5750, decode.loss_ce_2: 1.9438, decode.loss_mask_2: 0.4377, decode.loss_dice_2: 0.5760, decode.loss_ce_3: 1.9323, decode.loss_mask_3: 0.4557, decode.loss_dice_3: 0.5717, decode.loss_ce_4: 1.9680, decode.loss_mask_4: 0.4518, decode.loss_dice_4: 0.5767, loss: 18.0165
2023-09-21 22:32:47,195 - mmseg - INFO - Iter [1300/160000]	lr: 8.590e-05, eta: 1 day, 1:06:13, time: 0.631, data_time: 0.009, memory: 13718, decode.loss_ce: 1.9016, decode.loss_mask: 0.4280, decode.loss_dice: 0.5782, decode.loss_ce_0: 1.9333, decode.loss_mask_0: 0.4508, decode.loss_dice_0: 0.5827, decode.loss_ce_1: 1.8855, decode.loss_mask_1: 0.4363, decode.loss_dice_1: 0.5899, decode.loss_ce_2: 1.9424, decode.loss_mask_2: 0.4391, decode.loss_dice_2: 0.5860, decode.loss_ce_3: 1.9282, decode.loss_mask_3: 0.4446, decode.loss_dice_3: 0.5848, decode.loss_ce_4: 1.9236, decode.loss_mask_4: 0.4428, decode.loss_dice_4: 0.5777, loss: 17.6555
2023-09-21 22:33:18,920 - mmseg - INFO - Iter [1350/160000]	lr: 8.918e-05, eta: 1 day, 1:12:07, time: 0.634, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8705, decode.loss_mask: 0.4293, decode.loss_dice: 0.5693, decode.loss_ce_0: 1.9154, decode.loss_mask_0: 0.4647, decode.loss_dice_0: 0.5636, decode.loss_ce_1: 1.8658, decode.loss_mask_1: 0.4539, decode.loss_dice_1: 0.5866, decode.loss_ce_2: 1.9090, decode.loss_mask_2: 0.4281, decode.loss_dice_2: 0.5731, decode.loss_ce_3: 1.8916, decode.loss_mask_3: 0.3923, decode.loss_dice_3: 0.5647, decode.loss_ce_4: 1.8760, decode.loss_mask_4: 0.4086, decode.loss_dice_4: 0.5711, loss: 17.3337
2023-09-21 22:33:51,465 - mmseg - INFO - Iter [1400/160000]	lr: 9.245e-05, eta: 1 day, 1:19:06, time: 0.651, data_time: 0.008, memory: 13718, decode.loss_ce: 2.0707, decode.loss_mask: 0.4485, decode.loss_dice: 0.6121, decode.loss_ce_0: 2.0796, decode.loss_mask_0: 0.4394, decode.loss_dice_0: 0.6126, decode.loss_ce_1: 2.0416, decode.loss_mask_1: 0.4369, decode.loss_dice_1: 0.6164, decode.loss_ce_2: 2.0932, decode.loss_mask_2: 0.4543, decode.loss_dice_2: 0.6160, decode.loss_ce_3: 2.0747, decode.loss_mask_3: 0.4492, decode.loss_dice_3: 0.6078, decode.loss_ce_4: 2.0818, decode.loss_mask_4: 0.4505, decode.loss_dice_4: 0.6071, loss: 18.7923
2023-09-21 22:34:22,925 - mmseg - INFO - Iter [1450/160000]	lr: 9.573e-05, eta: 1 day, 1:23:35, time: 0.629, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8427, decode.loss_mask: 0.4789, decode.loss_dice: 0.5774, decode.loss_ce_0: 1.8306, decode.loss_mask_0: 0.4896, decode.loss_dice_0: 0.5816, decode.loss_ce_1: 1.8156, decode.loss_mask_1: 0.5184, decode.loss_dice_1: 0.5928, decode.loss_ce_2: 1.8796, decode.loss_mask_2: 0.5575, decode.loss_dice_2: 0.5941, decode.loss_ce_3: 1.8402, decode.loss_mask_3: 0.5575, decode.loss_dice_3: 0.5906, decode.loss_ce_4: 1.8493, decode.loss_mask_4: 0.4752, decode.loss_dice_4: 0.5850, loss: 17.6564
2023-09-21 22:34:50,161 - mmseg - INFO - Iter [1500/160000]	lr: 9.900e-05, eta: 1 day, 1:20:18, time: 0.545, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8445, decode.loss_mask: 0.4627, decode.loss_dice: 0.5716, decode.loss_ce_0: 1.8812, decode.loss_mask_0: 0.4325, decode.loss_dice_0: 0.5472, decode.loss_ce_1: 1.8220, decode.loss_mask_1: 0.4439, decode.loss_dice_1: 0.5600, decode.loss_ce_2: 1.8624, decode.loss_mask_2: 0.4655, decode.loss_dice_2: 0.5611, decode.loss_ce_3: 1.8842, decode.loss_mask_3: 0.4998, decode.loss_dice_3: 0.5724, decode.loss_ce_4: 1.8849, decode.loss_mask_4: 0.4705, decode.loss_dice_4: 0.5671, loss: 17.3333
2023-09-21 22:35:17,615 - mmseg - INFO - Iter [1550/160000]	lr: 9.903e-05, eta: 1 day, 1:17:34, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9527, decode.loss_mask: 0.3721, decode.loss_dice: 0.5892, decode.loss_ce_0: 1.9803, decode.loss_mask_0: 0.3723, decode.loss_dice_0: 0.5846, decode.loss_ce_1: 1.9557, decode.loss_mask_1: 0.3961, decode.loss_dice_1: 0.5919, decode.loss_ce_2: 1.9604, decode.loss_mask_2: 0.3729, decode.loss_dice_2: 0.5892, decode.loss_ce_3: 1.9690, decode.loss_mask_3: 0.3809, decode.loss_dice_3: 0.5945, decode.loss_ce_4: 1.9595, decode.loss_mask_4: 0.3720, decode.loss_dice_4: 0.5942, loss: 17.5875
2023-09-21 22:35:44,979 - mmseg - INFO - Iter [1600/160000]	lr: 9.900e-05, eta: 1 day, 1:14:50, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 2.0450, decode.loss_mask: 0.4793, decode.loss_dice: 0.6162, decode.loss_ce_0: 2.0544, decode.loss_mask_0: 0.4404, decode.loss_dice_0: 0.6114, decode.loss_ce_1: 2.0148, decode.loss_mask_1: 0.4380, decode.loss_dice_1: 0.6199, decode.loss_ce_2: 2.0850, decode.loss_mask_2: 0.4446, decode.loss_dice_2: 0.6128, decode.loss_ce_3: 2.0655, decode.loss_mask_3: 0.4366, decode.loss_dice_3: 0.6106, decode.loss_ce_4: 2.0570, decode.loss_mask_4: 0.4291, decode.loss_dice_4: 0.6136, loss: 18.6744
2023-09-21 22:36:12,091 - mmseg - INFO - Iter [1650/160000]	lr: 9.897e-05, eta: 1 day, 1:11:49, time: 0.542, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9506, decode.loss_mask: 0.3892, decode.loss_dice: 0.5863, decode.loss_ce_0: 1.9444, decode.loss_mask_0: 0.3741, decode.loss_dice_0: 0.5829, decode.loss_ce_1: 1.9232, decode.loss_mask_1: 0.3814, decode.loss_dice_1: 0.5940, decode.loss_ce_2: 1.9722, decode.loss_mask_2: 0.3746, decode.loss_dice_2: 0.5855, decode.loss_ce_3: 1.9544, decode.loss_mask_3: 0.3954, decode.loss_dice_3: 0.5974, decode.loss_ce_4: 1.9812, decode.loss_mask_4: 0.3814, decode.loss_dice_4: 0.5928, loss: 17.5610
2023-09-21 22:36:39,469 - mmseg - INFO - Iter [1700/160000]	lr: 9.894e-05, eta: 1 day, 1:09:23, time: 0.548, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9197, decode.loss_mask: 0.4513, decode.loss_dice: 0.5598, decode.loss_ce_0: 1.9024, decode.loss_mask_0: 0.4619, decode.loss_dice_0: 0.5691, decode.loss_ce_1: 1.9024, decode.loss_mask_1: 0.4572, decode.loss_dice_1: 0.5658, decode.loss_ce_2: 1.9295, decode.loss_mask_2: 0.4284, decode.loss_dice_2: 0.5580, decode.loss_ce_3: 1.9234, decode.loss_mask_3: 0.4393, decode.loss_dice_3: 0.5679, decode.loss_ce_4: 1.9186, decode.loss_mask_4: 0.4438, decode.loss_dice_4: 0.5730, loss: 17.5719
2023-09-21 22:37:05,520 - mmseg - INFO - Iter [1750/160000]	lr: 9.891e-05, eta: 1 day, 1:05:03, time: 0.521, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8755, decode.loss_mask: 0.4318, decode.loss_dice: 0.5580, decode.loss_ce_0: 1.8794, decode.loss_mask_0: 0.4437, decode.loss_dice_0: 0.5514, decode.loss_ce_1: 1.8472, decode.loss_mask_1: 0.4401, decode.loss_dice_1: 0.5570, decode.loss_ce_2: 1.8919, decode.loss_mask_2: 0.4280, decode.loss_dice_2: 0.5503, decode.loss_ce_3: 1.9024, decode.loss_mask_3: 0.4313, decode.loss_dice_3: 0.5535, decode.loss_ce_4: 1.9066, decode.loss_mask_4: 0.4305, decode.loss_dice_4: 0.5544, loss: 17.2331
2023-09-21 22:37:31,698 - mmseg - INFO - Iter [1800/160000]	lr: 9.888e-05, eta: 1 day, 1:01:08, time: 0.524, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9383, decode.loss_mask: 0.4313, decode.loss_dice: 0.5966, decode.loss_ce_0: 1.9395, decode.loss_mask_0: 0.4346, decode.loss_dice_0: 0.5869, decode.loss_ce_1: 1.8700, decode.loss_mask_1: 0.4341, decode.loss_dice_1: 0.5941, decode.loss_ce_2: 1.9505, decode.loss_mask_2: 0.4610, decode.loss_dice_2: 0.5935, decode.loss_ce_3: 1.9570, decode.loss_mask_3: 0.4747, decode.loss_dice_3: 0.6037, decode.loss_ce_4: 1.9611, decode.loss_mask_4: 0.4471, decode.loss_dice_4: 0.5950, loss: 17.8691
2023-09-21 22:37:57,730 - mmseg - INFO - Iter [1850/160000]	lr: 9.884e-05, eta: 1 day, 0:57:11, time: 0.521, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9329, decode.loss_mask: 0.3621, decode.loss_dice: 0.5685, decode.loss_ce_0: 1.9612, decode.loss_mask_0: 0.3536, decode.loss_dice_0: 0.5623, decode.loss_ce_1: 1.9054, decode.loss_mask_1: 0.3809, decode.loss_dice_1: 0.5712, decode.loss_ce_2: 1.9437, decode.loss_mask_2: 0.3866, decode.loss_dice_2: 0.5673, decode.loss_ce_3: 1.9399, decode.loss_mask_3: 0.3562, decode.loss_dice_3: 0.5733, decode.loss_ce_4: 1.9441, decode.loss_mask_4: 0.3682, decode.loss_dice_4: 0.5744, loss: 17.2518
2023-09-21 22:38:23,840 - mmseg - INFO - Iter [1900/160000]	lr: 9.881e-05, eta: 1 day, 0:53:32, time: 0.522, data_time: 0.007, memory: 13718, decode.loss_ce: 1.9070, decode.loss_mask: 0.4340, decode.loss_dice: 0.5639, decode.loss_ce_0: 1.9169, decode.loss_mask_0: 0.3791, decode.loss_dice_0: 0.5604, decode.loss_ce_1: 1.8640, decode.loss_mask_1: 0.4296, decode.loss_dice_1: 0.5726, decode.loss_ce_2: 1.9529, decode.loss_mask_2: 0.4045, decode.loss_dice_2: 0.5605, decode.loss_ce_3: 1.9454, decode.loss_mask_3: 0.3823, decode.loss_dice_3: 0.5615, decode.loss_ce_4: 1.9023, decode.loss_mask_4: 0.4096, decode.loss_dice_4: 0.5611, loss: 17.3077
2023-09-21 22:38:50,139 - mmseg - INFO - Iter [1950/160000]	lr: 9.878e-05, eta: 1 day, 0:50:18, time: 0.526, data_time: 0.007, memory: 13718, decode.loss_ce: 1.8902, decode.loss_mask: 0.4442, decode.loss_dice: 0.6219, decode.loss_ce_0: 1.9359, decode.loss_mask_0: 0.4612, decode.loss_dice_0: 0.6159, decode.loss_ce_1: 1.8585, decode.loss_mask_1: 0.5310, decode.loss_dice_1: 0.6356, decode.loss_ce_2: 1.9327, decode.loss_mask_2: 0.4245, decode.loss_dice_2: 0.6106, decode.loss_ce_3: 1.9753, decode.loss_mask_3: 0.4227, decode.loss_dice_3: 0.6146, decode.loss_ce_4: 1.9138, decode.loss_mask_4: 0.4597, decode.loss_dice_4: 0.6231, loss: 17.9715
2023-09-21 22:39:21,848 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 22:39:21,849 - mmseg - INFO - Iter [2000/160000]	lr: 9.875e-05, eta: 1 day, 0:54:20, time: 0.634, data_time: 0.009, memory: 13718, decode.loss_ce: 1.9661, decode.loss_mask: 0.3837, decode.loss_dice: 0.5580, decode.loss_ce_0: 2.0255, decode.loss_mask_0: 0.4191, decode.loss_dice_0: 0.5565, decode.loss_ce_1: 1.8873, decode.loss_mask_1: 0.3973, decode.loss_dice_1: 0.5698, decode.loss_ce_2: 1.9384, decode.loss_mask_2: 0.3817, decode.loss_dice_2: 0.5522, decode.loss_ce_3: 1.9991, decode.loss_mask_3: 0.4311, decode.loss_dice_3: 0.5712, decode.loss_ce_4: 1.9453, decode.loss_mask_4: 0.4084, decode.loss_dice_4: 0.5678, loss: 17.5588
2023-09-21 22:39:53,482 - mmseg - INFO - Iter [2050/160000]	lr: 9.872e-05, eta: 1 day, 0:58:03, time: 0.633, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7833, decode.loss_mask: 0.3573, decode.loss_dice: 0.5287, decode.loss_ce_0: 1.7744, decode.loss_mask_0: 0.3623, decode.loss_dice_0: 0.5304, decode.loss_ce_1: 1.7567, decode.loss_mask_1: 0.3925, decode.loss_dice_1: 0.5447, decode.loss_ce_2: 1.8180, decode.loss_mask_2: 0.3671, decode.loss_dice_2: 0.5360, decode.loss_ce_3: 1.8229, decode.loss_mask_3: 0.3911, decode.loss_dice_3: 0.5333, decode.loss_ce_4: 1.8044, decode.loss_mask_4: 0.3641, decode.loss_dice_4: 0.5352, loss: 16.2025
2023-09-21 22:40:25,574 - mmseg - INFO - Iter [2100/160000]	lr: 9.869e-05, eta: 1 day, 1:02:08, time: 0.642, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8080, decode.loss_mask: 0.4026, decode.loss_dice: 0.5574, decode.loss_ce_0: 1.8102, decode.loss_mask_0: 0.3852, decode.loss_dice_0: 0.5555, decode.loss_ce_1: 1.7508, decode.loss_mask_1: 0.3895, decode.loss_dice_1: 0.5681, decode.loss_ce_2: 1.7751, decode.loss_mask_2: 0.3825, decode.loss_dice_2: 0.5505, decode.loss_ce_3: 1.8432, decode.loss_mask_3: 0.3986, decode.loss_dice_3: 0.5510, decode.loss_ce_4: 1.8149, decode.loss_mask_4: 0.3941, decode.loss_dice_4: 0.5555, loss: 16.4930
2023-09-21 22:40:57,518 - mmseg - INFO - Iter [2150/160000]	lr: 9.866e-05, eta: 1 day, 1:05:49, time: 0.639, data_time: 0.011, memory: 13718, decode.loss_ce: 1.9178, decode.loss_mask: 0.5332, decode.loss_dice: 0.5774, decode.loss_ce_0: 1.9097, decode.loss_mask_0: 0.3765, decode.loss_dice_0: 0.5550, decode.loss_ce_1: 1.8864, decode.loss_mask_1: 0.3753, decode.loss_dice_1: 0.5500, decode.loss_ce_2: 1.9022, decode.loss_mask_2: 0.3760, decode.loss_dice_2: 0.5540, decode.loss_ce_3: 1.9433, decode.loss_mask_3: 0.4043, decode.loss_dice_3: 0.5421, decode.loss_ce_4: 1.8992, decode.loss_mask_4: 0.3957, decode.loss_dice_4: 0.5586, loss: 17.2565
2023-09-21 22:41:29,397 - mmseg - INFO - Iter [2200/160000]	lr: 9.863e-05, eta: 1 day, 1:09:15, time: 0.638, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8856, decode.loss_mask: 0.4089, decode.loss_dice: 0.5658, decode.loss_ce_0: 1.9372, decode.loss_mask_0: 0.4237, decode.loss_dice_0: 0.5689, decode.loss_ce_1: 1.9251, decode.loss_mask_1: 0.4106, decode.loss_dice_1: 0.5623, decode.loss_ce_2: 1.9435, decode.loss_mask_2: 0.4047, decode.loss_dice_2: 0.5629, decode.loss_ce_3: 1.9575, decode.loss_mask_3: 0.3937, decode.loss_dice_3: 0.5591, decode.loss_ce_4: 1.8940, decode.loss_mask_4: 0.4368, decode.loss_dice_4: 0.5790, loss: 17.4193
2023-09-21 22:42:01,246 - mmseg - INFO - Iter [2250/160000]	lr: 9.859e-05, eta: 1 day, 1:12:27, time: 0.637, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8326, decode.loss_mask: 0.3928, decode.loss_dice: 0.5721, decode.loss_ce_0: 1.8822, decode.loss_mask_0: 0.3629, decode.loss_dice_0: 0.5523, decode.loss_ce_1: 1.8318, decode.loss_mask_1: 0.3531, decode.loss_dice_1: 0.5640, decode.loss_ce_2: 1.9315, decode.loss_mask_2: 0.5210, decode.loss_dice_2: 0.5764, decode.loss_ce_3: 1.8811, decode.loss_mask_3: 0.3499, decode.loss_dice_3: 0.5538, decode.loss_ce_4: 1.8067, decode.loss_mask_4: 0.3660, decode.loss_dice_4: 0.5717, loss: 16.9018
2023-09-21 22:42:32,236 - mmseg - INFO - Iter [2300/160000]	lr: 9.856e-05, eta: 1 day, 1:14:31, time: 0.620, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7745, decode.loss_mask: 0.4439, decode.loss_dice: 0.5565, decode.loss_ce_0: 1.8522, decode.loss_mask_0: 0.4421, decode.loss_dice_0: 0.5370, decode.loss_ce_1: 1.7778, decode.loss_mask_1: 0.4182, decode.loss_dice_1: 0.5431, decode.loss_ce_2: 1.8889, decode.loss_mask_2: 0.5219, decode.loss_dice_2: 0.5685, decode.loss_ce_3: 1.8417, decode.loss_mask_3: 0.4142, decode.loss_dice_3: 0.5355, decode.loss_ce_4: 1.7594, decode.loss_mask_4: 0.4044, decode.loss_dice_4: 0.5495, loss: 16.8293
2023-09-21 22:43:04,661 - mmseg - INFO - Iter [2350/160000]	lr: 9.853e-05, eta: 1 day, 1:18:05, time: 0.648, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9527, decode.loss_mask: 0.4093, decode.loss_dice: 0.5890, decode.loss_ce_0: 1.9771, decode.loss_mask_0: 0.3839, decode.loss_dice_0: 0.5810, decode.loss_ce_1: 1.9553, decode.loss_mask_1: 0.3959, decode.loss_dice_1: 0.5814, decode.loss_ce_2: 2.0189, decode.loss_mask_2: 0.3892, decode.loss_dice_2: 0.5842, decode.loss_ce_3: 1.9708, decode.loss_mask_3: 0.3967, decode.loss_dice_3: 0.5894, decode.loss_ce_4: 1.9951, decode.loss_mask_4: 0.3848, decode.loss_dice_4: 0.5859, loss: 17.7405
2023-09-21 22:43:36,857 - mmseg - INFO - Iter [2400/160000]	lr: 9.850e-05, eta: 1 day, 1:21:13, time: 0.644, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6789, decode.loss_mask: 0.3420, decode.loss_dice: 0.5211, decode.loss_ce_0: 1.7105, decode.loss_mask_0: 0.3618, decode.loss_dice_0: 0.5156, decode.loss_ce_1: 1.6814, decode.loss_mask_1: 0.3642, decode.loss_dice_1: 0.5273, decode.loss_ce_2: 1.7373, decode.loss_mask_2: 0.3872, decode.loss_dice_2: 0.5233, decode.loss_ce_3: 1.7052, decode.loss_mask_3: 0.3369, decode.loss_dice_3: 0.5192, decode.loss_ce_4: 1.7263, decode.loss_mask_4: 0.3451, decode.loss_dice_4: 0.5197, loss: 15.5027
2023-09-21 22:44:07,979 - mmseg - INFO - Iter [2450/160000]	lr: 9.847e-05, eta: 1 day, 1:23:03, time: 0.622, data_time: 0.008, memory: 13718, decode.loss_ce: 1.9008, decode.loss_mask: 0.3976, decode.loss_dice: 0.5661, decode.loss_ce_0: 1.9680, decode.loss_mask_0: 0.3960, decode.loss_dice_0: 0.5594, decode.loss_ce_1: 1.8722, decode.loss_mask_1: 0.4034, decode.loss_dice_1: 0.5714, decode.loss_ce_2: 1.9624, decode.loss_mask_2: 0.4131, decode.loss_dice_2: 0.5646, decode.loss_ce_3: 1.9553, decode.loss_mask_3: 0.3897, decode.loss_dice_3: 0.5586, decode.loss_ce_4: 1.9106, decode.loss_mask_4: 0.3851, decode.loss_dice_4: 0.5606, loss: 17.3351
2023-09-21 22:44:52,350 - mmseg - INFO - Iter [2500/160000]	lr: 9.844e-05, eta: 1 day, 1:38:42, time: 0.887, data_time: 0.331, memory: 13718, decode.loss_ce: 1.8493, decode.loss_mask: 0.3988, decode.loss_dice: 0.5169, decode.loss_ce_0: 1.8792, decode.loss_mask_0: 0.3864, decode.loss_dice_0: 0.5100, decode.loss_ce_1: 1.8242, decode.loss_mask_1: 0.4149, decode.loss_dice_1: 0.5183, decode.loss_ce_2: 1.8782, decode.loss_mask_2: 0.3862, decode.loss_dice_2: 0.5181, decode.loss_ce_3: 1.8583, decode.loss_mask_3: 0.3771, decode.loss_dice_3: 0.5149, decode.loss_ce_4: 1.8618, decode.loss_mask_4: 0.3720, decode.loss_dice_4: 0.5059, loss: 16.5704
2023-09-21 22:45:23,884 - mmseg - INFO - Iter [2550/160000]	lr: 9.841e-05, eta: 1 day, 1:40:31, time: 0.631, data_time: 0.096, memory: 13718, decode.loss_ce: 1.7719, decode.loss_mask: 0.3717, decode.loss_dice: 0.5115, decode.loss_ce_0: 1.8671, decode.loss_mask_0: 0.5050, decode.loss_dice_0: 0.5307, decode.loss_ce_1: 1.7753, decode.loss_mask_1: 0.3775, decode.loss_dice_1: 0.5104, decode.loss_ce_2: 1.8316, decode.loss_mask_2: 0.3917, decode.loss_dice_2: 0.4943, decode.loss_ce_3: 1.8470, decode.loss_mask_3: 0.3884, decode.loss_dice_3: 0.5092, decode.loss_ce_4: 1.7881, decode.loss_mask_4: 0.3610, decode.loss_dice_4: 0.5060, loss: 16.3382
2023-09-21 22:45:52,547 - mmseg - INFO - Iter [2600/160000]	lr: 9.838e-05, eta: 1 day, 1:39:19, time: 0.573, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8722, decode.loss_mask: 0.4590, decode.loss_dice: 0.5715, decode.loss_ce_0: 1.8899, decode.loss_mask_0: 0.3957, decode.loss_dice_0: 0.5684, decode.loss_ce_1: 1.8211, decode.loss_mask_1: 0.3895, decode.loss_dice_1: 0.5584, decode.loss_ce_2: 1.9242, decode.loss_mask_2: 0.4129, decode.loss_dice_2: 0.5637, decode.loss_ce_3: 1.8812, decode.loss_mask_3: 0.3912, decode.loss_dice_3: 0.5649, decode.loss_ce_4: 1.8366, decode.loss_mask_4: 0.4202, decode.loss_dice_4: 0.5654, loss: 17.0861
2023-09-21 22:46:19,787 - mmseg - INFO - Iter [2650/160000]	lr: 9.834e-05, eta: 1 day, 1:36:45, time: 0.545, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6692, decode.loss_mask: 0.4087, decode.loss_dice: 0.5077, decode.loss_ce_0: 1.6991, decode.loss_mask_0: 0.3845, decode.loss_dice_0: 0.5011, decode.loss_ce_1: 1.6604, decode.loss_mask_1: 0.3978, decode.loss_dice_1: 0.5025, decode.loss_ce_2: 1.7262, decode.loss_mask_2: 0.4066, decode.loss_dice_2: 0.5031, decode.loss_ce_3: 1.7199, decode.loss_mask_3: 0.4245, decode.loss_dice_3: 0.5028, decode.loss_ce_4: 1.6586, decode.loss_mask_4: 0.4103, decode.loss_dice_4: 0.5066, loss: 15.5895
2023-09-21 22:46:46,517 - mmseg - INFO - Iter [2700/160000]	lr: 9.831e-05, eta: 1 day, 1:33:46, time: 0.535, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7114, decode.loss_mask: 0.4129, decode.loss_dice: 0.5633, decode.loss_ce_0: 1.7691, decode.loss_mask_0: 0.4111, decode.loss_dice_0: 0.5512, decode.loss_ce_1: 1.7299, decode.loss_mask_1: 0.3991, decode.loss_dice_1: 0.5537, decode.loss_ce_2: 1.7599, decode.loss_mask_2: 0.4007, decode.loss_dice_2: 0.5584, decode.loss_ce_3: 1.7806, decode.loss_mask_3: 0.4475, decode.loss_dice_3: 0.5722, decode.loss_ce_4: 1.7378, decode.loss_mask_4: 0.4335, decode.loss_dice_4: 0.5578, loss: 16.3499
2023-09-21 22:47:13,034 - mmseg - INFO - Iter [2750/160000]	lr: 9.828e-05, eta: 1 day, 1:30:41, time: 0.530, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7859, decode.loss_mask: 0.3597, decode.loss_dice: 0.5504, decode.loss_ce_0: 1.7964, decode.loss_mask_0: 0.3617, decode.loss_dice_0: 0.5342, decode.loss_ce_1: 1.7671, decode.loss_mask_1: 0.3458, decode.loss_dice_1: 0.5332, decode.loss_ce_2: 1.7944, decode.loss_mask_2: 0.3733, decode.loss_dice_2: 0.5459, decode.loss_ce_3: 1.7978, decode.loss_mask_3: 0.3560, decode.loss_dice_3: 0.5434, decode.loss_ce_4: 1.7837, decode.loss_mask_4: 0.3704, decode.loss_dice_4: 0.5472, loss: 16.1466
2023-09-21 22:47:40,766 - mmseg - INFO - Iter [2800/160000]	lr: 9.825e-05, eta: 1 day, 1:28:49, time: 0.555, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7029, decode.loss_mask: 0.3397, decode.loss_dice: 0.4816, decode.loss_ce_0: 1.7453, decode.loss_mask_0: 0.3682, decode.loss_dice_0: 0.4975, decode.loss_ce_1: 1.7042, decode.loss_mask_1: 0.3358, decode.loss_dice_1: 0.4800, decode.loss_ce_2: 1.7257, decode.loss_mask_2: 0.3615, decode.loss_dice_2: 0.4910, decode.loss_ce_3: 1.7363, decode.loss_mask_3: 0.3277, decode.loss_dice_3: 0.4836, decode.loss_ce_4: 1.7213, decode.loss_mask_4: 0.3385, decode.loss_dice_4: 0.4852, loss: 15.3261
2023-09-21 22:48:07,962 - mmseg - INFO - Iter [2850/160000]	lr: 9.822e-05, eta: 1 day, 1:26:30, time: 0.544, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7934, decode.loss_mask: 0.3207, decode.loss_dice: 0.5138, decode.loss_ce_0: 1.8318, decode.loss_mask_0: 0.3395, decode.loss_dice_0: 0.5081, decode.loss_ce_1: 1.7887, decode.loss_mask_1: 0.3199, decode.loss_dice_1: 0.5095, decode.loss_ce_2: 1.8126, decode.loss_mask_2: 0.3204, decode.loss_dice_2: 0.5176, decode.loss_ce_3: 1.8194, decode.loss_mask_3: 0.3175, decode.loss_dice_3: 0.5033, decode.loss_ce_4: 1.8023, decode.loss_mask_4: 0.3328, decode.loss_dice_4: 0.5160, loss: 15.8675
2023-09-21 22:48:35,027 - mmseg - INFO - Iter [2900/160000]	lr: 9.819e-05, eta: 1 day, 1:24:09, time: 0.541, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8857, decode.loss_mask: 0.3284, decode.loss_dice: 0.5140, decode.loss_ce_0: 1.9825, decode.loss_mask_0: 0.3535, decode.loss_dice_0: 0.5263, decode.loss_ce_1: 1.9265, decode.loss_mask_1: 0.3425, decode.loss_dice_1: 0.5238, decode.loss_ce_2: 1.9864, decode.loss_mask_2: 0.3308, decode.loss_dice_2: 0.5185, decode.loss_ce_3: 1.9420, decode.loss_mask_3: 0.3322, decode.loss_dice_3: 0.5188, decode.loss_ce_4: 1.8981, decode.loss_mask_4: 0.3270, decode.loss_dice_4: 0.5245, loss: 16.7616
2023-09-21 22:49:02,240 - mmseg - INFO - Iter [2950/160000]	lr: 9.816e-05, eta: 1 day, 1:21:59, time: 0.544, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8446, decode.loss_mask: 0.3723, decode.loss_dice: 0.5491, decode.loss_ce_0: 1.8838, decode.loss_mask_0: 0.3604, decode.loss_dice_0: 0.5529, decode.loss_ce_1: 1.9170, decode.loss_mask_1: 0.3651, decode.loss_dice_1: 0.5430, decode.loss_ce_2: 1.9241, decode.loss_mask_2: 0.3586, decode.loss_dice_2: 0.5418, decode.loss_ce_3: 1.8914, decode.loss_mask_3: 0.3850, decode.loss_dice_3: 0.5555, decode.loss_ce_4: 1.8567, decode.loss_mask_4: 0.3375, decode.loss_dice_4: 0.5444, loss: 16.7834
2023-09-21 22:49:29,426 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 22:49:29,426 - mmseg - INFO - Iter [3000/160000]	lr: 9.813e-05, eta: 1 day, 1:19:51, time: 0.544, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8103, decode.loss_mask: 0.3581, decode.loss_dice: 0.5160, decode.loss_ce_0: 1.8176, decode.loss_mask_0: 0.3669, decode.loss_dice_0: 0.5253, decode.loss_ce_1: 1.7712, decode.loss_mask_1: 0.3583, decode.loss_dice_1: 0.5310, decode.loss_ce_2: 1.7867, decode.loss_mask_2: 0.3488, decode.loss_dice_2: 0.5278, decode.loss_ce_3: 1.8127, decode.loss_mask_3: 0.3392, decode.loss_dice_3: 0.5325, decode.loss_ce_4: 1.7811, decode.loss_mask_4: 0.3414, decode.loss_dice_4: 0.5193, loss: 16.0443
2023-09-21 22:49:56,898 - mmseg - INFO - Iter [3050/160000]	lr: 9.809e-05, eta: 1 day, 1:18:01, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7756, decode.loss_mask: 0.4339, decode.loss_dice: 0.5454, decode.loss_ce_0: 1.7809, decode.loss_mask_0: 0.3724, decode.loss_dice_0: 0.5350, decode.loss_ce_1: 1.7359, decode.loss_mask_1: 0.4311, decode.loss_dice_1: 0.5438, decode.loss_ce_2: 1.7938, decode.loss_mask_2: 0.3954, decode.loss_dice_2: 0.5393, decode.loss_ce_3: 1.7884, decode.loss_mask_3: 0.3974, decode.loss_dice_3: 0.5448, decode.loss_ce_4: 1.7414, decode.loss_mask_4: 0.4256, decode.loss_dice_4: 0.5578, loss: 16.3381
2023-09-21 22:50:24,031 - mmseg - INFO - Iter [3100/160000]	lr: 9.806e-05, eta: 1 day, 1:15:57, time: 0.543, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8376, decode.loss_mask: 0.3690, decode.loss_dice: 0.5293, decode.loss_ce_0: 1.7676, decode.loss_mask_0: 0.3607, decode.loss_dice_0: 0.5277, decode.loss_ce_1: 1.7685, decode.loss_mask_1: 0.4020, decode.loss_dice_1: 0.5423, decode.loss_ce_2: 1.7787, decode.loss_mask_2: 0.4544, decode.loss_dice_2: 0.5474, decode.loss_ce_3: 1.8479, decode.loss_mask_3: 0.3655, decode.loss_dice_3: 0.5249, decode.loss_ce_4: 1.7611, decode.loss_mask_4: 0.3567, decode.loss_dice_4: 0.5423, loss: 16.2836
2023-09-21 22:50:51,621 - mmseg - INFO - Iter [3150/160000]	lr: 9.803e-05, eta: 1 day, 1:14:18, time: 0.552, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7350, decode.loss_mask: 0.2724, decode.loss_dice: 0.5144, decode.loss_ce_0: 1.7395, decode.loss_mask_0: 0.2573, decode.loss_dice_0: 0.5060, decode.loss_ce_1: 1.7363, decode.loss_mask_1: 0.2797, decode.loss_dice_1: 0.5079, decode.loss_ce_2: 1.7239, decode.loss_mask_2: 0.2590, decode.loss_dice_2: 0.5062, decode.loss_ce_3: 1.7469, decode.loss_mask_3: 0.3113, decode.loss_dice_3: 0.5111, decode.loss_ce_4: 1.7168, decode.loss_mask_4: 0.2843, decode.loss_dice_4: 0.5216, loss: 15.1297
2023-09-21 22:51:18,825 - mmseg - INFO - Iter [3200/160000]	lr: 9.800e-05, eta: 1 day, 1:12:23, time: 0.544, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7435, decode.loss_mask: 0.3434, decode.loss_dice: 0.5338, decode.loss_ce_0: 1.7580, decode.loss_mask_0: 0.3308, decode.loss_dice_0: 0.5276, decode.loss_ce_1: 1.7182, decode.loss_mask_1: 0.3435, decode.loss_dice_1: 0.5406, decode.loss_ce_2: 1.7479, decode.loss_mask_2: 0.3608, decode.loss_dice_2: 0.5376, decode.loss_ce_3: 1.7804, decode.loss_mask_3: 0.3331, decode.loss_dice_3: 0.5202, decode.loss_ce_4: 1.7472, decode.loss_mask_4: 0.3365, decode.loss_dice_4: 0.5320, loss: 15.7350
2023-09-21 22:51:46,077 - mmseg - INFO - Iter [3250/160000]	lr: 9.797e-05, eta: 1 day, 1:10:33, time: 0.545, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7712, decode.loss_mask: 0.4495, decode.loss_dice: 0.5087, decode.loss_ce_0: 1.7633, decode.loss_mask_0: 0.3755, decode.loss_dice_0: 0.4981, decode.loss_ce_1: 1.6845, decode.loss_mask_1: 0.3415, decode.loss_dice_1: 0.5017, decode.loss_ce_2: 1.7316, decode.loss_mask_2: 0.3655, decode.loss_dice_2: 0.5040, decode.loss_ce_3: 1.7675, decode.loss_mask_3: 0.3873, decode.loss_dice_3: 0.5014, decode.loss_ce_4: 1.7544, decode.loss_mask_4: 0.3500, decode.loss_dice_4: 0.4952, loss: 15.7510
2023-09-21 22:52:13,504 - mmseg - INFO - Iter [3300/160000]	lr: 9.794e-05, eta: 1 day, 1:08:54, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8674, decode.loss_mask: 0.4205, decode.loss_dice: 0.5668, decode.loss_ce_0: 1.8898, decode.loss_mask_0: 0.3981, decode.loss_dice_0: 0.5486, decode.loss_ce_1: 1.9120, decode.loss_mask_1: 0.4125, decode.loss_dice_1: 0.5507, decode.loss_ce_2: 1.8554, decode.loss_mask_2: 0.4473, decode.loss_dice_2: 0.5730, decode.loss_ce_3: 1.8721, decode.loss_mask_3: 0.4079, decode.loss_dice_3: 0.5595, decode.loss_ce_4: 1.9131, decode.loss_mask_4: 0.4303, decode.loss_dice_4: 0.5543, loss: 17.1792
2023-09-21 22:52:39,983 - mmseg - INFO - Iter [3350/160000]	lr: 9.791e-05, eta: 1 day, 1:06:32, time: 0.530, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8129, decode.loss_mask: 0.3629, decode.loss_dice: 0.5555, decode.loss_ce_0: 1.7805, decode.loss_mask_0: 0.3777, decode.loss_dice_0: 0.5606, decode.loss_ce_1: 1.8506, decode.loss_mask_1: 0.3793, decode.loss_dice_1: 0.5517, decode.loss_ce_2: 1.8196, decode.loss_mask_2: 0.3728, decode.loss_dice_2: 0.5624, decode.loss_ce_3: 1.8150, decode.loss_mask_3: 0.3702, decode.loss_dice_3: 0.5648, decode.loss_ce_4: 1.7847, decode.loss_mask_4: 0.3766, decode.loss_dice_4: 0.5694, loss: 16.4673
2023-09-21 22:53:06,327 - mmseg - INFO - Iter [3400/160000]	lr: 9.788e-05, eta: 1 day, 1:04:08, time: 0.527, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7224, decode.loss_mask: 0.3828, decode.loss_dice: 0.5183, decode.loss_ce_0: 1.7487, decode.loss_mask_0: 0.3618, decode.loss_dice_0: 0.5107, decode.loss_ce_1: 1.7843, decode.loss_mask_1: 0.3650, decode.loss_dice_1: 0.5089, decode.loss_ce_2: 1.7186, decode.loss_mask_2: 0.3870, decode.loss_dice_2: 0.5320, decode.loss_ce_3: 1.7730, decode.loss_mask_3: 0.3792, decode.loss_dice_3: 0.5127, decode.loss_ce_4: 1.7604, decode.loss_mask_4: 0.3719, decode.loss_dice_4: 0.5129, loss: 15.8506
2023-09-21 22:53:32,646 - mmseg - INFO - Iter [3450/160000]	lr: 9.784e-05, eta: 1 day, 1:01:46, time: 0.526, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8510, decode.loss_mask: 0.3421, decode.loss_dice: 0.5360, decode.loss_ce_0: 1.9101, decode.loss_mask_0: 0.3286, decode.loss_dice_0: 0.5192, decode.loss_ce_1: 1.9046, decode.loss_mask_1: 0.3346, decode.loss_dice_1: 0.5203, decode.loss_ce_2: 1.8353, decode.loss_mask_2: 0.3479, decode.loss_dice_2: 0.5315, decode.loss_ce_3: 1.8834, decode.loss_mask_3: 0.3305, decode.loss_dice_3: 0.5243, decode.loss_ce_4: 1.8802, decode.loss_mask_4: 0.3301, decode.loss_dice_4: 0.5264, loss: 16.4361
2023-09-21 22:53:58,841 - mmseg - INFO - Iter [3500/160000]	lr: 9.781e-05, eta: 1 day, 0:59:21, time: 0.524, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7650, decode.loss_mask: 0.3537, decode.loss_dice: 0.5287, decode.loss_ce_0: 1.7851, decode.loss_mask_0: 0.4193, decode.loss_dice_0: 0.5292, decode.loss_ce_1: 1.7844, decode.loss_mask_1: 0.3430, decode.loss_dice_1: 0.5214, decode.loss_ce_2: 1.7910, decode.loss_mask_2: 0.4197, decode.loss_dice_2: 0.5339, decode.loss_ce_3: 1.7807, decode.loss_mask_3: 0.3573, decode.loss_dice_3: 0.5234, decode.loss_ce_4: 1.7828, decode.loss_mask_4: 0.3598, decode.loss_dice_4: 0.5217, loss: 16.1002
2023-09-21 22:54:26,372 - mmseg - INFO - Iter [3550/160000]	lr: 9.778e-05, eta: 1 day, 0:57:59, time: 0.551, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7868, decode.loss_mask: 0.3077, decode.loss_dice: 0.4800, decode.loss_ce_0: 1.7951, decode.loss_mask_0: 0.3171, decode.loss_dice_0: 0.4826, decode.loss_ce_1: 1.7875, decode.loss_mask_1: 0.3077, decode.loss_dice_1: 0.4859, decode.loss_ce_2: 1.7536, decode.loss_mask_2: 0.3193, decode.loss_dice_2: 0.5006, decode.loss_ce_3: 1.7895, decode.loss_mask_3: 0.3073, decode.loss_dice_3: 0.4898, decode.loss_ce_4: 1.7870, decode.loss_mask_4: 0.3064, decode.loss_dice_4: 0.4850, loss: 15.4889
2023-09-21 22:54:58,688 - mmseg - INFO - Iter [3600/160000]	lr: 9.775e-05, eta: 1 day, 1:00:06, time: 0.646, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7802, decode.loss_mask: 0.3531, decode.loss_dice: 0.5133, decode.loss_ce_0: 1.7701, decode.loss_mask_0: 0.3334, decode.loss_dice_0: 0.5051, decode.loss_ce_1: 1.7537, decode.loss_mask_1: 0.3789, decode.loss_dice_1: 0.5176, decode.loss_ce_2: 1.7810, decode.loss_mask_2: 0.3597, decode.loss_dice_2: 0.5174, decode.loss_ce_3: 1.7799, decode.loss_mask_3: 0.3626, decode.loss_dice_3: 0.5099, decode.loss_ce_4: 1.8097, decode.loss_mask_4: 0.3461, decode.loss_dice_4: 0.5054, loss: 15.8770
2023-09-21 22:55:34,799 - mmseg - INFO - Iter [3650/160000]	lr: 9.772e-05, eta: 1 day, 1:04:52, time: 0.722, data_time: 0.010, memory: 13718, decode.loss_ce: 1.9337, decode.loss_mask: 0.3014, decode.loss_dice: 0.5042, decode.loss_ce_0: 1.9444, decode.loss_mask_0: 0.3161, decode.loss_dice_0: 0.5116, decode.loss_ce_1: 1.8736, decode.loss_mask_1: 0.3287, decode.loss_dice_1: 0.5254, decode.loss_ce_2: 1.9425, decode.loss_mask_2: 0.3160, decode.loss_dice_2: 0.5115, decode.loss_ce_3: 1.9446, decode.loss_mask_3: 0.3062, decode.loss_dice_3: 0.5110, decode.loss_ce_4: 1.9512, decode.loss_mask_4: 0.3071, decode.loss_dice_4: 0.5005, loss: 16.5297
2023-09-21 22:56:12,251 - mmseg - INFO - Iter [3700/160000]	lr: 9.769e-05, eta: 1 day, 1:10:25, time: 0.749, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6383, decode.loss_mask: 0.2980, decode.loss_dice: 0.4608, decode.loss_ce_0: 1.6268, decode.loss_mask_0: 0.2968, decode.loss_dice_0: 0.4726, decode.loss_ce_1: 1.6709, decode.loss_mask_1: 0.3165, decode.loss_dice_1: 0.4732, decode.loss_ce_2: 1.6627, decode.loss_mask_2: 0.3035, decode.loss_dice_2: 0.4660, decode.loss_ce_3: 1.6681, decode.loss_mask_3: 0.3053, decode.loss_dice_3: 0.4595, decode.loss_ce_4: 1.6261, decode.loss_mask_4: 0.2992, decode.loss_dice_4: 0.4669, loss: 14.5112
2023-09-21 22:56:51,294 - mmseg - INFO - Iter [3750/160000]	lr: 9.766e-05, eta: 1 day, 1:16:55, time: 0.781, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8594, decode.loss_mask: 0.3345, decode.loss_dice: 0.4809, decode.loss_ce_0: 1.8677, decode.loss_mask_0: 0.3298, decode.loss_dice_0: 0.4861, decode.loss_ce_1: 1.8516, decode.loss_mask_1: 0.3232, decode.loss_dice_1: 0.4912, decode.loss_ce_2: 1.8564, decode.loss_mask_2: 0.3311, decode.loss_dice_2: 0.4917, decode.loss_ce_3: 1.8706, decode.loss_mask_3: 0.3290, decode.loss_dice_3: 0.4807, decode.loss_ce_4: 1.8565, decode.loss_mask_4: 0.3364, decode.loss_dice_4: 0.4823, loss: 16.0592
2023-09-21 22:57:30,154 - mmseg - INFO - Iter [3800/160000]	lr: 9.763e-05, eta: 1 day, 1:23:06, time: 0.777, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7628, decode.loss_mask: 0.3303, decode.loss_dice: 0.5199, decode.loss_ce_0: 1.8333, decode.loss_mask_0: 0.3801, decode.loss_dice_0: 0.5234, decode.loss_ce_1: 1.8166, decode.loss_mask_1: 0.3194, decode.loss_dice_1: 0.5092, decode.loss_ce_2: 1.8366, decode.loss_mask_2: 0.3113, decode.loss_dice_2: 0.5095, decode.loss_ce_3: 1.8319, decode.loss_mask_3: 0.3276, decode.loss_dice_3: 0.5102, decode.loss_ce_4: 1.8508, decode.loss_mask_4: 0.3241, decode.loss_dice_4: 0.5145, loss: 16.0113
2023-09-21 22:58:08,210 - mmseg - INFO - Iter [3850/160000]	lr: 9.759e-05, eta: 1 day, 1:28:34, time: 0.761, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6708, decode.loss_mask: 0.3168, decode.loss_dice: 0.4786, decode.loss_ce_0: 1.7120, decode.loss_mask_0: 0.3070, decode.loss_dice_0: 0.4688, decode.loss_ce_1: 1.7034, decode.loss_mask_1: 0.3396, decode.loss_dice_1: 0.4859, decode.loss_ce_2: 1.6908, decode.loss_mask_2: 0.3125, decode.loss_dice_2: 0.4674, decode.loss_ce_3: 1.7082, decode.loss_mask_3: 0.3186, decode.loss_dice_3: 0.4641, decode.loss_ce_4: 1.6914, decode.loss_mask_4: 0.3097, decode.loss_dice_4: 0.4677, loss: 14.9131
2023-09-21 22:58:46,717 - mmseg - INFO - Iter [3900/160000]	lr: 9.756e-05, eta: 1 day, 1:34:10, time: 0.770, data_time: 0.011, memory: 13718, decode.loss_ce: 1.5873, decode.loss_mask: 0.3949, decode.loss_dice: 0.4775, decode.loss_ce_0: 1.5981, decode.loss_mask_0: 0.3653, decode.loss_dice_0: 0.4735, decode.loss_ce_1: 1.5983, decode.loss_mask_1: 0.3616, decode.loss_dice_1: 0.4789, decode.loss_ce_2: 1.5902, decode.loss_mask_2: 0.3764, decode.loss_dice_2: 0.4844, decode.loss_ce_3: 1.6016, decode.loss_mask_3: 0.3583, decode.loss_dice_3: 0.4775, decode.loss_ce_4: 1.6114, decode.loss_mask_4: 0.3760, decode.loss_dice_4: 0.4729, loss: 14.6841
2023-09-21 22:59:24,636 - mmseg - INFO - Iter [3950/160000]	lr: 9.753e-05, eta: 1 day, 1:39:14, time: 0.758, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6730, decode.loss_mask: 0.3560, decode.loss_dice: 0.5139, decode.loss_ce_0: 1.7307, decode.loss_mask_0: 0.3527, decode.loss_dice_0: 0.4893, decode.loss_ce_1: 1.6979, decode.loss_mask_1: 0.3715, decode.loss_dice_1: 0.5083, decode.loss_ce_2: 1.7257, decode.loss_mask_2: 0.3586, decode.loss_dice_2: 0.5013, decode.loss_ce_3: 1.7069, decode.loss_mask_3: 0.3497, decode.loss_dice_3: 0.4994, decode.loss_ce_4: 1.7218, decode.loss_mask_4: 0.3880, decode.loss_dice_4: 0.5023, loss: 15.4469
2023-09-21 23:00:02,653 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-09-21 23:00:06,391 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:00:06,391 - mmseg - INFO - Iter [4000/160000]	lr: 9.750e-05, eta: 1 day, 1:46:39, time: 0.835, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8541, decode.loss_mask: 0.3147, decode.loss_dice: 0.5253, decode.loss_ce_0: 1.8721, decode.loss_mask_0: 0.3125, decode.loss_dice_0: 0.5246, decode.loss_ce_1: 1.8396, decode.loss_mask_1: 0.3140, decode.loss_dice_1: 0.5262, decode.loss_ce_2: 1.8296, decode.loss_mask_2: 0.3233, decode.loss_dice_2: 0.5264, decode.loss_ce_3: 1.8752, decode.loss_mask_3: 0.3039, decode.loss_dice_3: 0.5182, decode.loss_ce_4: 1.8202, decode.loss_mask_4: 0.2978, decode.loss_dice_4: 0.5246, loss: 16.1021
2023-09-21 23:00:44,345 - mmseg - INFO - Iter [4050/160000]	lr: 9.747e-05, eta: 1 day, 1:51:25, time: 0.759, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7494, decode.loss_mask: 0.2791, decode.loss_dice: 0.4597, decode.loss_ce_0: 1.7341, decode.loss_mask_0: 0.2771, decode.loss_dice_0: 0.4727, decode.loss_ce_1: 1.7622, decode.loss_mask_1: 0.3413, decode.loss_dice_1: 0.4801, decode.loss_ce_2: 1.7372, decode.loss_mask_2: 0.2881, decode.loss_dice_2: 0.4710, decode.loss_ce_3: 1.7602, decode.loss_mask_3: 0.3076, decode.loss_dice_3: 0.4693, decode.loss_ce_4: 1.7452, decode.loss_mask_4: 0.3243, decode.loss_dice_4: 0.4824, loss: 15.1412
2023-09-21 23:01:23,460 - mmseg - INFO - Iter [4100/160000]	lr: 9.744e-05, eta: 1 day, 1:56:48, time: 0.782, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7582, decode.loss_mask: 0.3712, decode.loss_dice: 0.5201, decode.loss_ce_0: 1.7988, decode.loss_mask_0: 0.3372, decode.loss_dice_0: 0.5147, decode.loss_ce_1: 1.7633, decode.loss_mask_1: 0.3558, decode.loss_dice_1: 0.5392, decode.loss_ce_2: 1.7890, decode.loss_mask_2: 0.3489, decode.loss_dice_2: 0.5390, decode.loss_ce_3: 1.7777, decode.loss_mask_3: 0.3409, decode.loss_dice_3: 0.5255, decode.loss_ce_4: 1.7650, decode.loss_mask_4: 0.3348, decode.loss_dice_4: 0.5154, loss: 15.8947
2023-09-21 23:02:00,713 - mmseg - INFO - Iter [4150/160000]	lr: 9.741e-05, eta: 1 day, 2:00:52, time: 0.745, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6717, decode.loss_mask: 0.3459, decode.loss_dice: 0.4968, decode.loss_ce_0: 1.7080, decode.loss_mask_0: 0.3474, decode.loss_dice_0: 0.4825, decode.loss_ce_1: 1.6901, decode.loss_mask_1: 0.3564, decode.loss_dice_1: 0.4933, decode.loss_ce_2: 1.7153, decode.loss_mask_2: 0.3656, decode.loss_dice_2: 0.4939, decode.loss_ce_3: 1.7144, decode.loss_mask_3: 0.3549, decode.loss_dice_3: 0.4884, decode.loss_ce_4: 1.6890, decode.loss_mask_4: 0.3348, decode.loss_dice_4: 0.4833, loss: 15.2318
2023-09-21 23:02:39,250 - mmseg - INFO - Iter [4200/160000]	lr: 9.738e-05, eta: 1 day, 2:05:37, time: 0.771, data_time: 0.066, memory: 13718, decode.loss_ce: 1.8739, decode.loss_mask: 0.3353, decode.loss_dice: 0.5451, decode.loss_ce_0: 1.9298, decode.loss_mask_0: 0.3305, decode.loss_dice_0: 0.5370, decode.loss_ce_1: 1.8809, decode.loss_mask_1: 0.3313, decode.loss_dice_1: 0.5409, decode.loss_ce_2: 1.9352, decode.loss_mask_2: 0.3384, decode.loss_dice_2: 0.5397, decode.loss_ce_3: 1.9169, decode.loss_mask_3: 0.3236, decode.loss_dice_3: 0.5341, decode.loss_ce_4: 1.9327, decode.loss_mask_4: 0.3378, decode.loss_dice_4: 0.5330, loss: 16.6960
2023-09-21 23:03:28,573 - mmseg - INFO - Iter [4250/160000]	lr: 9.734e-05, eta: 1 day, 2:16:49, time: 0.986, data_time: 0.296, memory: 13718, decode.loss_ce: 1.6818, decode.loss_mask: 0.2980, decode.loss_dice: 0.4999, decode.loss_ce_0: 1.7137, decode.loss_mask_0: 0.3158, decode.loss_dice_0: 0.5029, decode.loss_ce_1: 1.6786, decode.loss_mask_1: 0.2979, decode.loss_dice_1: 0.4984, decode.loss_ce_2: 1.6963, decode.loss_mask_2: 0.3132, decode.loss_dice_2: 0.5054, decode.loss_ce_3: 1.6907, decode.loss_mask_3: 0.3235, decode.loss_dice_3: 0.5035, decode.loss_ce_4: 1.7060, decode.loss_mask_4: 0.3136, decode.loss_dice_4: 0.5004, loss: 15.0395
2023-09-21 23:04:06,179 - mmseg - INFO - Iter [4300/160000]	lr: 9.731e-05, eta: 1 day, 2:20:41, time: 0.752, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8147, decode.loss_mask: 0.3894, decode.loss_dice: 0.4974, decode.loss_ce_0: 1.8025, decode.loss_mask_0: 0.3469, decode.loss_dice_0: 0.4887, decode.loss_ce_1: 1.8206, decode.loss_mask_1: 0.5276, decode.loss_dice_1: 0.5088, decode.loss_ce_2: 1.8347, decode.loss_mask_2: 0.3878, decode.loss_dice_2: 0.4909, decode.loss_ce_3: 1.8320, decode.loss_mask_3: 0.3461, decode.loss_dice_3: 0.4855, decode.loss_ce_4: 1.8137, decode.loss_mask_4: 0.3962, decode.loss_dice_4: 0.5002, loss: 16.2838
2023-09-21 23:04:39,659 - mmseg - INFO - Iter [4350/160000]	lr: 9.728e-05, eta: 1 day, 2:21:59, time: 0.670, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7947, decode.loss_mask: 0.3441, decode.loss_dice: 0.5192, decode.loss_ce_0: 1.8211, decode.loss_mask_0: 0.3092, decode.loss_dice_0: 0.5014, decode.loss_ce_1: 1.8316, decode.loss_mask_1: 0.3190, decode.loss_dice_1: 0.5057, decode.loss_ce_2: 1.8307, decode.loss_mask_2: 0.3183, decode.loss_dice_2: 0.4993, decode.loss_ce_3: 1.8004, decode.loss_mask_3: 0.3302, decode.loss_dice_3: 0.4998, decode.loss_ce_4: 1.8148, decode.loss_mask_4: 0.3287, decode.loss_dice_4: 0.5108, loss: 15.8789
2023-09-21 23:05:07,503 - mmseg - INFO - Iter [4400/160000]	lr: 9.725e-05, eta: 1 day, 2:19:54, time: 0.557, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6533, decode.loss_mask: 0.4303, decode.loss_dice: 0.5345, decode.loss_ce_0: 1.6979, decode.loss_mask_0: 0.3697, decode.loss_dice_0: 0.5192, decode.loss_ce_1: 1.7086, decode.loss_mask_1: 0.3902, decode.loss_dice_1: 0.5350, decode.loss_ce_2: 1.7149, decode.loss_mask_2: 0.4141, decode.loss_dice_2: 0.5417, decode.loss_ce_3: 1.7060, decode.loss_mask_3: 0.3973, decode.loss_dice_3: 0.5261, decode.loss_ce_4: 1.6880, decode.loss_mask_4: 0.4086, decode.loss_dice_4: 0.5190, loss: 15.7545
2023-09-21 23:05:34,947 - mmseg - INFO - Iter [4450/160000]	lr: 9.722e-05, eta: 1 day, 2:17:39, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7279, decode.loss_mask: 0.4004, decode.loss_dice: 0.5074, decode.loss_ce_0: 1.7521, decode.loss_mask_0: 0.4370, decode.loss_dice_0: 0.5164, decode.loss_ce_1: 1.7126, decode.loss_mask_1: 0.4394, decode.loss_dice_1: 0.5111, decode.loss_ce_2: 1.7433, decode.loss_mask_2: 0.4299, decode.loss_dice_2: 0.5084, decode.loss_ce_3: 1.7175, decode.loss_mask_3: 0.4196, decode.loss_dice_3: 0.5135, decode.loss_ce_4: 1.7614, decode.loss_mask_4: 0.4618, decode.loss_dice_4: 0.5055, loss: 16.0653
2023-09-21 23:06:02,801 - mmseg - INFO - Iter [4500/160000]	lr: 9.719e-05, eta: 1 day, 2:15:39, time: 0.557, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7498, decode.loss_mask: 0.3506, decode.loss_dice: 0.5069, decode.loss_ce_0: 1.7872, decode.loss_mask_0: 0.3300, decode.loss_dice_0: 0.4972, decode.loss_ce_1: 1.7545, decode.loss_mask_1: 0.3223, decode.loss_dice_1: 0.4987, decode.loss_ce_2: 1.7710, decode.loss_mask_2: 0.3190, decode.loss_dice_2: 0.5052, decode.loss_ce_3: 1.7633, decode.loss_mask_3: 0.3273, decode.loss_dice_3: 0.4990, decode.loss_ce_4: 1.7913, decode.loss_mask_4: 0.3583, decode.loss_dice_4: 0.5030, loss: 15.6346
2023-09-21 23:06:29,956 - mmseg - INFO - Iter [4550/160000]	lr: 9.716e-05, eta: 1 day, 2:13:18, time: 0.543, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6661, decode.loss_mask: 0.4459, decode.loss_dice: 0.5339, decode.loss_ce_0: 1.6728, decode.loss_mask_0: 0.4217, decode.loss_dice_0: 0.5245, decode.loss_ce_1: 1.6750, decode.loss_mask_1: 0.4541, decode.loss_dice_1: 0.5303, decode.loss_ce_2: 1.7082, decode.loss_mask_2: 0.4134, decode.loss_dice_2: 0.5246, decode.loss_ce_3: 1.7159, decode.loss_mask_3: 0.4317, decode.loss_dice_3: 0.5157, decode.loss_ce_4: 1.7037, decode.loss_mask_4: 0.4222, decode.loss_dice_4: 0.5196, loss: 15.8795
2023-09-21 23:06:56,754 - mmseg - INFO - Iter [4600/160000]	lr: 9.713e-05, eta: 1 day, 2:10:47, time: 0.536, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7651, decode.loss_mask: 0.3468, decode.loss_dice: 0.4927, decode.loss_ce_0: 1.7855, decode.loss_mask_0: 0.3098, decode.loss_dice_0: 0.4865, decode.loss_ce_1: 1.7671, decode.loss_mask_1: 0.3202, decode.loss_dice_1: 0.4995, decode.loss_ce_2: 1.7924, decode.loss_mask_2: 0.3348, decode.loss_dice_2: 0.4911, decode.loss_ce_3: 1.7961, decode.loss_mask_3: 0.3415, decode.loss_dice_3: 0.4936, decode.loss_ce_4: 1.7871, decode.loss_mask_4: 0.3349, decode.loss_dice_4: 0.4851, loss: 15.6298
2023-09-21 23:07:23,068 - mmseg - INFO - Iter [4650/160000]	lr: 9.709e-05, eta: 1 day, 2:08:03, time: 0.526, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6949, decode.loss_mask: 0.3720, decode.loss_dice: 0.4930, decode.loss_ce_0: 1.7072, decode.loss_mask_0: 0.3299, decode.loss_dice_0: 0.4856, decode.loss_ce_1: 1.7042, decode.loss_mask_1: 0.3493, decode.loss_dice_1: 0.4904, decode.loss_ce_2: 1.7276, decode.loss_mask_2: 0.3716, decode.loss_dice_2: 0.4950, decode.loss_ce_3: 1.7390, decode.loss_mask_3: 0.3331, decode.loss_dice_3: 0.4830, decode.loss_ce_4: 1.6922, decode.loss_mask_4: 0.3383, decode.loss_dice_4: 0.4772, loss: 15.2836
2023-09-21 23:07:49,836 - mmseg - INFO - Iter [4700/160000]	lr: 9.706e-05, eta: 1 day, 2:05:36, time: 0.535, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7762, decode.loss_mask: 0.2696, decode.loss_dice: 0.4981, decode.loss_ce_0: 1.7677, decode.loss_mask_0: 0.2892, decode.loss_dice_0: 0.4952, decode.loss_ce_1: 1.7753, decode.loss_mask_1: 0.2999, decode.loss_dice_1: 0.4958, decode.loss_ce_2: 1.7598, decode.loss_mask_2: 0.2897, decode.loss_dice_2: 0.4937, decode.loss_ce_3: 1.7515, decode.loss_mask_3: 0.2983, decode.loss_dice_3: 0.5117, decode.loss_ce_4: 1.7729, decode.loss_mask_4: 0.2855, decode.loss_dice_4: 0.4873, loss: 15.3174
2023-09-21 23:08:16,592 - mmseg - INFO - Iter [4750/160000]	lr: 9.703e-05, eta: 1 day, 2:03:12, time: 0.535, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6177, decode.loss_mask: 0.3654, decode.loss_dice: 0.4651, decode.loss_ce_0: 1.6277, decode.loss_mask_0: 0.3481, decode.loss_dice_0: 0.4598, decode.loss_ce_1: 1.5803, decode.loss_mask_1: 0.3591, decode.loss_dice_1: 0.4811, decode.loss_ce_2: 1.6038, decode.loss_mask_2: 0.3697, decode.loss_dice_2: 0.4748, decode.loss_ce_3: 1.5936, decode.loss_mask_3: 0.4026, decode.loss_dice_3: 0.4757, decode.loss_ce_4: 1.6137, decode.loss_mask_4: 0.3808, decode.loss_dice_4: 0.4706, loss: 14.6896
2023-09-21 23:08:43,980 - mmseg - INFO - Iter [4800/160000]	lr: 9.700e-05, eta: 1 day, 2:01:11, time: 0.548, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7452, decode.loss_mask: 0.3027, decode.loss_dice: 0.4859, decode.loss_ce_0: 1.7559, decode.loss_mask_0: 0.3173, decode.loss_dice_0: 0.4835, decode.loss_ce_1: 1.7599, decode.loss_mask_1: 0.2912, decode.loss_dice_1: 0.4838, decode.loss_ce_2: 1.7691, decode.loss_mask_2: 0.2943, decode.loss_dice_2: 0.4870, decode.loss_ce_3: 1.7655, decode.loss_mask_3: 0.2956, decode.loss_dice_3: 0.4842, decode.loss_ce_4: 1.7583, decode.loss_mask_4: 0.2819, decode.loss_dice_4: 0.4812, loss: 15.2424
2023-09-21 23:09:11,324 - mmseg - INFO - Iter [4850/160000]	lr: 9.697e-05, eta: 1 day, 1:59:10, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8148, decode.loss_mask: 0.3025, decode.loss_dice: 0.4783, decode.loss_ce_0: 1.8198, decode.loss_mask_0: 0.2961, decode.loss_dice_0: 0.4748, decode.loss_ce_1: 1.7663, decode.loss_mask_1: 0.2699, decode.loss_dice_1: 0.4728, decode.loss_ce_2: 1.7935, decode.loss_mask_2: 0.2656, decode.loss_dice_2: 0.4705, decode.loss_ce_3: 1.8234, decode.loss_mask_3: 0.3041, decode.loss_dice_3: 0.4776, decode.loss_ce_4: 1.8155, decode.loss_mask_4: 0.2910, decode.loss_dice_4: 0.4780, loss: 15.4144
2023-09-21 23:09:38,629 - mmseg - INFO - Iter [4900/160000]	lr: 9.694e-05, eta: 1 day, 1:57:10, time: 0.546, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6643, decode.loss_mask: 0.3907, decode.loss_dice: 0.5003, decode.loss_ce_0: 1.6549, decode.loss_mask_0: 0.3896, decode.loss_dice_0: 0.5042, decode.loss_ce_1: 1.6623, decode.loss_mask_1: 0.4163, decode.loss_dice_1: 0.5125, decode.loss_ce_2: 1.6560, decode.loss_mask_2: 0.3711, decode.loss_dice_2: 0.5000, decode.loss_ce_3: 1.6648, decode.loss_mask_3: 0.3902, decode.loss_dice_3: 0.5030, decode.loss_ce_4: 1.6684, decode.loss_mask_4: 0.4033, decode.loss_dice_4: 0.4975, loss: 15.3494
2023-09-21 23:10:05,658 - mmseg - INFO - Iter [4950/160000]	lr: 9.691e-05, eta: 1 day, 1:55:03, time: 0.541, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7061, decode.loss_mask: 0.3784, decode.loss_dice: 0.5322, decode.loss_ce_0: 1.6555, decode.loss_mask_0: 0.3553, decode.loss_dice_0: 0.5149, decode.loss_ce_1: 1.6595, decode.loss_mask_1: 0.3451, decode.loss_dice_1: 0.5144, decode.loss_ce_2: 1.6674, decode.loss_mask_2: 0.3430, decode.loss_dice_2: 0.5107, decode.loss_ce_3: 1.6925, decode.loss_mask_3: 0.4017, decode.loss_dice_3: 0.5274, decode.loss_ce_4: 1.7006, decode.loss_mask_4: 0.3711, decode.loss_dice_4: 0.5228, loss: 15.3984
2023-09-21 23:10:32,957 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:10:32,957 - mmseg - INFO - Iter [5000/160000]	lr: 9.688e-05, eta: 1 day, 1:53:06, time: 0.546, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8256, decode.loss_mask: 0.4023, decode.loss_dice: 0.5289, decode.loss_ce_0: 1.7822, decode.loss_mask_0: 0.3945, decode.loss_dice_0: 0.5259, decode.loss_ce_1: 1.7693, decode.loss_mask_1: 0.3919, decode.loss_dice_1: 0.5260, decode.loss_ce_2: 1.8159, decode.loss_mask_2: 0.4121, decode.loss_dice_2: 0.5191, decode.loss_ce_3: 1.8028, decode.loss_mask_3: 0.3809, decode.loss_dice_3: 0.5279, decode.loss_ce_4: 1.7915, decode.loss_mask_4: 0.4030, decode.loss_dice_4: 0.5200, loss: 16.3199
2023-09-21 23:11:00,373 - mmseg - INFO - Iter [5050/160000]	lr: 9.684e-05, eta: 1 day, 1:51:15, time: 0.548, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7191, decode.loss_mask: 0.3940, decode.loss_dice: 0.5145, decode.loss_ce_0: 1.7281, decode.loss_mask_0: 0.4038, decode.loss_dice_0: 0.5214, decode.loss_ce_1: 1.7431, decode.loss_mask_1: 0.4298, decode.loss_dice_1: 0.5319, decode.loss_ce_2: 1.8034, decode.loss_mask_2: 0.4217, decode.loss_dice_2: 0.5284, decode.loss_ce_3: 1.7317, decode.loss_mask_3: 0.3996, decode.loss_dice_3: 0.5234, decode.loss_ce_4: 1.7267, decode.loss_mask_4: 0.4305, decode.loss_dice_4: 0.5243, loss: 16.0755
2023-09-21 23:11:27,834 - mmseg - INFO - Iter [5100/160000]	lr: 9.681e-05, eta: 1 day, 1:49:27, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7236, decode.loss_mask: 0.3398, decode.loss_dice: 0.5011, decode.loss_ce_0: 1.7065, decode.loss_mask_0: 0.3498, decode.loss_dice_0: 0.5036, decode.loss_ce_1: 1.6884, decode.loss_mask_1: 0.3522, decode.loss_dice_1: 0.5097, decode.loss_ce_2: 1.7356, decode.loss_mask_2: 0.3392, decode.loss_dice_2: 0.5019, decode.loss_ce_3: 1.7246, decode.loss_mask_3: 0.3329, decode.loss_dice_3: 0.4998, decode.loss_ce_4: 1.7494, decode.loss_mask_4: 0.3399, decode.loss_dice_4: 0.4954, loss: 15.3931
2023-09-21 23:11:55,616 - mmseg - INFO - Iter [5150/160000]	lr: 9.678e-05, eta: 1 day, 1:47:50, time: 0.556, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8101, decode.loss_mask: 0.3532, decode.loss_dice: 0.5359, decode.loss_ce_0: 1.8509, decode.loss_mask_0: 0.3629, decode.loss_dice_0: 0.5296, decode.loss_ce_1: 1.8157, decode.loss_mask_1: 0.3651, decode.loss_dice_1: 0.5449, decode.loss_ce_2: 1.8648, decode.loss_mask_2: 0.3477, decode.loss_dice_2: 0.5340, decode.loss_ce_3: 1.8211, decode.loss_mask_3: 0.3695, decode.loss_dice_3: 0.5406, decode.loss_ce_4: 1.8403, decode.loss_mask_4: 0.3405, decode.loss_dice_4: 0.5248, loss: 16.3515
2023-09-21 23:12:23,131 - mmseg - INFO - Iter [5200/160000]	lr: 9.675e-05, eta: 1 day, 1:46:06, time: 0.550, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7313, decode.loss_mask: 0.3214, decode.loss_dice: 0.5094, decode.loss_ce_0: 1.7390, decode.loss_mask_0: 0.3323, decode.loss_dice_0: 0.5097, decode.loss_ce_1: 1.7309, decode.loss_mask_1: 0.3416, decode.loss_dice_1: 0.5183, decode.loss_ce_2: 1.7674, decode.loss_mask_2: 0.3254, decode.loss_dice_2: 0.5075, decode.loss_ce_3: 1.7451, decode.loss_mask_3: 0.3200, decode.loss_dice_3: 0.5150, decode.loss_ce_4: 1.7583, decode.loss_mask_4: 0.3235, decode.loss_dice_4: 0.5051, loss: 15.5012
2023-09-21 23:12:49,583 - mmseg - INFO - Iter [5250/160000]	lr: 9.672e-05, eta: 1 day, 1:43:53, time: 0.529, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6930, decode.loss_mask: 0.3836, decode.loss_dice: 0.4898, decode.loss_ce_0: 1.6851, decode.loss_mask_0: 0.3769, decode.loss_dice_0: 0.4867, decode.loss_ce_1: 1.6575, decode.loss_mask_1: 0.3880, decode.loss_dice_1: 0.5047, decode.loss_ce_2: 1.6795, decode.loss_mask_2: 0.3847, decode.loss_dice_2: 0.4884, decode.loss_ce_3: 1.7011, decode.loss_mask_3: 0.4165, decode.loss_dice_3: 0.4951, decode.loss_ce_4: 1.7024, decode.loss_mask_4: 0.4019, decode.loss_dice_4: 0.4903, loss: 15.4252
2023-09-21 23:13:16,376 - mmseg - INFO - Iter [5300/160000]	lr: 9.669e-05, eta: 1 day, 1:41:51, time: 0.536, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8528, decode.loss_mask: 0.3968, decode.loss_dice: 0.5484, decode.loss_ce_0: 1.8622, decode.loss_mask_0: 0.4118, decode.loss_dice_0: 0.5386, decode.loss_ce_1: 1.8357, decode.loss_mask_1: 0.4006, decode.loss_dice_1: 0.5481, decode.loss_ce_2: 1.8609, decode.loss_mask_2: 0.4061, decode.loss_dice_2: 0.5455, decode.loss_ce_3: 1.8908, decode.loss_mask_3: 0.3964, decode.loss_dice_3: 0.5525, decode.loss_ce_4: 1.8541, decode.loss_mask_4: 0.4212, decode.loss_dice_4: 0.5460, loss: 16.8685
2023-09-21 23:13:42,826 - mmseg - INFO - Iter [5350/160000]	lr: 9.666e-05, eta: 1 day, 1:39:42, time: 0.529, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7472, decode.loss_mask: 0.3226, decode.loss_dice: 0.5128, decode.loss_ce_0: 1.7399, decode.loss_mask_0: 0.3233, decode.loss_dice_0: 0.5096, decode.loss_ce_1: 1.7638, decode.loss_mask_1: 0.3330, decode.loss_dice_1: 0.5247, decode.loss_ce_2: 1.7351, decode.loss_mask_2: 0.3333, decode.loss_dice_2: 0.5124, decode.loss_ce_3: 1.7770, decode.loss_mask_3: 0.3348, decode.loss_dice_3: 0.5198, decode.loss_ce_4: 1.7622, decode.loss_mask_4: 0.3459, decode.loss_dice_4: 0.5070, loss: 15.6045
2023-09-21 23:14:09,424 - mmseg - INFO - Iter [5400/160000]	lr: 9.663e-05, eta: 1 day, 1:37:38, time: 0.532, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6725, decode.loss_mask: 0.3300, decode.loss_dice: 0.4809, decode.loss_ce_0: 1.6589, decode.loss_mask_0: 0.3414, decode.loss_dice_0: 0.4804, decode.loss_ce_1: 1.6585, decode.loss_mask_1: 0.3285, decode.loss_dice_1: 0.4924, decode.loss_ce_2: 1.6846, decode.loss_mask_2: 0.3339, decode.loss_dice_2: 0.4872, decode.loss_ce_3: 1.7248, decode.loss_mask_3: 0.3486, decode.loss_dice_3: 0.4859, decode.loss_ce_4: 1.6925, decode.loss_mask_4: 0.3388, decode.loss_dice_4: 0.4702, loss: 15.0100
2023-09-21 23:14:35,923 - mmseg - INFO - Iter [5450/160000]	lr: 9.659e-05, eta: 1 day, 1:35:34, time: 0.530, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7158, decode.loss_mask: 0.3381, decode.loss_dice: 0.4851, decode.loss_ce_0: 1.7385, decode.loss_mask_0: 0.3721, decode.loss_dice_0: 0.4890, decode.loss_ce_1: 1.7266, decode.loss_mask_1: 0.4040, decode.loss_dice_1: 0.5020, decode.loss_ce_2: 1.7051, decode.loss_mask_2: 0.3423, decode.loss_dice_2: 0.4852, decode.loss_ce_3: 1.7450, decode.loss_mask_3: 0.3556, decode.loss_dice_3: 0.4894, decode.loss_ce_4: 1.6996, decode.loss_mask_4: 0.3427, decode.loss_dice_4: 0.4903, loss: 15.4266
2023-09-21 23:15:02,434 - mmseg - INFO - Iter [5500/160000]	lr: 9.656e-05, eta: 1 day, 1:33:31, time: 0.530, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7917, decode.loss_mask: 0.3234, decode.loss_dice: 0.5380, decode.loss_ce_0: 1.7895, decode.loss_mask_0: 0.3211, decode.loss_dice_0: 0.5371, decode.loss_ce_1: 1.7739, decode.loss_mask_1: 0.3492, decode.loss_dice_1: 0.5514, decode.loss_ce_2: 1.7812, decode.loss_mask_2: 0.3461, decode.loss_dice_2: 0.5447, decode.loss_ce_3: 1.8124, decode.loss_mask_3: 0.3362, decode.loss_dice_3: 0.5496, decode.loss_ce_4: 1.7731, decode.loss_mask_4: 0.3448, decode.loss_dice_4: 0.5442, loss: 16.0076
2023-09-21 23:15:29,942 - mmseg - INFO - Iter [5550/160000]	lr: 9.653e-05, eta: 1 day, 1:31:58, time: 0.550, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7828, decode.loss_mask: 0.3132, decode.loss_dice: 0.5089, decode.loss_ce_0: 1.7578, decode.loss_mask_0: 0.3274, decode.loss_dice_0: 0.5195, decode.loss_ce_1: 1.8102, decode.loss_mask_1: 0.3343, decode.loss_dice_1: 0.5217, decode.loss_ce_2: 1.8042, decode.loss_mask_2: 0.3401, decode.loss_dice_2: 0.5224, decode.loss_ce_3: 1.7896, decode.loss_mask_3: 0.3192, decode.loss_dice_3: 0.5197, decode.loss_ce_4: 1.8317, decode.loss_mask_4: 0.3446, decode.loss_dice_4: 0.5115, loss: 15.8588
2023-09-21 23:15:56,691 - mmseg - INFO - Iter [5600/160000]	lr: 9.650e-05, eta: 1 day, 1:30:06, time: 0.535, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7545, decode.loss_mask: 0.3496, decode.loss_dice: 0.4997, decode.loss_ce_0: 1.7452, decode.loss_mask_0: 0.3603, decode.loss_dice_0: 0.5071, decode.loss_ce_1: 1.7579, decode.loss_mask_1: 0.3601, decode.loss_dice_1: 0.5053, decode.loss_ce_2: 1.8010, decode.loss_mask_2: 0.3675, decode.loss_dice_2: 0.5042, decode.loss_ce_3: 1.7664, decode.loss_mask_3: 0.3726, decode.loss_dice_3: 0.5087, decode.loss_ce_4: 1.7786, decode.loss_mask_4: 0.4104, decode.loss_dice_4: 0.5078, loss: 15.8569
2023-09-21 23:16:23,802 - mmseg - INFO - Iter [5650/160000]	lr: 9.647e-05, eta: 1 day, 1:28:24, time: 0.542, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8195, decode.loss_mask: 0.3733, decode.loss_dice: 0.5161, decode.loss_ce_0: 1.8004, decode.loss_mask_0: 0.3673, decode.loss_dice_0: 0.5185, decode.loss_ce_1: 1.8217, decode.loss_mask_1: 0.3635, decode.loss_dice_1: 0.5209, decode.loss_ce_2: 1.8280, decode.loss_mask_2: 0.3656, decode.loss_dice_2: 0.5160, decode.loss_ce_3: 1.8229, decode.loss_mask_3: 0.3648, decode.loss_dice_3: 0.5185, decode.loss_ce_4: 1.8062, decode.loss_mask_4: 0.3742, decode.loss_dice_4: 0.5234, loss: 16.2209
2023-09-21 23:16:51,360 - mmseg - INFO - Iter [5700/160000]	lr: 9.644e-05, eta: 1 day, 1:26:56, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8715, decode.loss_mask: 0.3167, decode.loss_dice: 0.5052, decode.loss_ce_0: 1.8920, decode.loss_mask_0: 0.3184, decode.loss_dice_0: 0.5088, decode.loss_ce_1: 1.8412, decode.loss_mask_1: 0.3212, decode.loss_dice_1: 0.5152, decode.loss_ce_2: 1.8589, decode.loss_mask_2: 0.3171, decode.loss_dice_2: 0.5156, decode.loss_ce_3: 1.8649, decode.loss_mask_3: 0.3139, decode.loss_dice_3: 0.5100, decode.loss_ce_4: 1.8803, decode.loss_mask_4: 0.3462, decode.loss_dice_4: 0.5173, loss: 16.2146
2023-09-21 23:17:18,913 - mmseg - INFO - Iter [5750/160000]	lr: 9.641e-05, eta: 1 day, 1:25:29, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.9095, decode.loss_mask: 0.2920, decode.loss_dice: 0.5333, decode.loss_ce_0: 1.8831, decode.loss_mask_0: 0.2941, decode.loss_dice_0: 0.5343, decode.loss_ce_1: 1.8848, decode.loss_mask_1: 0.3106, decode.loss_dice_1: 0.5453, decode.loss_ce_2: 1.9005, decode.loss_mask_2: 0.2917, decode.loss_dice_2: 0.5309, decode.loss_ce_3: 1.8850, decode.loss_mask_3: 0.3051, decode.loss_dice_3: 0.5308, decode.loss_ce_4: 1.9061, decode.loss_mask_4: 0.3167, decode.loss_dice_4: 0.5375, loss: 16.3915
2023-09-21 23:17:45,732 - mmseg - INFO - Iter [5800/160000]	lr: 9.638e-05, eta: 1 day, 1:23:44, time: 0.536, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7453, decode.loss_mask: 0.3734, decode.loss_dice: 0.4848, decode.loss_ce_0: 1.7435, decode.loss_mask_0: 0.3502, decode.loss_dice_0: 0.4859, decode.loss_ce_1: 1.7266, decode.loss_mask_1: 0.3521, decode.loss_dice_1: 0.4893, decode.loss_ce_2: 1.7636, decode.loss_mask_2: 0.3582, decode.loss_dice_2: 0.4760, decode.loss_ce_3: 1.7533, decode.loss_mask_3: 0.3495, decode.loss_dice_3: 0.4743, decode.loss_ce_4: 1.7798, decode.loss_mask_4: 0.3558, decode.loss_dice_4: 0.4740, loss: 15.5358
2023-09-21 23:18:13,063 - mmseg - INFO - Iter [5850/160000]	lr: 9.634e-05, eta: 1 day, 1:22:13, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6814, decode.loss_mask: 0.3212, decode.loss_dice: 0.4677, decode.loss_ce_0: 1.6750, decode.loss_mask_0: 0.3245, decode.loss_dice_0: 0.4722, decode.loss_ce_1: 1.6707, decode.loss_mask_1: 0.3024, decode.loss_dice_1: 0.4575, decode.loss_ce_2: 1.6826, decode.loss_mask_2: 0.3298, decode.loss_dice_2: 0.4655, decode.loss_ce_3: 1.6922, decode.loss_mask_3: 0.3402, decode.loss_dice_3: 0.4729, decode.loss_ce_4: 1.6942, decode.loss_mask_4: 0.3284, decode.loss_dice_4: 0.4662, loss: 14.8444
2023-09-21 23:18:40,959 - mmseg - INFO - Iter [5900/160000]	lr: 9.631e-05, eta: 1 day, 1:20:59, time: 0.558, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7734, decode.loss_mask: 0.2833, decode.loss_dice: 0.4747, decode.loss_ce_0: 1.7593, decode.loss_mask_0: 0.2884, decode.loss_dice_0: 0.4764, decode.loss_ce_1: 1.7648, decode.loss_mask_1: 0.2774, decode.loss_dice_1: 0.4758, decode.loss_ce_2: 1.7522, decode.loss_mask_2: 0.2821, decode.loss_dice_2: 0.4807, decode.loss_ce_3: 1.8014, decode.loss_mask_3: 0.2978, decode.loss_dice_3: 0.4913, decode.loss_ce_4: 1.7943, decode.loss_mask_4: 0.2819, decode.loss_dice_4: 0.4711, loss: 15.2263
2023-09-21 23:19:08,234 - mmseg - INFO - Iter [5950/160000]	lr: 9.628e-05, eta: 1 day, 1:19:28, time: 0.545, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7063, decode.loss_mask: 0.3293, decode.loss_dice: 0.4557, decode.loss_ce_0: 1.6993, decode.loss_mask_0: 0.3271, decode.loss_dice_0: 0.4592, decode.loss_ce_1: 1.7227, decode.loss_mask_1: 0.3367, decode.loss_dice_1: 0.4563, decode.loss_ce_2: 1.7004, decode.loss_mask_2: 0.3272, decode.loss_dice_2: 0.4668, decode.loss_ce_3: 1.7134, decode.loss_mask_3: 0.3330, decode.loss_dice_3: 0.4620, decode.loss_ce_4: 1.7345, decode.loss_mask_4: 0.3719, decode.loss_dice_4: 0.4626, loss: 15.0644
2023-09-21 23:19:35,434 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:19:35,435 - mmseg - INFO - Iter [6000/160000]	lr: 9.625e-05, eta: 1 day, 1:17:58, time: 0.544, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7210, decode.loss_mask: 0.3232, decode.loss_dice: 0.4913, decode.loss_ce_0: 1.7183, decode.loss_mask_0: 0.3187, decode.loss_dice_0: 0.4938, decode.loss_ce_1: 1.6871, decode.loss_mask_1: 0.3039, decode.loss_dice_1: 0.5014, decode.loss_ce_2: 1.7469, decode.loss_mask_2: 0.3111, decode.loss_dice_2: 0.4911, decode.loss_ce_3: 1.7438, decode.loss_mask_3: 0.3517, decode.loss_dice_3: 0.4931, decode.loss_ce_4: 1.7568, decode.loss_mask_4: 0.3443, decode.loss_dice_4: 0.5167, loss: 15.3143
2023-09-21 23:20:02,272 - mmseg - INFO - Iter [6050/160000]	lr: 9.622e-05, eta: 1 day, 1:16:18, time: 0.537, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6152, decode.loss_mask: 0.3431, decode.loss_dice: 0.4718, decode.loss_ce_0: 1.6242, decode.loss_mask_0: 0.3587, decode.loss_dice_0: 0.4573, decode.loss_ce_1: 1.6657, decode.loss_mask_1: 0.3800, decode.loss_dice_1: 0.4579, decode.loss_ce_2: 1.6395, decode.loss_mask_2: 0.3524, decode.loss_dice_2: 0.4615, decode.loss_ce_3: 1.6341, decode.loss_mask_3: 0.3457, decode.loss_dice_3: 0.4700, decode.loss_ce_4: 1.6026, decode.loss_mask_4: 0.3452, decode.loss_dice_4: 0.4778, loss: 14.7029
2023-09-21 23:20:38,685 - mmseg - INFO - Iter [6100/160000]	lr: 9.619e-05, eta: 1 day, 1:18:42, time: 0.728, data_time: 0.218, memory: 13718, decode.loss_ce: 1.7660, decode.loss_mask: 0.3033, decode.loss_dice: 0.4946, decode.loss_ce_0: 1.7862, decode.loss_mask_0: 0.3203, decode.loss_dice_0: 0.5019, decode.loss_ce_1: 1.7592, decode.loss_mask_1: 0.3165, decode.loss_dice_1: 0.4984, decode.loss_ce_2: 1.7894, decode.loss_mask_2: 0.3065, decode.loss_dice_2: 0.4916, decode.loss_ce_3: 1.7953, decode.loss_mask_3: 0.3041, decode.loss_dice_3: 0.4984, decode.loss_ce_4: 1.8030, decode.loss_mask_4: 0.3139, decode.loss_dice_4: 0.4895, loss: 15.5381
2023-09-21 23:21:12,994 - mmseg - INFO - Iter [6150/160000]	lr: 9.616e-05, eta: 1 day, 1:20:10, time: 0.686, data_time: 0.172, memory: 13718, decode.loss_ce: 1.7181, decode.loss_mask: 0.3752, decode.loss_dice: 0.4841, decode.loss_ce_0: 1.7147, decode.loss_mask_0: 0.3422, decode.loss_dice_0: 0.4764, decode.loss_ce_1: 1.6921, decode.loss_mask_1: 0.3491, decode.loss_dice_1: 0.4833, decode.loss_ce_2: 1.7133, decode.loss_mask_2: 0.3715, decode.loss_dice_2: 0.4793, decode.loss_ce_3: 1.7203, decode.loss_mask_3: 0.3550, decode.loss_dice_3: 0.4722, decode.loss_ce_4: 1.7044, decode.loss_mask_4: 0.3759, decode.loss_dice_4: 0.4768, loss: 15.3037
2023-09-21 23:21:39,700 - mmseg - INFO - Iter [6200/160000]	lr: 9.613e-05, eta: 1 day, 1:18:28, time: 0.534, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8111, decode.loss_mask: 0.2851, decode.loss_dice: 0.5264, decode.loss_ce_0: 1.7827, decode.loss_mask_0: 0.2918, decode.loss_dice_0: 0.5339, decode.loss_ce_1: 1.7862, decode.loss_mask_1: 0.2920, decode.loss_dice_1: 0.5321, decode.loss_ce_2: 1.8193, decode.loss_mask_2: 0.2997, decode.loss_dice_2: 0.5297, decode.loss_ce_3: 1.8263, decode.loss_mask_3: 0.2792, decode.loss_dice_3: 0.5147, decode.loss_ce_4: 1.8127, decode.loss_mask_4: 0.2770, decode.loss_dice_4: 0.5195, loss: 15.7194
2023-09-21 23:22:05,692 - mmseg - INFO - Iter [6250/160000]	lr: 9.609e-05, eta: 1 day, 1:16:29, time: 0.520, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6932, decode.loss_mask: 0.3050, decode.loss_dice: 0.4682, decode.loss_ce_0: 1.7107, decode.loss_mask_0: 0.3211, decode.loss_dice_0: 0.4699, decode.loss_ce_1: 1.6941, decode.loss_mask_1: 0.3120, decode.loss_dice_1: 0.4813, decode.loss_ce_2: 1.7086, decode.loss_mask_2: 0.3021, decode.loss_dice_2: 0.4713, decode.loss_ce_3: 1.7170, decode.loss_mask_3: 0.3034, decode.loss_dice_3: 0.4680, decode.loss_ce_4: 1.7229, decode.loss_mask_4: 0.3265, decode.loss_dice_4: 0.4806, loss: 14.9559
2023-09-21 23:22:31,677 - mmseg - INFO - Iter [6300/160000]	lr: 9.606e-05, eta: 1 day, 1:14:31, time: 0.520, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6675, decode.loss_mask: 0.2835, decode.loss_dice: 0.4427, decode.loss_ce_0: 1.6821, decode.loss_mask_0: 0.2725, decode.loss_dice_0: 0.4476, decode.loss_ce_1: 1.6653, decode.loss_mask_1: 0.2864, decode.loss_dice_1: 0.4568, decode.loss_ce_2: 1.6724, decode.loss_mask_2: 0.2792, decode.loss_dice_2: 0.4412, decode.loss_ce_3: 1.6954, decode.loss_mask_3: 0.2816, decode.loss_dice_3: 0.4417, decode.loss_ce_4: 1.6558, decode.loss_mask_4: 0.2899, decode.loss_dice_4: 0.4480, loss: 14.4095
2023-09-21 23:22:59,222 - mmseg - INFO - Iter [6350/160000]	lr: 9.603e-05, eta: 1 day, 1:13:13, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.5664, decode.loss_mask: 0.3316, decode.loss_dice: 0.4559, decode.loss_ce_0: 1.5917, decode.loss_mask_0: 0.3294, decode.loss_dice_0: 0.4537, decode.loss_ce_1: 1.5658, decode.loss_mask_1: 0.3176, decode.loss_dice_1: 0.4595, decode.loss_ce_2: 1.5713, decode.loss_mask_2: 0.3042, decode.loss_dice_2: 0.4434, decode.loss_ce_3: 1.5797, decode.loss_mask_3: 0.3121, decode.loss_dice_3: 0.4461, decode.loss_ce_4: 1.5620, decode.loss_mask_4: 0.3159, decode.loss_dice_4: 0.4452, loss: 14.0512
2023-09-21 23:23:26,173 - mmseg - INFO - Iter [6400/160000]	lr: 9.600e-05, eta: 1 day, 1:11:41, time: 0.539, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7382, decode.loss_mask: 0.4038, decode.loss_dice: 0.5225, decode.loss_ce_0: 1.7142, decode.loss_mask_0: 0.3738, decode.loss_dice_0: 0.5157, decode.loss_ce_1: 1.7170, decode.loss_mask_1: 0.3783, decode.loss_dice_1: 0.5314, decode.loss_ce_2: 1.7194, decode.loss_mask_2: 0.4098, decode.loss_dice_2: 0.5209, decode.loss_ce_3: 1.7282, decode.loss_mask_3: 0.4261, decode.loss_dice_3: 0.5221, decode.loss_ce_4: 1.7126, decode.loss_mask_4: 0.4136, decode.loss_dice_4: 0.5253, loss: 15.8728
2023-09-21 23:23:53,781 - mmseg - INFO - Iter [6450/160000]	lr: 9.597e-05, eta: 1 day, 1:10:26, time: 0.552, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6060, decode.loss_mask: 0.3225, decode.loss_dice: 0.4357, decode.loss_ce_0: 1.5676, decode.loss_mask_0: 0.3533, decode.loss_dice_0: 0.4411, decode.loss_ce_1: 1.5597, decode.loss_mask_1: 0.3343, decode.loss_dice_1: 0.4438, decode.loss_ce_2: 1.5781, decode.loss_mask_2: 0.3375, decode.loss_dice_2: 0.4477, decode.loss_ce_3: 1.6096, decode.loss_mask_3: 0.3394, decode.loss_dice_3: 0.4405, decode.loss_ce_4: 1.5758, decode.loss_mask_4: 0.3333, decode.loss_dice_4: 0.4341, loss: 14.1600
2023-09-21 23:24:21,255 - mmseg - INFO - Iter [6500/160000]	lr: 9.594e-05, eta: 1 day, 1:09:08, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7112, decode.loss_mask: 0.3217, decode.loss_dice: 0.4909, decode.loss_ce_0: 1.7182, decode.loss_mask_0: 0.3173, decode.loss_dice_0: 0.5080, decode.loss_ce_1: 1.7440, decode.loss_mask_1: 0.3420, decode.loss_dice_1: 0.5080, decode.loss_ce_2: 1.7237, decode.loss_mask_2: 0.3269, decode.loss_dice_2: 0.5018, decode.loss_ce_3: 1.7083, decode.loss_mask_3: 0.3067, decode.loss_dice_3: 0.4958, decode.loss_ce_4: 1.7270, decode.loss_mask_4: 0.3455, decode.loss_dice_4: 0.5014, loss: 15.2983
2023-09-21 23:24:48,578 - mmseg - INFO - Iter [6550/160000]	lr: 9.591e-05, eta: 1 day, 1:07:48, time: 0.546, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7715, decode.loss_mask: 0.3190, decode.loss_dice: 0.5097, decode.loss_ce_0: 1.7952, decode.loss_mask_0: 0.4321, decode.loss_dice_0: 0.5437, decode.loss_ce_1: 1.7267, decode.loss_mask_1: 0.3293, decode.loss_dice_1: 0.5099, decode.loss_ce_2: 1.7878, decode.loss_mask_2: 0.3486, decode.loss_dice_2: 0.5039, decode.loss_ce_3: 1.7672, decode.loss_mask_3: 0.3233, decode.loss_dice_3: 0.5105, decode.loss_ce_4: 1.7993, decode.loss_mask_4: 0.3786, decode.loss_dice_4: 0.5187, loss: 15.8752
2023-09-21 23:25:16,141 - mmseg - INFO - Iter [6600/160000]	lr: 9.588e-05, eta: 1 day, 1:06:34, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6250, decode.loss_mask: 0.3189, decode.loss_dice: 0.4863, decode.loss_ce_0: 1.6443, decode.loss_mask_0: 0.3172, decode.loss_dice_0: 0.4768, decode.loss_ce_1: 1.5949, decode.loss_mask_1: 0.3136, decode.loss_dice_1: 0.4829, decode.loss_ce_2: 1.6312, decode.loss_mask_2: 0.3238, decode.loss_dice_2: 0.4806, decode.loss_ce_3: 1.6145, decode.loss_mask_3: 0.3126, decode.loss_dice_3: 0.4812, decode.loss_ce_4: 1.6197, decode.loss_mask_4: 0.3404, decode.loss_dice_4: 0.4883, loss: 14.5525
2023-09-21 23:25:43,463 - mmseg - INFO - Iter [6650/160000]	lr: 9.584e-05, eta: 1 day, 1:05:15, time: 0.546, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6744, decode.loss_mask: 0.3740, decode.loss_dice: 0.4437, decode.loss_ce_0: 1.6253, decode.loss_mask_0: 0.2921, decode.loss_dice_0: 0.4269, decode.loss_ce_1: 1.5982, decode.loss_mask_1: 0.2933, decode.loss_dice_1: 0.4361, decode.loss_ce_2: 1.6286, decode.loss_mask_2: 0.2922, decode.loss_dice_2: 0.4303, decode.loss_ce_3: 1.6506, decode.loss_mask_3: 0.3235, decode.loss_dice_3: 0.4218, decode.loss_ce_4: 1.6523, decode.loss_mask_4: 0.3176, decode.loss_dice_4: 0.4256, loss: 14.3065
2023-09-21 23:26:10,461 - mmseg - INFO - Iter [6700/160000]	lr: 9.581e-05, eta: 1 day, 1:03:49, time: 0.540, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6922, decode.loss_mask: 0.3701, decode.loss_dice: 0.4961, decode.loss_ce_0: 1.6187, decode.loss_mask_0: 0.3230, decode.loss_dice_0: 0.4834, decode.loss_ce_1: 1.6367, decode.loss_mask_1: 0.3213, decode.loss_dice_1: 0.4829, decode.loss_ce_2: 1.6399, decode.loss_mask_2: 0.3525, decode.loss_dice_2: 0.4887, decode.loss_ce_3: 1.6551, decode.loss_mask_3: 0.3362, decode.loss_dice_3: 0.4888, decode.loss_ce_4: 1.6676, decode.loss_mask_4: 0.3951, decode.loss_dice_4: 0.4969, loss: 14.9451
2023-09-21 23:26:37,567 - mmseg - INFO - Iter [6750/160000]	lr: 9.578e-05, eta: 1 day, 1:02:27, time: 0.542, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6618, decode.loss_mask: 0.3515, decode.loss_dice: 0.4884, decode.loss_ce_0: 1.6862, decode.loss_mask_0: 0.3765, decode.loss_dice_0: 0.4821, decode.loss_ce_1: 1.6241, decode.loss_mask_1: 0.3482, decode.loss_dice_1: 0.4878, decode.loss_ce_2: 1.6536, decode.loss_mask_2: 0.3428, decode.loss_dice_2: 0.4824, decode.loss_ce_3: 1.6523, decode.loss_mask_3: 0.3492, decode.loss_dice_3: 0.4909, decode.loss_ce_4: 1.6606, decode.loss_mask_4: 0.3763, decode.loss_dice_4: 0.4919, loss: 15.0066
2023-09-21 23:27:04,566 - mmseg - INFO - Iter [6800/160000]	lr: 9.575e-05, eta: 1 day, 1:01:04, time: 0.540, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7930, decode.loss_mask: 0.3322, decode.loss_dice: 0.4632, decode.loss_ce_0: 1.7712, decode.loss_mask_0: 0.3139, decode.loss_dice_0: 0.4588, decode.loss_ce_1: 1.7316, decode.loss_mask_1: 0.3080, decode.loss_dice_1: 0.4701, decode.loss_ce_2: 1.7342, decode.loss_mask_2: 0.3076, decode.loss_dice_2: 0.4510, decode.loss_ce_3: 1.7502, decode.loss_mask_3: 0.2995, decode.loss_dice_3: 0.4542, decode.loss_ce_4: 1.7282, decode.loss_mask_4: 0.3301, decode.loss_dice_4: 0.4661, loss: 15.1630
2023-09-21 23:27:32,095 - mmseg - INFO - Iter [6850/160000]	lr: 9.572e-05, eta: 1 day, 0:59:52, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7507, decode.loss_mask: 0.2961, decode.loss_dice: 0.4624, decode.loss_ce_0: 1.7738, decode.loss_mask_0: 0.3035, decode.loss_dice_0: 0.4590, decode.loss_ce_1: 1.7689, decode.loss_mask_1: 0.3178, decode.loss_dice_1: 0.4696, decode.loss_ce_2: 1.7782, decode.loss_mask_2: 0.3184, decode.loss_dice_2: 0.4614, decode.loss_ce_3: 1.7637, decode.loss_mask_3: 0.3150, decode.loss_dice_3: 0.4660, decode.loss_ce_4: 1.7496, decode.loss_mask_4: 0.3004, decode.loss_dice_4: 0.4611, loss: 15.2156
2023-09-21 23:27:59,360 - mmseg - INFO - Iter [6900/160000]	lr: 9.569e-05, eta: 1 day, 0:58:36, time: 0.545, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6533, decode.loss_mask: 0.3133, decode.loss_dice: 0.4721, decode.loss_ce_0: 1.6676, decode.loss_mask_0: 0.3261, decode.loss_dice_0: 0.4684, decode.loss_ce_1: 1.6381, decode.loss_mask_1: 0.3248, decode.loss_dice_1: 0.4873, decode.loss_ce_2: 1.6331, decode.loss_mask_2: 0.3262, decode.loss_dice_2: 0.4858, decode.loss_ce_3: 1.6492, decode.loss_mask_3: 0.3154, decode.loss_dice_3: 0.4746, decode.loss_ce_4: 1.6509, decode.loss_mask_4: 0.3282, decode.loss_dice_4: 0.4714, loss: 14.6860
2023-09-21 23:28:27,387 - mmseg - INFO - Iter [6950/160000]	lr: 9.566e-05, eta: 1 day, 0:57:37, time: 0.561, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7377, decode.loss_mask: 0.2782, decode.loss_dice: 0.5012, decode.loss_ce_0: 1.7706, decode.loss_mask_0: 0.3596, decode.loss_dice_0: 0.5250, decode.loss_ce_1: 1.7365, decode.loss_mask_1: 0.2882, decode.loss_dice_1: 0.5186, decode.loss_ce_2: 1.7318, decode.loss_mask_2: 0.2747, decode.loss_dice_2: 0.5053, decode.loss_ce_3: 1.7500, decode.loss_mask_3: 0.3077, decode.loss_dice_3: 0.5042, decode.loss_ce_4: 1.7141, decode.loss_mask_4: 0.2922, decode.loss_dice_4: 0.5052, loss: 15.3007
2023-09-21 23:28:55,053 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:28:55,054 - mmseg - INFO - Iter [7000/160000]	lr: 9.563e-05, eta: 1 day, 0:56:31, time: 0.553, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6002, decode.loss_mask: 0.3487, decode.loss_dice: 0.4260, decode.loss_ce_0: 1.6400, decode.loss_mask_0: 0.3580, decode.loss_dice_0: 0.4316, decode.loss_ce_1: 1.6250, decode.loss_mask_1: 0.3585, decode.loss_dice_1: 0.4330, decode.loss_ce_2: 1.6180, decode.loss_mask_2: 0.3501, decode.loss_dice_2: 0.4282, decode.loss_ce_3: 1.6335, decode.loss_mask_3: 0.3482, decode.loss_dice_3: 0.4199, decode.loss_ce_4: 1.6306, decode.loss_mask_4: 0.3328, decode.loss_dice_4: 0.4176, loss: 14.4000
2023-09-21 23:29:23,644 - mmseg - INFO - Iter [7050/160000]	lr: 9.559e-05, eta: 1 day, 0:55:45, time: 0.572, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7315, decode.loss_mask: 0.2712, decode.loss_dice: 0.4747, decode.loss_ce_0: 1.7674, decode.loss_mask_0: 0.2873, decode.loss_dice_0: 0.4720, decode.loss_ce_1: 1.7634, decode.loss_mask_1: 0.2864, decode.loss_dice_1: 0.4776, decode.loss_ce_2: 1.7573, decode.loss_mask_2: 0.2738, decode.loss_dice_2: 0.4632, decode.loss_ce_3: 1.7721, decode.loss_mask_3: 0.2698, decode.loss_dice_3: 0.4632, decode.loss_ce_4: 1.7399, decode.loss_mask_4: 0.2792, decode.loss_dice_4: 0.4711, loss: 15.0211
2023-09-21 23:29:51,470 - mmseg - INFO - Iter [7100/160000]	lr: 9.556e-05, eta: 1 day, 0:54:43, time: 0.557, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7785, decode.loss_mask: 0.3317, decode.loss_dice: 0.5030, decode.loss_ce_0: 1.7494, decode.loss_mask_0: 0.3328, decode.loss_dice_0: 0.4997, decode.loss_ce_1: 1.7476, decode.loss_mask_1: 0.3362, decode.loss_dice_1: 0.5091, decode.loss_ce_2: 1.7729, decode.loss_mask_2: 0.3304, decode.loss_dice_2: 0.4963, decode.loss_ce_3: 1.7853, decode.loss_mask_3: 0.3162, decode.loss_dice_3: 0.4994, decode.loss_ce_4: 1.7663, decode.loss_mask_4: 0.3275, decode.loss_dice_4: 0.4908, loss: 15.5729
2023-09-21 23:30:19,138 - mmseg - INFO - Iter [7150/160000]	lr: 9.553e-05, eta: 1 day, 0:53:38, time: 0.553, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7549, decode.loss_mask: 0.3193, decode.loss_dice: 0.4753, decode.loss_ce_0: 1.7300, decode.loss_mask_0: 0.3305, decode.loss_dice_0: 0.4780, decode.loss_ce_1: 1.7333, decode.loss_mask_1: 0.3396, decode.loss_dice_1: 0.4937, decode.loss_ce_2: 1.7641, decode.loss_mask_2: 0.3455, decode.loss_dice_2: 0.4744, decode.loss_ce_3: 1.7711, decode.loss_mask_3: 0.3260, decode.loss_dice_3: 0.4765, decode.loss_ce_4: 1.7598, decode.loss_mask_4: 0.3304, decode.loss_dice_4: 0.4758, loss: 15.3782
2023-09-21 23:30:47,331 - mmseg - INFO - Iter [7200/160000]	lr: 9.550e-05, eta: 1 day, 0:52:45, time: 0.564, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6739, decode.loss_mask: 0.2660, decode.loss_dice: 0.4396, decode.loss_ce_0: 1.6509, decode.loss_mask_0: 0.2629, decode.loss_dice_0: 0.4475, decode.loss_ce_1: 1.6674, decode.loss_mask_1: 0.2551, decode.loss_dice_1: 0.4482, decode.loss_ce_2: 1.6782, decode.loss_mask_2: 0.2726, decode.loss_dice_2: 0.4522, decode.loss_ce_3: 1.6682, decode.loss_mask_3: 0.2569, decode.loss_dice_3: 0.4424, decode.loss_ce_4: 1.6734, decode.loss_mask_4: 0.2723, decode.loss_dice_4: 0.4406, loss: 14.2682
2023-09-21 23:31:15,191 - mmseg - INFO - Iter [7250/160000]	lr: 9.547e-05, eta: 1 day, 0:51:45, time: 0.557, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7691, decode.loss_mask: 0.3130, decode.loss_dice: 0.4511, decode.loss_ce_0: 1.7304, decode.loss_mask_0: 0.3105, decode.loss_dice_0: 0.4516, decode.loss_ce_1: 1.7402, decode.loss_mask_1: 0.3209, decode.loss_dice_1: 0.4536, decode.loss_ce_2: 1.7279, decode.loss_mask_2: 0.3113, decode.loss_dice_2: 0.4610, decode.loss_ce_3: 1.7890, decode.loss_mask_3: 0.3159, decode.loss_dice_3: 0.4499, decode.loss_ce_4: 1.7741, decode.loss_mask_4: 0.3392, decode.loss_dice_4: 0.4576, loss: 15.1664
2023-09-21 23:31:42,861 - mmseg - INFO - Iter [7300/160000]	lr: 9.544e-05, eta: 1 day, 0:50:42, time: 0.553, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7723, decode.loss_mask: 0.2983, decode.loss_dice: 0.4784, decode.loss_ce_0: 1.7795, decode.loss_mask_0: 0.3136, decode.loss_dice_0: 0.4773, decode.loss_ce_1: 1.7519, decode.loss_mask_1: 0.3047, decode.loss_dice_1: 0.4833, decode.loss_ce_2: 1.7672, decode.loss_mask_2: 0.3028, decode.loss_dice_2: 0.4777, decode.loss_ce_3: 1.7875, decode.loss_mask_3: 0.3030, decode.loss_dice_3: 0.4847, decode.loss_ce_4: 1.7814, decode.loss_mask_4: 0.3368, decode.loss_dice_4: 0.4900, loss: 15.3903
2023-09-21 23:32:10,284 - mmseg - INFO - Iter [7350/160000]	lr: 9.541e-05, eta: 1 day, 0:49:34, time: 0.548, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7009, decode.loss_mask: 0.3405, decode.loss_dice: 0.5052, decode.loss_ce_0: 1.7069, decode.loss_mask_0: 0.3517, decode.loss_dice_0: 0.5060, decode.loss_ce_1: 1.7356, decode.loss_mask_1: 0.3530, decode.loss_dice_1: 0.5114, decode.loss_ce_2: 1.7124, decode.loss_mask_2: 0.3622, decode.loss_dice_2: 0.5151, decode.loss_ce_3: 1.7097, decode.loss_mask_3: 0.3413, decode.loss_dice_3: 0.5109, decode.loss_ce_4: 1.7285, decode.loss_mask_4: 0.3455, decode.loss_dice_4: 0.5180, loss: 15.4550
2023-09-21 23:32:38,314 - mmseg - INFO - Iter [7400/160000]	lr: 9.538e-05, eta: 1 day, 0:48:39, time: 0.561, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6663, decode.loss_mask: 0.3283, decode.loss_dice: 0.4602, decode.loss_ce_0: 1.6468, decode.loss_mask_0: 0.3216, decode.loss_dice_0: 0.4687, decode.loss_ce_1: 1.6651, decode.loss_mask_1: 0.3274, decode.loss_dice_1: 0.4804, decode.loss_ce_2: 1.6567, decode.loss_mask_2: 0.3126, decode.loss_dice_2: 0.4725, decode.loss_ce_3: 1.6795, decode.loss_mask_3: 0.3211, decode.loss_dice_3: 0.4666, decode.loss_ce_4: 1.6746, decode.loss_mask_4: 0.3554, decode.loss_dice_4: 0.4757, loss: 14.7798
2023-09-21 23:33:06,754 - mmseg - INFO - Iter [7450/160000]	lr: 9.534e-05, eta: 1 day, 0:47:53, time: 0.569, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7300, decode.loss_mask: 0.3046, decode.loss_dice: 0.4524, decode.loss_ce_0: 1.6875, decode.loss_mask_0: 0.3038, decode.loss_dice_0: 0.4524, decode.loss_ce_1: 1.6789, decode.loss_mask_1: 0.2854, decode.loss_dice_1: 0.4558, decode.loss_ce_2: 1.6919, decode.loss_mask_2: 0.3165, decode.loss_dice_2: 0.4518, decode.loss_ce_3: 1.7286, decode.loss_mask_3: 0.3039, decode.loss_dice_3: 0.4472, decode.loss_ce_4: 1.7415, decode.loss_mask_4: 0.3141, decode.loss_dice_4: 0.4597, loss: 14.8061
2023-09-21 23:33:34,768 - mmseg - INFO - Iter [7500/160000]	lr: 9.531e-05, eta: 1 day, 0:46:58, time: 0.560, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7974, decode.loss_mask: 0.3478, decode.loss_dice: 0.4904, decode.loss_ce_0: 1.8093, decode.loss_mask_0: 0.3388, decode.loss_dice_0: 0.4733, decode.loss_ce_1: 1.7883, decode.loss_mask_1: 0.3481, decode.loss_dice_1: 0.4906, decode.loss_ce_2: 1.8177, decode.loss_mask_2: 0.3767, decode.loss_dice_2: 0.4863, decode.loss_ce_3: 1.7954, decode.loss_mask_3: 0.3447, decode.loss_dice_3: 0.4784, decode.loss_ce_4: 1.7756, decode.loss_mask_4: 0.3547, decode.loss_dice_4: 0.4805, loss: 15.7939
2023-09-21 23:34:02,101 - mmseg - INFO - Iter [7550/160000]	lr: 9.528e-05, eta: 1 day, 0:45:50, time: 0.547, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5850, decode.loss_mask: 0.2887, decode.loss_dice: 0.4347, decode.loss_ce_0: 1.5800, decode.loss_mask_0: 0.3093, decode.loss_dice_0: 0.4341, decode.loss_ce_1: 1.5587, decode.loss_mask_1: 0.3116, decode.loss_dice_1: 0.4454, decode.loss_ce_2: 1.5632, decode.loss_mask_2: 0.3112, decode.loss_dice_2: 0.4471, decode.loss_ce_3: 1.5927, decode.loss_mask_3: 0.3226, decode.loss_dice_3: 0.4387, decode.loss_ce_4: 1.5824, decode.loss_mask_4: 0.2950, decode.loss_dice_4: 0.4357, loss: 13.9362
2023-09-21 23:34:30,715 - mmseg - INFO - Iter [7600/160000]	lr: 9.525e-05, eta: 1 day, 0:45:09, time: 0.572, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7146, decode.loss_mask: 0.2899, decode.loss_dice: 0.5023, decode.loss_ce_0: 1.6910, decode.loss_mask_0: 0.2821, decode.loss_dice_0: 0.4995, decode.loss_ce_1: 1.6989, decode.loss_mask_1: 0.2826, decode.loss_dice_1: 0.5043, decode.loss_ce_2: 1.7200, decode.loss_mask_2: 0.2870, decode.loss_dice_2: 0.4999, decode.loss_ce_3: 1.6953, decode.loss_mask_3: 0.2743, decode.loss_dice_3: 0.5052, decode.loss_ce_4: 1.6751, decode.loss_mask_4: 0.2822, decode.loss_dice_4: 0.4987, loss: 14.9028
2023-09-21 23:34:58,524 - mmseg - INFO - Iter [7650/160000]	lr: 9.522e-05, eta: 1 day, 0:44:11, time: 0.556, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6860, decode.loss_mask: 0.2942, decode.loss_dice: 0.4455, decode.loss_ce_0: 1.7390, decode.loss_mask_0: 0.3210, decode.loss_dice_0: 0.4603, decode.loss_ce_1: 1.7191, decode.loss_mask_1: 0.2923, decode.loss_dice_1: 0.4571, decode.loss_ce_2: 1.7319, decode.loss_mask_2: 0.3156, decode.loss_dice_2: 0.4607, decode.loss_ce_3: 1.7196, decode.loss_mask_3: 0.2984, decode.loss_dice_3: 0.4540, decode.loss_ce_4: 1.7055, decode.loss_mask_4: 0.3075, decode.loss_dice_4: 0.4519, loss: 14.8597
2023-09-21 23:35:27,038 - mmseg - INFO - Iter [7700/160000]	lr: 9.519e-05, eta: 1 day, 0:43:28, time: 0.570, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6014, decode.loss_mask: 0.3261, decode.loss_dice: 0.4580, decode.loss_ce_0: 1.6223, decode.loss_mask_0: 0.3404, decode.loss_dice_0: 0.4471, decode.loss_ce_1: 1.6002, decode.loss_mask_1: 0.3229, decode.loss_dice_1: 0.4500, decode.loss_ce_2: 1.6045, decode.loss_mask_2: 0.3283, decode.loss_dice_2: 0.4543, decode.loss_ce_3: 1.6341, decode.loss_mask_3: 0.3285, decode.loss_dice_3: 0.4396, decode.loss_ce_4: 1.6123, decode.loss_mask_4: 0.3335, decode.loss_dice_4: 0.4700, loss: 14.3734
2023-09-21 23:35:54,840 - mmseg - INFO - Iter [7750/160000]	lr: 9.516e-05, eta: 1 day, 0:42:30, time: 0.556, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8134, decode.loss_mask: 0.2921, decode.loss_dice: 0.4824, decode.loss_ce_0: 1.8396, decode.loss_mask_0: 0.3070, decode.loss_dice_0: 0.4865, decode.loss_ce_1: 1.8357, decode.loss_mask_1: 0.2968, decode.loss_dice_1: 0.4807, decode.loss_ce_2: 1.8674, decode.loss_mask_2: 0.3514, decode.loss_dice_2: 0.4873, decode.loss_ce_3: 1.8488, decode.loss_mask_3: 0.2968, decode.loss_dice_3: 0.4778, decode.loss_ce_4: 1.8394, decode.loss_mask_4: 0.2963, decode.loss_dice_4: 0.4822, loss: 15.7816
2023-09-21 23:36:22,665 - mmseg - INFO - Iter [7800/160000]	lr: 9.513e-05, eta: 1 day, 0:41:34, time: 0.556, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6465, decode.loss_mask: 0.2623, decode.loss_dice: 0.4306, decode.loss_ce_0: 1.6731, decode.loss_mask_0: 0.2753, decode.loss_dice_0: 0.4397, decode.loss_ce_1: 1.6524, decode.loss_mask_1: 0.2666, decode.loss_dice_1: 0.4375, decode.loss_ce_2: 1.6380, decode.loss_mask_2: 0.2621, decode.loss_dice_2: 0.4327, decode.loss_ce_3: 1.6812, decode.loss_mask_3: 0.2636, decode.loss_dice_3: 0.4264, decode.loss_ce_4: 1.6791, decode.loss_mask_4: 0.2591, decode.loss_dice_4: 0.4298, loss: 14.1561
2023-09-21 23:36:50,553 - mmseg - INFO - Iter [7850/160000]	lr: 9.509e-05, eta: 1 day, 0:40:39, time: 0.558, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7267, decode.loss_mask: 0.3087, decode.loss_dice: 0.4666, decode.loss_ce_0: 1.7263, decode.loss_mask_0: 0.3546, decode.loss_dice_0: 0.4817, decode.loss_ce_1: 1.7290, decode.loss_mask_1: 0.3311, decode.loss_dice_1: 0.4804, decode.loss_ce_2: 1.7116, decode.loss_mask_2: 0.3391, decode.loss_dice_2: 0.4733, decode.loss_ce_3: 1.7336, decode.loss_mask_3: 0.3334, decode.loss_dice_3: 0.4772, decode.loss_ce_4: 1.7276, decode.loss_mask_4: 0.3265, decode.loss_dice_4: 0.4736, loss: 15.2008
2023-09-21 23:37:18,773 - mmseg - INFO - Iter [7900/160000]	lr: 9.506e-05, eta: 1 day, 0:39:52, time: 0.564, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8185, decode.loss_mask: 0.3803, decode.loss_dice: 0.4797, decode.loss_ce_0: 1.7622, decode.loss_mask_0: 0.3665, decode.loss_dice_0: 0.4819, decode.loss_ce_1: 1.7666, decode.loss_mask_1: 0.3388, decode.loss_dice_1: 0.4856, decode.loss_ce_2: 1.7677, decode.loss_mask_2: 0.3462, decode.loss_dice_2: 0.4815, decode.loss_ce_3: 1.8042, decode.loss_mask_3: 0.3544, decode.loss_dice_3: 0.4818, decode.loss_ce_4: 1.7812, decode.loss_mask_4: 0.3421, decode.loss_dice_4: 0.4688, loss: 15.7078
2023-09-21 23:37:46,695 - mmseg - INFO - Iter [7950/160000]	lr: 9.503e-05, eta: 1 day, 0:38:58, time: 0.558, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7023, decode.loss_mask: 0.3041, decode.loss_dice: 0.4601, decode.loss_ce_0: 1.6992, decode.loss_mask_0: 0.3221, decode.loss_dice_0: 0.4746, decode.loss_ce_1: 1.6843, decode.loss_mask_1: 0.2912, decode.loss_dice_1: 0.4692, decode.loss_ce_2: 1.6735, decode.loss_mask_2: 0.3183, decode.loss_dice_2: 0.4751, decode.loss_ce_3: 1.7398, decode.loss_mask_3: 0.3114, decode.loss_dice_3: 0.4620, decode.loss_ce_4: 1.7108, decode.loss_mask_4: 0.3200, decode.loss_dice_4: 0.4629, loss: 14.8810
2023-09-21 23:38:19,766 - mmseg - INFO - Saving checkpoint at 8000 iterations
2023-09-21 23:38:23,270 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:38:23,271 - mmseg - INFO - Iter [8000/160000]	lr: 9.500e-05, eta: 1 day, 0:40:49, time: 0.732, data_time: 0.128, memory: 13718, decode.loss_ce: 1.7432, decode.loss_mask: 0.3138, decode.loss_dice: 0.4751, decode.loss_ce_0: 1.7295, decode.loss_mask_0: 0.3242, decode.loss_dice_0: 0.4795, decode.loss_ce_1: 1.7698, decode.loss_mask_1: 0.3462, decode.loss_dice_1: 0.4852, decode.loss_ce_2: 1.7623, decode.loss_mask_2: 0.3069, decode.loss_dice_2: 0.4755, decode.loss_ce_3: 1.7303, decode.loss_mask_3: 0.3134, decode.loss_dice_3: 0.4823, decode.loss_ce_4: 1.7368, decode.loss_mask_4: 0.3184, decode.loss_dice_4: 0.4789, loss: 15.2711
2023-09-21 23:39:12,845 - mmseg - INFO - Iter [8050/160000]	lr: 9.497e-05, eta: 1 day, 0:46:44, time: 0.991, data_time: 0.453, memory: 13718, decode.loss_ce: 1.6727, decode.loss_mask: 0.3306, decode.loss_dice: 0.4648, decode.loss_ce_0: 1.6879, decode.loss_mask_0: 0.3431, decode.loss_dice_0: 0.4813, decode.loss_ce_1: 1.6850, decode.loss_mask_1: 0.3400, decode.loss_dice_1: 0.4833, decode.loss_ce_2: 1.6904, decode.loss_mask_2: 0.3267, decode.loss_dice_2: 0.4785, decode.loss_ce_3: 1.6983, decode.loss_mask_3: 0.3191, decode.loss_dice_3: 0.4631, decode.loss_ce_4: 1.6771, decode.loss_mask_4: 0.3279, decode.loss_dice_4: 0.4666, loss: 14.9364
2023-09-21 23:39:40,385 - mmseg - INFO - Iter [8100/160000]	lr: 9.494e-05, eta: 1 day, 0:45:41, time: 0.551, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7224, decode.loss_mask: 0.3042, decode.loss_dice: 0.5063, decode.loss_ce_0: 1.7363, decode.loss_mask_0: 0.3031, decode.loss_dice_0: 0.5039, decode.loss_ce_1: 1.7413, decode.loss_mask_1: 0.3281, decode.loss_dice_1: 0.5179, decode.loss_ce_2: 1.7432, decode.loss_mask_2: 0.3034, decode.loss_dice_2: 0.4999, decode.loss_ce_3: 1.7849, decode.loss_mask_3: 0.3041, decode.loss_dice_3: 0.5045, decode.loss_ce_4: 1.7218, decode.loss_mask_4: 0.3076, decode.loss_dice_4: 0.5008, loss: 15.3339
2023-09-21 23:40:07,997 - mmseg - INFO - Iter [8150/160000]	lr: 9.491e-05, eta: 1 day, 0:44:39, time: 0.552, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7576, decode.loss_mask: 0.3545, decode.loss_dice: 0.5246, decode.loss_ce_0: 1.7741, decode.loss_mask_0: 0.3545, decode.loss_dice_0: 0.5297, decode.loss_ce_1: 1.7561, decode.loss_mask_1: 0.3633, decode.loss_dice_1: 0.5433, decode.loss_ce_2: 1.7703, decode.loss_mask_2: 0.3502, decode.loss_dice_2: 0.5329, decode.loss_ce_3: 1.7687, decode.loss_mask_3: 0.3681, decode.loss_dice_3: 0.5226, decode.loss_ce_4: 1.7519, decode.loss_mask_4: 0.3560, decode.loss_dice_4: 0.5218, loss: 15.9000
2023-09-21 23:40:37,003 - mmseg - INFO - Iter [8200/160000]	lr: 9.488e-05, eta: 1 day, 0:44:04, time: 0.580, data_time: 0.009, memory: 13718, decode.loss_ce: 1.8074, decode.loss_mask: 0.4097, decode.loss_dice: 0.5640, decode.loss_ce_0: 1.8509, decode.loss_mask_0: 0.3962, decode.loss_dice_0: 0.5627, decode.loss_ce_1: 1.8284, decode.loss_mask_1: 0.3814, decode.loss_dice_1: 0.5613, decode.loss_ce_2: 1.8183, decode.loss_mask_2: 0.3752, decode.loss_dice_2: 0.5560, decode.loss_ce_3: 1.8395, decode.loss_mask_3: 0.4029, decode.loss_dice_3: 0.5587, decode.loss_ce_4: 1.8459, decode.loss_mask_4: 0.3929, decode.loss_dice_4: 0.5614, loss: 16.7128
2023-09-21 23:41:04,554 - mmseg - INFO - Iter [8250/160000]	lr: 9.484e-05, eta: 1 day, 0:43:02, time: 0.551, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8400, decode.loss_mask: 0.4184, decode.loss_dice: 0.5356, decode.loss_ce_0: 1.8152, decode.loss_mask_0: 0.3361, decode.loss_dice_0: 0.5177, decode.loss_ce_1: 1.8094, decode.loss_mask_1: 0.3337, decode.loss_dice_1: 0.5104, decode.loss_ce_2: 1.8040, decode.loss_mask_2: 0.3354, decode.loss_dice_2: 0.5096, decode.loss_ce_3: 1.8446, decode.loss_mask_3: 0.3424, decode.loss_dice_3: 0.5083, decode.loss_ce_4: 1.7985, decode.loss_mask_4: 0.3530, decode.loss_dice_4: 0.5137, loss: 16.1260
2023-09-21 23:41:32,112 - mmseg - INFO - Iter [8300/160000]	lr: 9.481e-05, eta: 1 day, 0:42:00, time: 0.551, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7095, decode.loss_mask: 0.3177, decode.loss_dice: 0.4559, decode.loss_ce_0: 1.6638, decode.loss_mask_0: 0.2803, decode.loss_dice_0: 0.4635, decode.loss_ce_1: 1.6781, decode.loss_mask_1: 0.2920, decode.loss_dice_1: 0.4507, decode.loss_ce_2: 1.6786, decode.loss_mask_2: 0.2827, decode.loss_dice_2: 0.4472, decode.loss_ce_3: 1.6972, decode.loss_mask_3: 0.2875, decode.loss_dice_3: 0.4456, decode.loss_ce_4: 1.6936, decode.loss_mask_4: 0.3057, decode.loss_dice_4: 0.4472, loss: 14.5966
2023-09-21 23:42:00,731 - mmseg - INFO - Iter [8350/160000]	lr: 9.478e-05, eta: 1 day, 0:41:19, time: 0.572, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7169, decode.loss_mask: 0.2579, decode.loss_dice: 0.4638, decode.loss_ce_0: 1.7228, decode.loss_mask_0: 0.2589, decode.loss_dice_0: 0.4767, decode.loss_ce_1: 1.7226, decode.loss_mask_1: 0.2591, decode.loss_dice_1: 0.4659, decode.loss_ce_2: 1.7260, decode.loss_mask_2: 0.2570, decode.loss_dice_2: 0.4704, decode.loss_ce_3: 1.7458, decode.loss_mask_3: 0.2618, decode.loss_dice_3: 0.4711, decode.loss_ce_4: 1.7212, decode.loss_mask_4: 0.2596, decode.loss_dice_4: 0.4713, loss: 14.7288
2023-09-21 23:42:36,241 - mmseg - INFO - Iter [8400/160000]	lr: 9.475e-05, eta: 1 day, 0:42:41, time: 0.710, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7361, decode.loss_mask: 0.4022, decode.loss_dice: 0.4812, decode.loss_ce_0: 1.7390, decode.loss_mask_0: 0.3877, decode.loss_dice_0: 0.4846, decode.loss_ce_1: 1.7043, decode.loss_mask_1: 0.3239, decode.loss_dice_1: 0.4708, decode.loss_ce_2: 1.6891, decode.loss_mask_2: 0.3396, decode.loss_dice_2: 0.4769, decode.loss_ce_3: 1.7216, decode.loss_mask_3: 0.3475, decode.loss_dice_3: 0.4790, decode.loss_ce_4: 1.7181, decode.loss_mask_4: 0.3514, decode.loss_dice_4: 0.4754, loss: 15.3284
2023-09-21 23:43:11,431 - mmseg - INFO - Iter [8450/160000]	lr: 9.472e-05, eta: 1 day, 0:43:57, time: 0.704, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6252, decode.loss_mask: 0.3084, decode.loss_dice: 0.4516, decode.loss_ce_0: 1.6464, decode.loss_mask_0: 0.2953, decode.loss_dice_0: 0.4749, decode.loss_ce_1: 1.6878, decode.loss_mask_1: 0.3750, decode.loss_dice_1: 0.4781, decode.loss_ce_2: 1.6408, decode.loss_mask_2: 0.3218, decode.loss_dice_2: 0.4670, decode.loss_ce_3: 1.6830, decode.loss_mask_3: 0.3146, decode.loss_dice_3: 0.4490, decode.loss_ce_4: 1.6628, decode.loss_mask_4: 0.3080, decode.loss_dice_4: 0.4496, loss: 14.6393
2023-09-21 23:43:47,650 - mmseg - INFO - Iter [8500/160000]	lr: 9.469e-05, eta: 1 day, 0:45:29, time: 0.724, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6919, decode.loss_mask: 0.3951, decode.loss_dice: 0.5109, decode.loss_ce_0: 1.6737, decode.loss_mask_0: 0.3087, decode.loss_dice_0: 0.5010, decode.loss_ce_1: 1.6704, decode.loss_mask_1: 0.3120, decode.loss_dice_1: 0.4968, decode.loss_ce_2: 1.6811, decode.loss_mask_2: 0.3080, decode.loss_dice_2: 0.4963, decode.loss_ce_3: 1.6810, decode.loss_mask_3: 0.3198, decode.loss_dice_3: 0.4887, decode.loss_ce_4: 1.6631, decode.loss_mask_4: 0.3162, decode.loss_dice_4: 0.4932, loss: 15.0079
2023-09-21 23:44:22,525 - mmseg - INFO - Iter [8550/160000]	lr: 9.466e-05, eta: 1 day, 0:46:37, time: 0.698, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7646, decode.loss_mask: 0.3139, decode.loss_dice: 0.5148, decode.loss_ce_0: 1.7549, decode.loss_mask_0: 0.2930, decode.loss_dice_0: 0.5238, decode.loss_ce_1: 1.7484, decode.loss_mask_1: 0.3013, decode.loss_dice_1: 0.5165, decode.loss_ce_2: 1.7394, decode.loss_mask_2: 0.2947, decode.loss_dice_2: 0.5161, decode.loss_ce_3: 1.7710, decode.loss_mask_3: 0.3198, decode.loss_dice_3: 0.5115, decode.loss_ce_4: 1.7641, decode.loss_mask_4: 0.2875, decode.loss_dice_4: 0.5121, loss: 15.4473
2023-09-21 23:44:56,733 - mmseg - INFO - Iter [8600/160000]	lr: 9.463e-05, eta: 1 day, 0:47:31, time: 0.684, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5954, decode.loss_mask: 0.3242, decode.loss_dice: 0.4641, decode.loss_ce_0: 1.5930, decode.loss_mask_0: 0.3333, decode.loss_dice_0: 0.4700, decode.loss_ce_1: 1.6137, decode.loss_mask_1: 0.3393, decode.loss_dice_1: 0.4721, decode.loss_ce_2: 1.6017, decode.loss_mask_2: 0.3203, decode.loss_dice_2: 0.4733, decode.loss_ce_3: 1.6269, decode.loss_mask_3: 0.3228, decode.loss_dice_3: 0.4633, decode.loss_ce_4: 1.5929, decode.loss_mask_4: 0.3224, decode.loss_dice_4: 0.4710, loss: 14.3996
2023-09-21 23:45:32,597 - mmseg - INFO - Iter [8650/160000]	lr: 9.459e-05, eta: 1 day, 0:48:53, time: 0.717, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6334, decode.loss_mask: 0.3439, decode.loss_dice: 0.4533, decode.loss_ce_0: 1.6347, decode.loss_mask_0: 0.3311, decode.loss_dice_0: 0.4620, decode.loss_ce_1: 1.6558, decode.loss_mask_1: 0.3159, decode.loss_dice_1: 0.4572, decode.loss_ce_2: 1.6468, decode.loss_mask_2: 0.3404, decode.loss_dice_2: 0.4570, decode.loss_ce_3: 1.6475, decode.loss_mask_3: 0.3412, decode.loss_dice_3: 0.4580, decode.loss_ce_4: 1.6369, decode.loss_mask_4: 0.3362, decode.loss_dice_4: 0.4573, loss: 14.6088
2023-09-21 23:46:07,783 - mmseg - INFO - Iter [8700/160000]	lr: 9.456e-05, eta: 1 day, 0:50:02, time: 0.704, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6222, decode.loss_mask: 0.3801, decode.loss_dice: 0.4649, decode.loss_ce_0: 1.6220, decode.loss_mask_0: 0.3713, decode.loss_dice_0: 0.4667, decode.loss_ce_1: 1.6219, decode.loss_mask_1: 0.3722, decode.loss_dice_1: 0.4692, decode.loss_ce_2: 1.6426, decode.loss_mask_2: 0.3776, decode.loss_dice_2: 0.4647, decode.loss_ce_3: 1.6421, decode.loss_mask_3: 0.4085, decode.loss_dice_3: 0.4714, decode.loss_ce_4: 1.6243, decode.loss_mask_4: 0.3879, decode.loss_dice_4: 0.4714, loss: 14.8810
2023-09-21 23:46:42,730 - mmseg - INFO - Iter [8750/160000]	lr: 9.453e-05, eta: 1 day, 0:51:06, time: 0.699, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6924, decode.loss_mask: 0.3006, decode.loss_dice: 0.4801, decode.loss_ce_0: 1.6654, decode.loss_mask_0: 0.3010, decode.loss_dice_0: 0.4751, decode.loss_ce_1: 1.6895, decode.loss_mask_1: 0.3016, decode.loss_dice_1: 0.4785, decode.loss_ce_2: 1.7251, decode.loss_mask_2: 0.3150, decode.loss_dice_2: 0.4756, decode.loss_ce_3: 1.6837, decode.loss_mask_3: 0.3100, decode.loss_dice_3: 0.4860, decode.loss_ce_4: 1.7109, decode.loss_mask_4: 0.3086, decode.loss_dice_4: 0.4745, loss: 14.8737
2023-09-21 23:47:17,862 - mmseg - INFO - Iter [8800/160000]	lr: 9.450e-05, eta: 1 day, 0:52:12, time: 0.703, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6435, decode.loss_mask: 0.3295, decode.loss_dice: 0.4504, decode.loss_ce_0: 1.6815, decode.loss_mask_0: 0.3241, decode.loss_dice_0: 0.4503, decode.loss_ce_1: 1.6393, decode.loss_mask_1: 0.3439, decode.loss_dice_1: 0.4605, decode.loss_ce_2: 1.6150, decode.loss_mask_2: 0.3257, decode.loss_dice_2: 0.4559, decode.loss_ce_3: 1.6308, decode.loss_mask_3: 0.3435, decode.loss_dice_3: 0.4632, decode.loss_ce_4: 1.6348, decode.loss_mask_4: 0.3601, decode.loss_dice_4: 0.4707, loss: 14.6226
2023-09-21 23:47:51,984 - mmseg - INFO - Iter [8850/160000]	lr: 9.447e-05, eta: 1 day, 0:53:00, time: 0.682, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5141, decode.loss_mask: 0.2929, decode.loss_dice: 0.4020, decode.loss_ce_0: 1.5412, decode.loss_mask_0: 0.2839, decode.loss_dice_0: 0.3933, decode.loss_ce_1: 1.5751, decode.loss_mask_1: 0.3576, decode.loss_dice_1: 0.4170, decode.loss_ce_2: 1.5372, decode.loss_mask_2: 0.2803, decode.loss_dice_2: 0.4026, decode.loss_ce_3: 1.5140, decode.loss_mask_3: 0.2764, decode.loss_dice_3: 0.4006, decode.loss_ce_4: 1.5079, decode.loss_mask_4: 0.2795, decode.loss_dice_4: 0.4007, loss: 13.3762
2023-09-21 23:48:26,689 - mmseg - INFO - Iter [8900/160000]	lr: 9.444e-05, eta: 1 day, 0:53:56, time: 0.694, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7157, decode.loss_mask: 0.3001, decode.loss_dice: 0.4550, decode.loss_ce_0: 1.7216, decode.loss_mask_0: 0.2995, decode.loss_dice_0: 0.4591, decode.loss_ce_1: 1.7317, decode.loss_mask_1: 0.3185, decode.loss_dice_1: 0.4755, decode.loss_ce_2: 1.7218, decode.loss_mask_2: 0.2948, decode.loss_dice_2: 0.4600, decode.loss_ce_3: 1.7052, decode.loss_mask_3: 0.3013, decode.loss_dice_3: 0.4496, decode.loss_ce_4: 1.7071, decode.loss_mask_4: 0.3036, decode.loss_dice_4: 0.4489, loss: 14.8690
2023-09-21 23:49:01,930 - mmseg - INFO - Iter [8950/160000]	lr: 9.441e-05, eta: 1 day, 0:55:01, time: 0.705, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6457, decode.loss_mask: 0.3615, decode.loss_dice: 0.4539, decode.loss_ce_0: 1.6607, decode.loss_mask_0: 0.3250, decode.loss_dice_0: 0.4516, decode.loss_ce_1: 1.6600, decode.loss_mask_1: 0.3441, decode.loss_dice_1: 0.4547, decode.loss_ce_2: 1.6726, decode.loss_mask_2: 0.3346, decode.loss_dice_2: 0.4465, decode.loss_ce_3: 1.6728, decode.loss_mask_3: 0.3491, decode.loss_dice_3: 0.4445, decode.loss_ce_4: 1.6535, decode.loss_mask_4: 0.3331, decode.loss_dice_4: 0.4473, loss: 14.7112
2023-09-21 23:49:36,816 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-21 23:49:36,817 - mmseg - INFO - Iter [9000/160000]	lr: 9.438e-05, eta: 1 day, 0:55:58, time: 0.698, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6820, decode.loss_mask: 0.3046, decode.loss_dice: 0.4214, decode.loss_ce_0: 1.6893, decode.loss_mask_0: 0.3032, decode.loss_dice_0: 0.4243, decode.loss_ce_1: 1.6700, decode.loss_mask_1: 0.3044, decode.loss_dice_1: 0.4328, decode.loss_ce_2: 1.6724, decode.loss_mask_2: 0.3089, decode.loss_dice_2: 0.4259, decode.loss_ce_3: 1.6969, decode.loss_mask_3: 0.3080, decode.loss_dice_3: 0.4258, decode.loss_ce_4: 1.6798, decode.loss_mask_4: 0.3176, decode.loss_dice_4: 0.4216, loss: 14.4890
2023-09-21 23:50:13,099 - mmseg - INFO - Iter [9050/160000]	lr: 9.434e-05, eta: 1 day, 0:57:18, time: 0.726, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6681, decode.loss_mask: 0.2982, decode.loss_dice: 0.4395, decode.loss_ce_0: 1.7125, decode.loss_mask_0: 0.2897, decode.loss_dice_0: 0.4513, decode.loss_ce_1: 1.6806, decode.loss_mask_1: 0.2899, decode.loss_dice_1: 0.4502, decode.loss_ce_2: 1.6829, decode.loss_mask_2: 0.2838, decode.loss_dice_2: 0.4452, decode.loss_ce_3: 1.6911, decode.loss_mask_3: 0.2866, decode.loss_dice_3: 0.4416, decode.loss_ce_4: 1.6813, decode.loss_mask_4: 0.2966, decode.loss_dice_4: 0.4467, loss: 14.5361
2023-09-21 23:50:48,445 - mmseg - INFO - Iter [9100/160000]	lr: 9.431e-05, eta: 1 day, 0:58:21, time: 0.707, data_time: 0.011, memory: 13718, decode.loss_ce: 1.5421, decode.loss_mask: 0.2818, decode.loss_dice: 0.4478, decode.loss_ce_0: 1.5317, decode.loss_mask_0: 0.2990, decode.loss_dice_0: 0.4505, decode.loss_ce_1: 1.5276, decode.loss_mask_1: 0.2946, decode.loss_dice_1: 0.4622, decode.loss_ce_2: 1.5579, decode.loss_mask_2: 0.2814, decode.loss_dice_2: 0.4469, decode.loss_ce_3: 1.5725, decode.loss_mask_3: 0.2885, decode.loss_dice_3: 0.4499, decode.loss_ce_4: 1.5658, decode.loss_mask_4: 0.2844, decode.loss_dice_4: 0.4472, loss: 13.7320
2023-09-21 23:51:24,709 - mmseg - INFO - Iter [9150/160000]	lr: 9.428e-05, eta: 1 day, 0:59:38, time: 0.725, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6335, decode.loss_mask: 0.3473, decode.loss_dice: 0.4946, decode.loss_ce_0: 1.6739, decode.loss_mask_0: 0.3402, decode.loss_dice_0: 0.4813, decode.loss_ce_1: 1.6226, decode.loss_mask_1: 0.3472, decode.loss_dice_1: 0.4921, decode.loss_ce_2: 1.6406, decode.loss_mask_2: 0.3434, decode.loss_dice_2: 0.4837, decode.loss_ce_3: 1.6628, decode.loss_mask_3: 0.3474, decode.loss_dice_3: 0.4835, decode.loss_ce_4: 1.6451, decode.loss_mask_4: 0.3496, decode.loss_dice_4: 0.4860, loss: 14.8749
2023-09-21 23:52:00,133 - mmseg - INFO - Iter [9200/160000]	lr: 9.425e-05, eta: 1 day, 1:00:40, time: 0.708, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7413, decode.loss_mask: 0.3180, decode.loss_dice: 0.4786, decode.loss_ce_0: 1.7664, decode.loss_mask_0: 0.3246, decode.loss_dice_0: 0.4838, decode.loss_ce_1: 1.7509, decode.loss_mask_1: 0.3221, decode.loss_dice_1: 0.4831, decode.loss_ce_2: 1.7518, decode.loss_mask_2: 0.3236, decode.loss_dice_2: 0.4893, decode.loss_ce_3: 1.7652, decode.loss_mask_3: 0.3243, decode.loss_dice_3: 0.4782, decode.loss_ce_4: 1.7410, decode.loss_mask_4: 0.3222, decode.loss_dice_4: 0.4825, loss: 15.3470
2023-09-21 23:52:34,375 - mmseg - INFO - Iter [9250/160000]	lr: 9.422e-05, eta: 1 day, 1:01:21, time: 0.685, data_time: 0.010, memory: 13718, decode.loss_ce: 1.3989, decode.loss_mask: 0.3126, decode.loss_dice: 0.3806, decode.loss_ce_0: 1.4337, decode.loss_mask_0: 0.3300, decode.loss_dice_0: 0.3805, decode.loss_ce_1: 1.4190, decode.loss_mask_1: 0.2933, decode.loss_dice_1: 0.3701, decode.loss_ce_2: 1.4176, decode.loss_mask_2: 0.3023, decode.loss_dice_2: 0.3703, decode.loss_ce_3: 1.4001, decode.loss_mask_3: 0.3084, decode.loss_dice_3: 0.3704, decode.loss_ce_4: 1.4021, decode.loss_mask_4: 0.3155, decode.loss_dice_4: 0.3828, loss: 12.5882
2023-09-21 23:53:09,367 - mmseg - INFO - Iter [9300/160000]	lr: 9.419e-05, eta: 1 day, 1:02:14, time: 0.700, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6919, decode.loss_mask: 0.3030, decode.loss_dice: 0.4581, decode.loss_ce_0: 1.7021, decode.loss_mask_0: 0.3169, decode.loss_dice_0: 0.4822, decode.loss_ce_1: 1.6979, decode.loss_mask_1: 0.3092, decode.loss_dice_1: 0.4626, decode.loss_ce_2: 1.6984, decode.loss_mask_2: 0.3049, decode.loss_dice_2: 0.4634, decode.loss_ce_3: 1.6939, decode.loss_mask_3: 0.2956, decode.loss_dice_3: 0.4558, decode.loss_ce_4: 1.6993, decode.loss_mask_4: 0.2880, decode.loss_dice_4: 0.4580, loss: 14.7811
2023-09-21 23:53:44,752 - mmseg - INFO - Iter [9350/160000]	lr: 9.416e-05, eta: 1 day, 1:03:13, time: 0.708, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6874, decode.loss_mask: 0.3399, decode.loss_dice: 0.4809, decode.loss_ce_0: 1.7321, decode.loss_mask_0: 0.3455, decode.loss_dice_0: 0.5007, decode.loss_ce_1: 1.7161, decode.loss_mask_1: 0.3401, decode.loss_dice_1: 0.4863, decode.loss_ce_2: 1.7648, decode.loss_mask_2: 0.4012, decode.loss_dice_2: 0.5086, decode.loss_ce_3: 1.7409, decode.loss_mask_3: 0.3523, decode.loss_dice_3: 0.4832, decode.loss_ce_4: 1.7070, decode.loss_mask_4: 0.3284, decode.loss_dice_4: 0.4808, loss: 15.3962
2023-09-21 23:54:19,993 - mmseg - INFO - Iter [9400/160000]	lr: 9.413e-05, eta: 1 day, 1:04:08, time: 0.705, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6924, decode.loss_mask: 0.2825, decode.loss_dice: 0.4777, decode.loss_ce_0: 1.6933, decode.loss_mask_0: 0.2851, decode.loss_dice_0: 0.4773, decode.loss_ce_1: 1.7051, decode.loss_mask_1: 0.2765, decode.loss_dice_1: 0.4711, decode.loss_ce_2: 1.6858, decode.loss_mask_2: 0.2902, decode.loss_dice_2: 0.4815, decode.loss_ce_3: 1.7100, decode.loss_mask_3: 0.2979, decode.loss_dice_3: 0.4733, decode.loss_ce_4: 1.7199, decode.loss_mask_4: 0.3072, decode.loss_dice_4: 0.4617, loss: 14.7885
2023-09-21 23:54:55,576 - mmseg - INFO - Iter [9450/160000]	lr: 9.409e-05, eta: 1 day, 1:05:07, time: 0.712, data_time: 0.010, memory: 13718, decode.loss_ce: 1.8069, decode.loss_mask: 0.2879, decode.loss_dice: 0.4640, decode.loss_ce_0: 1.8371, decode.loss_mask_0: 0.2920, decode.loss_dice_0: 0.4701, decode.loss_ce_1: 1.8356, decode.loss_mask_1: 0.2919, decode.loss_dice_1: 0.4627, decode.loss_ce_2: 1.8634, decode.loss_mask_2: 0.2922, decode.loss_dice_2: 0.4637, decode.loss_ce_3: 1.8382, decode.loss_mask_3: 0.3034, decode.loss_dice_3: 0.4703, decode.loss_ce_4: 1.8387, decode.loss_mask_4: 0.2842, decode.loss_dice_4: 0.4695, loss: 15.5719
2023-09-21 23:55:29,708 - mmseg - INFO - Iter [9500/160000]	lr: 9.406e-05, eta: 1 day, 1:05:43, time: 0.683, data_time: 0.011, memory: 13718, decode.loss_ce: 1.5729, decode.loss_mask: 0.3118, decode.loss_dice: 0.4353, decode.loss_ce_0: 1.6022, decode.loss_mask_0: 0.3503, decode.loss_dice_0: 0.4448, decode.loss_ce_1: 1.5764, decode.loss_mask_1: 0.3094, decode.loss_dice_1: 0.4303, decode.loss_ce_2: 1.5849, decode.loss_mask_2: 0.3304, decode.loss_dice_2: 0.4405, decode.loss_ce_3: 1.5672, decode.loss_mask_3: 0.3065, decode.loss_dice_3: 0.4318, decode.loss_ce_4: 1.5776, decode.loss_mask_4: 0.3217, decode.loss_dice_4: 0.4386, loss: 14.0323
2023-09-21 23:56:05,540 - mmseg - INFO - Iter [9550/160000]	lr: 9.403e-05, eta: 1 day, 1:06:44, time: 0.717, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8031, decode.loss_mask: 0.3461, decode.loss_dice: 0.5220, decode.loss_ce_0: 1.7835, decode.loss_mask_0: 0.3580, decode.loss_dice_0: 0.5195, decode.loss_ce_1: 1.7881, decode.loss_mask_1: 0.3336, decode.loss_dice_1: 0.4992, decode.loss_ce_2: 1.7755, decode.loss_mask_2: 0.3550, decode.loss_dice_2: 0.5043, decode.loss_ce_3: 1.7925, decode.loss_mask_3: 0.3467, decode.loss_dice_3: 0.5098, decode.loss_ce_4: 1.7919, decode.loss_mask_4: 0.3423, decode.loss_dice_4: 0.5167, loss: 15.8879
2023-09-21 23:56:38,454 - mmseg - INFO - Iter [9600/160000]	lr: 9.400e-05, eta: 1 day, 1:06:59, time: 0.658, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6882, decode.loss_mask: 0.3250, decode.loss_dice: 0.4652, decode.loss_ce_0: 1.7151, decode.loss_mask_0: 0.2945, decode.loss_dice_0: 0.4597, decode.loss_ce_1: 1.6944, decode.loss_mask_1: 0.3098, decode.loss_dice_1: 0.4590, decode.loss_ce_2: 1.6767, decode.loss_mask_2: 0.3015, decode.loss_dice_2: 0.4604, decode.loss_ce_3: 1.6440, decode.loss_mask_3: 0.2974, decode.loss_dice_3: 0.4583, decode.loss_ce_4: 1.6963, decode.loss_mask_4: 0.3277, decode.loss_dice_4: 0.4658, loss: 14.7392
2023-09-21 23:57:19,105 - mmseg - INFO - Iter [9650/160000]	lr: 9.397e-05, eta: 1 day, 1:09:14, time: 0.813, data_time: 0.214, memory: 13718, decode.loss_ce: 1.6977, decode.loss_mask: 0.2990, decode.loss_dice: 0.4702, decode.loss_ce_0: 1.7382, decode.loss_mask_0: 0.3048, decode.loss_dice_0: 0.4657, decode.loss_ce_1: 1.7248, decode.loss_mask_1: 0.3099, decode.loss_dice_1: 0.4704, decode.loss_ce_2: 1.7092, decode.loss_mask_2: 0.3025, decode.loss_dice_2: 0.4705, decode.loss_ce_3: 1.7241, decode.loss_mask_3: 0.3018, decode.loss_dice_3: 0.4665, decode.loss_ce_4: 1.6971, decode.loss_mask_4: 0.3131, decode.loss_dice_4: 0.4711, loss: 14.9367
2023-09-21 23:57:51,932 - mmseg - INFO - Iter [9700/160000]	lr: 9.394e-05, eta: 1 day, 1:09:26, time: 0.657, data_time: 0.079, memory: 13718, decode.loss_ce: 1.7232, decode.loss_mask: 0.2873, decode.loss_dice: 0.4314, decode.loss_ce_0: 1.7240, decode.loss_mask_0: 0.2824, decode.loss_dice_0: 0.4388, decode.loss_ce_1: 1.7102, decode.loss_mask_1: 0.3085, decode.loss_dice_1: 0.4389, decode.loss_ce_2: 1.6945, decode.loss_mask_2: 0.2828, decode.loss_dice_2: 0.4348, decode.loss_ce_3: 1.7201, decode.loss_mask_3: 0.2918, decode.loss_dice_3: 0.4303, decode.loss_ce_4: 1.7365, decode.loss_mask_4: 0.2982, decode.loss_dice_4: 0.4301, loss: 14.6637
2023-09-21 23:58:22,552 - mmseg - INFO - Iter [9750/160000]	lr: 9.391e-05, eta: 1 day, 1:09:04, time: 0.612, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6605, decode.loss_mask: 0.3167, decode.loss_dice: 0.4693, decode.loss_ce_0: 1.7005, decode.loss_mask_0: 0.2934, decode.loss_dice_0: 0.4749, decode.loss_ce_1: 1.6711, decode.loss_mask_1: 0.3031, decode.loss_dice_1: 0.4697, decode.loss_ce_2: 1.6630, decode.loss_mask_2: 0.2931, decode.loss_dice_2: 0.4650, decode.loss_ce_3: 1.6716, decode.loss_mask_3: 0.3032, decode.loss_dice_3: 0.4697, decode.loss_ce_4: 1.6810, decode.loss_mask_4: 0.3041, decode.loss_dice_4: 0.4614, loss: 14.6715
2023-09-21 23:58:52,394 - mmseg - INFO - Iter [9800/160000]	lr: 9.388e-05, eta: 1 day, 1:08:29, time: 0.597, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5991, decode.loss_mask: 0.3550, decode.loss_dice: 0.4402, decode.loss_ce_0: 1.5787, decode.loss_mask_0: 0.3168, decode.loss_dice_0: 0.4440, decode.loss_ce_1: 1.5575, decode.loss_mask_1: 0.3315, decode.loss_dice_1: 0.4406, decode.loss_ce_2: 1.5848, decode.loss_mask_2: 0.3386, decode.loss_dice_2: 0.4338, decode.loss_ce_3: 1.5983, decode.loss_mask_3: 0.3373, decode.loss_dice_3: 0.4395, decode.loss_ce_4: 1.6031, decode.loss_mask_4: 0.3472, decode.loss_dice_4: 0.4373, loss: 14.1832
2023-09-21 23:59:22,384 - mmseg - INFO - Iter [9850/160000]	lr: 9.384e-05, eta: 1 day, 1:07:57, time: 0.600, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6321, decode.loss_mask: 0.3079, decode.loss_dice: 0.4607, decode.loss_ce_0: 1.6681, decode.loss_mask_0: 0.3197, decode.loss_dice_0: 0.4700, decode.loss_ce_1: 1.6521, decode.loss_mask_1: 0.3061, decode.loss_dice_1: 0.4683, decode.loss_ce_2: 1.6518, decode.loss_mask_2: 0.3165, decode.loss_dice_2: 0.4735, decode.loss_ce_3: 1.6654, decode.loss_mask_3: 0.3301, decode.loss_dice_3: 0.4664, decode.loss_ce_4: 1.6534, decode.loss_mask_4: 0.3120, decode.loss_dice_4: 0.4646, loss: 14.6188
2023-09-21 23:59:51,718 - mmseg - INFO - Iter [9900/160000]	lr: 9.381e-05, eta: 1 day, 1:07:15, time: 0.587, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6486, decode.loss_mask: 0.3354, decode.loss_dice: 0.4550, decode.loss_ce_0: 1.6095, decode.loss_mask_0: 0.3063, decode.loss_dice_0: 0.4651, decode.loss_ce_1: 1.6126, decode.loss_mask_1: 0.3318, decode.loss_dice_1: 0.4639, decode.loss_ce_2: 1.6153, decode.loss_mask_2: 0.3263, decode.loss_dice_2: 0.4584, decode.loss_ce_3: 1.6271, decode.loss_mask_3: 0.3157, decode.loss_dice_3: 0.4658, decode.loss_ce_4: 1.6216, decode.loss_mask_4: 0.3068, decode.loss_dice_4: 0.4501, loss: 14.4154
2023-09-22 00:00:18,786 - mmseg - INFO - Iter [9950/160000]	lr: 9.378e-05, eta: 1 day, 1:05:58, time: 0.541, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6508, decode.loss_mask: 0.3040, decode.loss_dice: 0.4556, decode.loss_ce_0: 1.6717, decode.loss_mask_0: 0.3197, decode.loss_dice_0: 0.4608, decode.loss_ce_1: 1.6185, decode.loss_mask_1: 0.3185, decode.loss_dice_1: 0.4683, decode.loss_ce_2: 1.6467, decode.loss_mask_2: 0.2979, decode.loss_dice_2: 0.4681, decode.loss_ce_3: 1.6566, decode.loss_mask_3: 0.3155, decode.loss_dice_3: 0.4703, decode.loss_ce_4: 1.6508, decode.loss_mask_4: 0.3097, decode.loss_dice_4: 0.4572, loss: 14.5405
2023-09-22 00:00:45,716 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:00:45,717 - mmseg - INFO - Iter [10000/160000]	lr: 9.375e-05, eta: 1 day, 1:04:41, time: 0.539, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6771, decode.loss_mask: 0.2434, decode.loss_dice: 0.4527, decode.loss_ce_0: 1.6911, decode.loss_mask_0: 0.2400, decode.loss_dice_0: 0.4609, decode.loss_ce_1: 1.6590, decode.loss_mask_1: 0.2485, decode.loss_dice_1: 0.4573, decode.loss_ce_2: 1.6544, decode.loss_mask_2: 0.2439, decode.loss_dice_2: 0.4668, decode.loss_ce_3: 1.6566, decode.loss_mask_3: 0.2514, decode.loss_dice_3: 0.4637, decode.loss_ce_4: 1.6838, decode.loss_mask_4: 0.2472, decode.loss_dice_4: 0.4530, loss: 14.2510
2023-09-22 00:01:13,717 - mmseg - INFO - Iter [10050/160000]	lr: 9.372e-05, eta: 1 day, 1:03:39, time: 0.560, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6774, decode.loss_mask: 0.3239, decode.loss_dice: 0.4485, decode.loss_ce_0: 1.6784, decode.loss_mask_0: 0.3254, decode.loss_dice_0: 0.4468, decode.loss_ce_1: 1.6914, decode.loss_mask_1: 0.3239, decode.loss_dice_1: 0.4507, decode.loss_ce_2: 1.6997, decode.loss_mask_2: 0.3176, decode.loss_dice_2: 0.4458, decode.loss_ce_3: 1.6844, decode.loss_mask_3: 0.3177, decode.loss_dice_3: 0.4466, decode.loss_ce_4: 1.6961, decode.loss_mask_4: 0.3264, decode.loss_dice_4: 0.4469, loss: 14.7476
2023-09-22 00:01:40,596 - mmseg - INFO - Iter [10100/160000]	lr: 9.369e-05, eta: 1 day, 1:02:22, time: 0.538, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6332, decode.loss_mask: 0.3378, decode.loss_dice: 0.4480, decode.loss_ce_0: 1.6176, decode.loss_mask_0: 0.3667, decode.loss_dice_0: 0.4554, decode.loss_ce_1: 1.6039, decode.loss_mask_1: 0.3355, decode.loss_dice_1: 0.4391, decode.loss_ce_2: 1.6019, decode.loss_mask_2: 0.3230, decode.loss_dice_2: 0.4438, decode.loss_ce_3: 1.6108, decode.loss_mask_3: 0.3339, decode.loss_dice_3: 0.4423, decode.loss_ce_4: 1.6222, decode.loss_mask_4: 0.3364, decode.loss_dice_4: 0.4468, loss: 14.3984
2023-09-22 00:02:08,110 - mmseg - INFO - Iter [10150/160000]	lr: 9.366e-05, eta: 1 day, 1:01:14, time: 0.550, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6354, decode.loss_mask: 0.2914, decode.loss_dice: 0.4602, decode.loss_ce_0: 1.6517, decode.loss_mask_0: 0.2912, decode.loss_dice_0: 0.4381, decode.loss_ce_1: 1.6345, decode.loss_mask_1: 0.2770, decode.loss_dice_1: 0.4358, decode.loss_ce_2: 1.6539, decode.loss_mask_2: 0.2954, decode.loss_dice_2: 0.4337, decode.loss_ce_3: 1.6389, decode.loss_mask_3: 0.2904, decode.loss_dice_3: 0.4408, decode.loss_ce_4: 1.6318, decode.loss_mask_4: 0.3109, decode.loss_dice_4: 0.4549, loss: 14.2660
2023-09-22 00:02:35,702 - mmseg - INFO - Iter [10200/160000]	lr: 9.363e-05, eta: 1 day, 1:00:08, time: 0.552, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6893, decode.loss_mask: 0.3041, decode.loss_dice: 0.4455, decode.loss_ce_0: 1.6863, decode.loss_mask_0: 0.2957, decode.loss_dice_0: 0.4544, decode.loss_ce_1: 1.6678, decode.loss_mask_1: 0.2824, decode.loss_dice_1: 0.4437, decode.loss_ce_2: 1.6603, decode.loss_mask_2: 0.2761, decode.loss_dice_2: 0.4456, decode.loss_ce_3: 1.6595, decode.loss_mask_3: 0.2872, decode.loss_dice_3: 0.4504, decode.loss_ce_4: 1.6643, decode.loss_mask_4: 0.3150, decode.loss_dice_4: 0.4601, loss: 14.4880
2023-09-22 00:03:02,254 - mmseg - INFO - Iter [10250/160000]	lr: 9.359e-05, eta: 1 day, 0:58:47, time: 0.531, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6140, decode.loss_mask: 0.3561, decode.loss_dice: 0.4594, decode.loss_ce_0: 1.6089, decode.loss_mask_0: 0.3232, decode.loss_dice_0: 0.4377, decode.loss_ce_1: 1.6298, decode.loss_mask_1: 0.3484, decode.loss_dice_1: 0.4524, decode.loss_ce_2: 1.5897, decode.loss_mask_2: 0.3291, decode.loss_dice_2: 0.4391, decode.loss_ce_3: 1.6299, decode.loss_mask_3: 0.3409, decode.loss_dice_3: 0.4425, decode.loss_ce_4: 1.6111, decode.loss_mask_4: 0.3242, decode.loss_dice_4: 0.4450, loss: 14.3816
2023-09-22 00:03:28,722 - mmseg - INFO - Iter [10300/160000]	lr: 9.356e-05, eta: 1 day, 0:57:25, time: 0.529, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7465, decode.loss_mask: 0.3427, decode.loss_dice: 0.4934, decode.loss_ce_0: 1.7207, decode.loss_mask_0: 0.3525, decode.loss_dice_0: 0.5034, decode.loss_ce_1: 1.7258, decode.loss_mask_1: 0.3576, decode.loss_dice_1: 0.5054, decode.loss_ce_2: 1.7351, decode.loss_mask_2: 0.3604, decode.loss_dice_2: 0.5025, decode.loss_ce_3: 1.7135, decode.loss_mask_3: 0.3594, decode.loss_dice_3: 0.5032, decode.loss_ce_4: 1.7253, decode.loss_mask_4: 0.3498, decode.loss_dice_4: 0.4985, loss: 15.4959
2023-09-22 00:03:56,451 - mmseg - INFO - Iter [10350/160000]	lr: 9.353e-05, eta: 1 day, 0:56:22, time: 0.555, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7053, decode.loss_mask: 0.3074, decode.loss_dice: 0.4737, decode.loss_ce_0: 1.7206, decode.loss_mask_0: 0.3247, decode.loss_dice_0: 0.4781, decode.loss_ce_1: 1.6810, decode.loss_mask_1: 0.3382, decode.loss_dice_1: 0.4869, decode.loss_ce_2: 1.7204, decode.loss_mask_2: 0.3213, decode.loss_dice_2: 0.4841, decode.loss_ce_3: 1.7122, decode.loss_mask_3: 0.3113, decode.loss_dice_3: 0.4785, decode.loss_ce_4: 1.7216, decode.loss_mask_4: 0.3232, decode.loss_dice_4: 0.4764, loss: 15.0650
2023-09-22 00:04:23,421 - mmseg - INFO - Iter [10400/160000]	lr: 9.350e-05, eta: 1 day, 0:55:08, time: 0.539, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6838, decode.loss_mask: 0.3297, decode.loss_dice: 0.4634, decode.loss_ce_0: 1.6700, decode.loss_mask_0: 0.3376, decode.loss_dice_0: 0.4756, decode.loss_ce_1: 1.6972, decode.loss_mask_1: 0.3393, decode.loss_dice_1: 0.4719, decode.loss_ce_2: 1.6799, decode.loss_mask_2: 0.3248, decode.loss_dice_2: 0.4695, decode.loss_ce_3: 1.6841, decode.loss_mask_3: 0.3363, decode.loss_dice_3: 0.4660, decode.loss_ce_4: 1.7011, decode.loss_mask_4: 0.3254, decode.loss_dice_4: 0.4668, loss: 14.9225
2023-09-22 00:04:50,419 - mmseg - INFO - Iter [10450/160000]	lr: 9.347e-05, eta: 1 day, 0:53:56, time: 0.540, data_time: 0.009, memory: 13718, decode.loss_ce: 1.5423, decode.loss_mask: 0.2916, decode.loss_dice: 0.4134, decode.loss_ce_0: 1.5392, decode.loss_mask_0: 0.2948, decode.loss_dice_0: 0.4216, decode.loss_ce_1: 1.5572, decode.loss_mask_1: 0.3115, decode.loss_dice_1: 0.4236, decode.loss_ce_2: 1.5342, decode.loss_mask_2: 0.2905, decode.loss_dice_2: 0.4134, decode.loss_ce_3: 1.5464, decode.loss_mask_3: 0.2908, decode.loss_dice_3: 0.4189, decode.loss_ce_4: 1.5543, decode.loss_mask_4: 0.2888, decode.loss_dice_4: 0.4160, loss: 13.5487
2023-09-22 00:05:17,560 - mmseg - INFO - Iter [10500/160000]	lr: 9.344e-05, eta: 1 day, 0:52:45, time: 0.543, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7550, decode.loss_mask: 0.3272, decode.loss_dice: 0.4457, decode.loss_ce_0: 1.7293, decode.loss_mask_0: 0.3266, decode.loss_dice_0: 0.4554, decode.loss_ce_1: 1.7309, decode.loss_mask_1: 0.3357, decode.loss_dice_1: 0.4549, decode.loss_ce_2: 1.7178, decode.loss_mask_2: 0.3239, decode.loss_dice_2: 0.4488, decode.loss_ce_3: 1.7223, decode.loss_mask_3: 0.3221, decode.loss_dice_3: 0.4464, decode.loss_ce_4: 1.7296, decode.loss_mask_4: 0.3275, decode.loss_dice_4: 0.4555, loss: 15.0546
2023-09-22 00:05:44,093 - mmseg - INFO - Iter [10550/160000]	lr: 9.341e-05, eta: 1 day, 0:51:27, time: 0.531, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6219, decode.loss_mask: 0.2768, decode.loss_dice: 0.3969, decode.loss_ce_0: 1.6081, decode.loss_mask_0: 0.2574, decode.loss_dice_0: 0.4051, decode.loss_ce_1: 1.6045, decode.loss_mask_1: 0.2744, decode.loss_dice_1: 0.4093, decode.loss_ce_2: 1.6126, decode.loss_mask_2: 0.2499, decode.loss_dice_2: 0.4001, decode.loss_ce_3: 1.6296, decode.loss_mask_3: 0.2621, decode.loss_dice_3: 0.3938, decode.loss_ce_4: 1.6089, decode.loss_mask_4: 0.2608, decode.loss_dice_4: 0.4021, loss: 13.6743
2023-09-22 00:06:10,717 - mmseg - INFO - Iter [10600/160000]	lr: 9.338e-05, eta: 1 day, 0:50:10, time: 0.532, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7353, decode.loss_mask: 0.2866, decode.loss_dice: 0.4566, decode.loss_ce_0: 1.7261, decode.loss_mask_0: 0.2782, decode.loss_dice_0: 0.4649, decode.loss_ce_1: 1.7342, decode.loss_mask_1: 0.2785, decode.loss_dice_1: 0.4566, decode.loss_ce_2: 1.7412, decode.loss_mask_2: 0.2727, decode.loss_dice_2: 0.4600, decode.loss_ce_3: 1.7652, decode.loss_mask_3: 0.2742, decode.loss_dice_3: 0.4632, decode.loss_ce_4: 1.7385, decode.loss_mask_4: 0.2704, decode.loss_dice_4: 0.4588, loss: 14.8612
2023-09-22 00:06:37,916 - mmseg - INFO - Iter [10650/160000]	lr: 9.334e-05, eta: 1 day, 0:49:02, time: 0.544, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6961, decode.loss_mask: 0.3143, decode.loss_dice: 0.4566, decode.loss_ce_0: 1.6897, decode.loss_mask_0: 0.2935, decode.loss_dice_0: 0.4567, decode.loss_ce_1: 1.6981, decode.loss_mask_1: 0.2966, decode.loss_dice_1: 0.4493, decode.loss_ce_2: 1.6745, decode.loss_mask_2: 0.3065, decode.loss_dice_2: 0.4536, decode.loss_ce_3: 1.6979, decode.loss_mask_3: 0.2849, decode.loss_dice_3: 0.4502, decode.loss_ce_4: 1.7107, decode.loss_mask_4: 0.2953, decode.loss_dice_4: 0.4494, loss: 14.6740
2023-09-22 00:07:05,836 - mmseg - INFO - Iter [10700/160000]	lr: 9.331e-05, eta: 1 day, 0:48:04, time: 0.558, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6119, decode.loss_mask: 0.2821, decode.loss_dice: 0.4489, decode.loss_ce_0: 1.6469, decode.loss_mask_0: 0.2904, decode.loss_dice_0: 0.4425, decode.loss_ce_1: 1.6768, decode.loss_mask_1: 0.3139, decode.loss_dice_1: 0.4576, decode.loss_ce_2: 1.6495, decode.loss_mask_2: 0.2818, decode.loss_dice_2: 0.4312, decode.loss_ce_3: 1.6607, decode.loss_mask_3: 0.2800, decode.loss_dice_3: 0.4402, decode.loss_ce_4: 1.6418, decode.loss_mask_4: 0.2884, decode.loss_dice_4: 0.4445, loss: 14.2892
2023-09-22 00:07:33,034 - mmseg - INFO - Iter [10750/160000]	lr: 9.328e-05, eta: 1 day, 0:46:57, time: 0.544, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6244, decode.loss_mask: 0.2772, decode.loss_dice: 0.4642, decode.loss_ce_0: 1.6711, decode.loss_mask_0: 0.2860, decode.loss_dice_0: 0.4653, decode.loss_ce_1: 1.6877, decode.loss_mask_1: 0.2871, decode.loss_dice_1: 0.4569, decode.loss_ce_2: 1.6764, decode.loss_mask_2: 0.2780, decode.loss_dice_2: 0.4497, decode.loss_ce_3: 1.6757, decode.loss_mask_3: 0.2732, decode.loss_dice_3: 0.4540, decode.loss_ce_4: 1.6644, decode.loss_mask_4: 0.2869, decode.loss_dice_4: 0.4645, loss: 14.4427
2023-09-22 00:08:00,382 - mmseg - INFO - Iter [10800/160000]	lr: 9.325e-05, eta: 1 day, 0:45:52, time: 0.547, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7707, decode.loss_mask: 0.2724, decode.loss_dice: 0.4671, decode.loss_ce_0: 1.7981, decode.loss_mask_0: 0.2888, decode.loss_dice_0: 0.4672, decode.loss_ce_1: 1.7989, decode.loss_mask_1: 0.3008, decode.loss_dice_1: 0.4873, decode.loss_ce_2: 1.8033, decode.loss_mask_2: 0.2831, decode.loss_dice_2: 0.4668, decode.loss_ce_3: 1.7634, decode.loss_mask_3: 0.2832, decode.loss_dice_3: 0.4715, decode.loss_ce_4: 1.7746, decode.loss_mask_4: 0.2830, decode.loss_dice_4: 0.4793, loss: 15.2596
2023-09-22 00:08:26,991 - mmseg - INFO - Iter [10850/160000]	lr: 9.322e-05, eta: 1 day, 0:44:37, time: 0.532, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6687, decode.loss_mask: 0.2789, decode.loss_dice: 0.4495, decode.loss_ce_0: 1.6807, decode.loss_mask_0: 0.2878, decode.loss_dice_0: 0.4569, decode.loss_ce_1: 1.7121, decode.loss_mask_1: 0.2725, decode.loss_dice_1: 0.4523, decode.loss_ce_2: 1.6902, decode.loss_mask_2: 0.2870, decode.loss_dice_2: 0.4522, decode.loss_ce_3: 1.6997, decode.loss_mask_3: 0.2932, decode.loss_dice_3: 0.4515, decode.loss_ce_4: 1.6890, decode.loss_mask_4: 0.2711, decode.loss_dice_4: 0.4507, loss: 14.5440
2023-09-22 00:08:53,379 - mmseg - INFO - Iter [10900/160000]	lr: 9.319e-05, eta: 1 day, 0:43:20, time: 0.528, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7019, decode.loss_mask: 0.2785, decode.loss_dice: 0.4226, decode.loss_ce_0: 1.7066, decode.loss_mask_0: 0.2905, decode.loss_dice_0: 0.4321, decode.loss_ce_1: 1.7269, decode.loss_mask_1: 0.3066, decode.loss_dice_1: 0.4345, decode.loss_ce_2: 1.7174, decode.loss_mask_2: 0.2825, decode.loss_dice_2: 0.4367, decode.loss_ce_3: 1.7025, decode.loss_mask_3: 0.2746, decode.loss_dice_3: 0.4250, decode.loss_ce_4: 1.7025, decode.loss_mask_4: 0.2813, decode.loss_dice_4: 0.4256, loss: 14.5484
2023-09-22 00:09:21,028 - mmseg - INFO - Iter [10950/160000]	lr: 9.316e-05, eta: 1 day, 0:42:20, time: 0.553, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7423, decode.loss_mask: 0.3104, decode.loss_dice: 0.4450, decode.loss_ce_0: 1.7460, decode.loss_mask_0: 0.3014, decode.loss_dice_0: 0.4574, decode.loss_ce_1: 1.7362, decode.loss_mask_1: 0.2977, decode.loss_dice_1: 0.4617, decode.loss_ce_2: 1.7535, decode.loss_mask_2: 0.3286, decode.loss_dice_2: 0.4491, decode.loss_ce_3: 1.7274, decode.loss_mask_3: 0.3167, decode.loss_dice_3: 0.4634, decode.loss_ce_4: 1.7390, decode.loss_mask_4: 0.3070, decode.loss_dice_4: 0.4565, loss: 15.0395
2023-09-22 00:09:52,693 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:09:52,693 - mmseg - INFO - Iter [11000/160000]	lr: 9.313e-05, eta: 1 day, 0:42:15, time: 0.633, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6671, decode.loss_mask: 0.3394, decode.loss_dice: 0.4234, decode.loss_ce_0: 1.6762, decode.loss_mask_0: 0.3409, decode.loss_dice_0: 0.4259, decode.loss_ce_1: 1.6420, decode.loss_mask_1: 0.3378, decode.loss_dice_1: 0.4227, decode.loss_ce_2: 1.6672, decode.loss_mask_2: 0.3626, decode.loss_dice_2: 0.4276, decode.loss_ce_3: 1.6447, decode.loss_mask_3: 0.3223, decode.loss_dice_3: 0.4227, decode.loss_ce_4: 1.6320, decode.loss_mask_4: 0.3203, decode.loss_dice_4: 0.4298, loss: 14.5047
2023-09-22 00:10:26,421 - mmseg - INFO - Iter [11050/160000]	lr: 9.309e-05, eta: 1 day, 0:42:37, time: 0.675, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5820, decode.loss_mask: 0.3121, decode.loss_dice: 0.4190, decode.loss_ce_0: 1.5828, decode.loss_mask_0: 0.3138, decode.loss_dice_0: 0.4220, decode.loss_ce_1: 1.5964, decode.loss_mask_1: 0.3056, decode.loss_dice_1: 0.4185, decode.loss_ce_2: 1.5811, decode.loss_mask_2: 0.3087, decode.loss_dice_2: 0.4127, decode.loss_ce_3: 1.5849, decode.loss_mask_3: 0.2940, decode.loss_dice_3: 0.4102, decode.loss_ce_4: 1.5730, decode.loss_mask_4: 0.2997, decode.loss_dice_4: 0.4058, loss: 13.8222
2023-09-22 00:11:00,971 - mmseg - INFO - Iter [11100/160000]	lr: 9.306e-05, eta: 1 day, 0:43:10, time: 0.691, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6470, decode.loss_mask: 0.3272, decode.loss_dice: 0.4239, decode.loss_ce_0: 1.6410, decode.loss_mask_0: 0.3250, decode.loss_dice_0: 0.4278, decode.loss_ce_1: 1.6501, decode.loss_mask_1: 0.3162, decode.loss_dice_1: 0.4231, decode.loss_ce_2: 1.6516, decode.loss_mask_2: 0.3188, decode.loss_dice_2: 0.4209, decode.loss_ce_3: 1.6509, decode.loss_mask_3: 0.3205, decode.loss_dice_3: 0.4170, decode.loss_ce_4: 1.6497, decode.loss_mask_4: 0.3193, decode.loss_dice_4: 0.4265, loss: 14.3564
2023-09-22 00:11:35,293 - mmseg - INFO - Iter [11150/160000]	lr: 9.303e-05, eta: 1 day, 0:43:40, time: 0.686, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7382, decode.loss_mask: 0.3194, decode.loss_dice: 0.4756, decode.loss_ce_0: 1.7298, decode.loss_mask_0: 0.3031, decode.loss_dice_0: 0.4746, decode.loss_ce_1: 1.7348, decode.loss_mask_1: 0.3084, decode.loss_dice_1: 0.4720, decode.loss_ce_2: 1.7313, decode.loss_mask_2: 0.3288, decode.loss_dice_2: 0.4799, decode.loss_ce_3: 1.7548, decode.loss_mask_3: 0.3045, decode.loss_dice_3: 0.4688, decode.loss_ce_4: 1.7313, decode.loss_mask_4: 0.3261, decode.loss_dice_4: 0.4767, loss: 15.1580
2023-09-22 00:12:09,873 - mmseg - INFO - Iter [11200/160000]	lr: 9.300e-05, eta: 1 day, 0:44:12, time: 0.692, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6822, decode.loss_mask: 0.3118, decode.loss_dice: 0.4608, decode.loss_ce_0: 1.6707, decode.loss_mask_0: 0.3049, decode.loss_dice_0: 0.4611, decode.loss_ce_1: 1.6867, decode.loss_mask_1: 0.3092, decode.loss_dice_1: 0.4572, decode.loss_ce_2: 1.6811, decode.loss_mask_2: 0.2975, decode.loss_dice_2: 0.4524, decode.loss_ce_3: 1.6980, decode.loss_mask_3: 0.3081, decode.loss_dice_3: 0.4641, decode.loss_ce_4: 1.6992, decode.loss_mask_4: 0.3073, decode.loss_dice_4: 0.4581, loss: 14.7100
2023-09-22 00:12:43,145 - mmseg - INFO - Iter [11250/160000]	lr: 9.297e-05, eta: 1 day, 0:44:26, time: 0.665, data_time: 0.011, memory: 13718, decode.loss_ce: 1.4135, decode.loss_mask: 0.2404, decode.loss_dice: 0.3601, decode.loss_ce_0: 1.4148, decode.loss_mask_0: 0.2486, decode.loss_dice_0: 0.3611, decode.loss_ce_1: 1.4079, decode.loss_mask_1: 0.2466, decode.loss_dice_1: 0.3621, decode.loss_ce_2: 1.3950, decode.loss_mask_2: 0.2562, decode.loss_dice_2: 0.3676, decode.loss_ce_3: 1.4159, decode.loss_mask_3: 0.2435, decode.loss_dice_3: 0.3623, decode.loss_ce_4: 1.4196, decode.loss_mask_4: 0.2407, decode.loss_dice_4: 0.3680, loss: 12.1240
2023-09-22 00:13:18,389 - mmseg - INFO - Iter [11300/160000]	lr: 9.294e-05, eta: 1 day, 0:45:06, time: 0.705, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7990, decode.loss_mask: 0.3820, decode.loss_dice: 0.4743, decode.loss_ce_0: 1.8026, decode.loss_mask_0: 0.3689, decode.loss_dice_0: 0.4774, decode.loss_ce_1: 1.8028, decode.loss_mask_1: 0.3623, decode.loss_dice_1: 0.4794, decode.loss_ce_2: 1.8099, decode.loss_mask_2: 0.3527, decode.loss_dice_2: 0.4811, decode.loss_ce_3: 1.8199, decode.loss_mask_3: 0.3417, decode.loss_dice_3: 0.4787, decode.loss_ce_4: 1.7934, decode.loss_mask_4: 0.3645, decode.loss_dice_4: 0.4755, loss: 15.8660
2023-09-22 00:13:53,634 - mmseg - INFO - Iter [11350/160000]	lr: 9.291e-05, eta: 1 day, 0:45:45, time: 0.705, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8075, decode.loss_mask: 0.3032, decode.loss_dice: 0.4815, decode.loss_ce_0: 1.7806, decode.loss_mask_0: 0.3075, decode.loss_dice_0: 0.4789, decode.loss_ce_1: 1.7575, decode.loss_mask_1: 0.2989, decode.loss_dice_1: 0.4801, decode.loss_ce_2: 1.7521, decode.loss_mask_2: 0.3037, decode.loss_dice_2: 0.4840, decode.loss_ce_3: 1.7779, decode.loss_mask_3: 0.2949, decode.loss_dice_3: 0.4769, decode.loss_ce_4: 1.7855, decode.loss_mask_4: 0.3035, decode.loss_dice_4: 0.4808, loss: 15.3549
2023-09-22 00:14:26,966 - mmseg - INFO - Iter [11400/160000]	lr: 9.288e-05, eta: 1 day, 0:45:59, time: 0.667, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7246, decode.loss_mask: 0.3105, decode.loss_dice: 0.4687, decode.loss_ce_0: 1.6907, decode.loss_mask_0: 0.3004, decode.loss_dice_0: 0.4769, decode.loss_ce_1: 1.6939, decode.loss_mask_1: 0.3062, decode.loss_dice_1: 0.4645, decode.loss_ce_2: 1.6686, decode.loss_mask_2: 0.3218, decode.loss_dice_2: 0.4822, decode.loss_ce_3: 1.7092, decode.loss_mask_3: 0.2791, decode.loss_dice_3: 0.4591, decode.loss_ce_4: 1.6894, decode.loss_mask_4: 0.2897, decode.loss_dice_4: 0.4695, loss: 14.8049
2023-09-22 00:15:12,371 - mmseg - INFO - Iter [11450/160000]	lr: 9.284e-05, eta: 1 day, 0:48:49, time: 0.908, data_time: 0.277, memory: 13718, decode.loss_ce: 1.7647, decode.loss_mask: 0.3240, decode.loss_dice: 0.4845, decode.loss_ce_0: 1.7571, decode.loss_mask_0: 0.3123, decode.loss_dice_0: 0.4830, decode.loss_ce_1: 1.7511, decode.loss_mask_1: 0.3206, decode.loss_dice_1: 0.4881, decode.loss_ce_2: 1.7626, decode.loss_mask_2: 0.3072, decode.loss_dice_2: 0.4816, decode.loss_ce_3: 1.8082, decode.loss_mask_3: 0.3366, decode.loss_dice_3: 0.4759, decode.loss_ce_4: 1.7861, decode.loss_mask_4: 0.3239, decode.loss_dice_4: 0.4848, loss: 15.4523
2023-09-22 00:15:58,356 - mmseg - INFO - Iter [11500/160000]	lr: 9.281e-05, eta: 1 day, 0:51:44, time: 0.920, data_time: 0.224, memory: 13718, decode.loss_ce: 1.7212, decode.loss_mask: 0.3154, decode.loss_dice: 0.4436, decode.loss_ce_0: 1.7111, decode.loss_mask_0: 0.3333, decode.loss_dice_0: 0.4513, decode.loss_ce_1: 1.7130, decode.loss_mask_1: 0.3044, decode.loss_dice_1: 0.4415, decode.loss_ce_2: 1.6947, decode.loss_mask_2: 0.3162, decode.loss_dice_2: 0.4510, decode.loss_ce_3: 1.7012, decode.loss_mask_3: 0.3149, decode.loss_dice_3: 0.4503, decode.loss_ce_4: 1.6927, decode.loss_mask_4: 0.3193, decode.loss_dice_4: 0.4531, loss: 14.8283
2023-09-22 00:16:33,419 - mmseg - INFO - Iter [11550/160000]	lr: 9.278e-05, eta: 1 day, 0:52:18, time: 0.701, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7675, decode.loss_mask: 0.2735, decode.loss_dice: 0.4920, decode.loss_ce_0: 1.7547, decode.loss_mask_0: 0.2833, decode.loss_dice_0: 0.4982, decode.loss_ce_1: 1.7464, decode.loss_mask_1: 0.2881, decode.loss_dice_1: 0.4983, decode.loss_ce_2: 1.7508, decode.loss_mask_2: 0.2792, decode.loss_dice_2: 0.4957, decode.loss_ce_3: 1.7326, decode.loss_mask_3: 0.2739, decode.loss_dice_3: 0.4965, decode.loss_ce_4: 1.7342, decode.loss_mask_4: 0.2733, decode.loss_dice_4: 0.4911, loss: 15.1293
2023-09-22 00:17:10,121 - mmseg - INFO - Iter [11600/160000]	lr: 9.275e-05, eta: 1 day, 0:53:11, time: 0.734, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6259, decode.loss_mask: 0.2966, decode.loss_dice: 0.4572, decode.loss_ce_0: 1.6261, decode.loss_mask_0: 0.3098, decode.loss_dice_0: 0.4732, decode.loss_ce_1: 1.6341, decode.loss_mask_1: 0.3116, decode.loss_dice_1: 0.4654, decode.loss_ce_2: 1.6093, decode.loss_mask_2: 0.3110, decode.loss_dice_2: 0.4683, decode.loss_ce_3: 1.6222, decode.loss_mask_3: 0.3010, decode.loss_dice_3: 0.4607, decode.loss_ce_4: 1.6340, decode.loss_mask_4: 0.3108, decode.loss_dice_4: 0.4598, loss: 14.3768
2023-09-22 00:17:45,622 - mmseg - INFO - Iter [11650/160000]	lr: 9.272e-05, eta: 1 day, 0:53:49, time: 0.710, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7313, decode.loss_mask: 0.3616, decode.loss_dice: 0.4594, decode.loss_ce_0: 1.7238, decode.loss_mask_0: 0.3586, decode.loss_dice_0: 0.4573, decode.loss_ce_1: 1.7270, decode.loss_mask_1: 0.3518, decode.loss_dice_1: 0.4636, decode.loss_ce_2: 1.7166, decode.loss_mask_2: 0.3488, decode.loss_dice_2: 0.4599, decode.loss_ce_3: 1.7369, decode.loss_mask_3: 0.3440, decode.loss_dice_3: 0.4613, decode.loss_ce_4: 1.7569, decode.loss_mask_4: 0.3581, decode.loss_dice_4: 0.4596, loss: 15.2767
2023-09-22 00:18:20,661 - mmseg - INFO - Iter [11700/160000]	lr: 9.269e-05, eta: 1 day, 0:54:20, time: 0.701, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8483, decode.loss_mask: 0.2935, decode.loss_dice: 0.4981, decode.loss_ce_0: 1.8321, decode.loss_mask_0: 0.2888, decode.loss_dice_0: 0.5008, decode.loss_ce_1: 1.8713, decode.loss_mask_1: 0.2880, decode.loss_dice_1: 0.4973, decode.loss_ce_2: 1.8308, decode.loss_mask_2: 0.2977, decode.loss_dice_2: 0.5094, decode.loss_ce_3: 1.8464, decode.loss_mask_3: 0.2800, decode.loss_dice_3: 0.4898, decode.loss_ce_4: 1.8337, decode.loss_mask_4: 0.2960, decode.loss_dice_4: 0.5030, loss: 15.8049
2023-09-22 00:18:56,250 - mmseg - INFO - Iter [11750/160000]	lr: 9.266e-05, eta: 1 day, 0:54:57, time: 0.712, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8030, decode.loss_mask: 0.3318, decode.loss_dice: 0.4881, decode.loss_ce_0: 1.7935, decode.loss_mask_0: 0.3132, decode.loss_dice_0: 0.4841, decode.loss_ce_1: 1.7882, decode.loss_mask_1: 0.3210, decode.loss_dice_1: 0.4893, decode.loss_ce_2: 1.7759, decode.loss_mask_2: 0.3157, decode.loss_dice_2: 0.4897, decode.loss_ce_3: 1.8143, decode.loss_mask_3: 0.3337, decode.loss_dice_3: 0.4833, decode.loss_ce_4: 1.7825, decode.loss_mask_4: 0.3175, decode.loss_dice_4: 0.4847, loss: 15.6094
2023-09-22 00:19:30,782 - mmseg - INFO - Iter [11800/160000]	lr: 9.263e-05, eta: 1 day, 0:55:21, time: 0.691, data_time: 0.011, memory: 13718, decode.loss_ce: 1.5639, decode.loss_mask: 0.2831, decode.loss_dice: 0.4244, decode.loss_ce_0: 1.5632, decode.loss_mask_0: 0.2846, decode.loss_dice_0: 0.4247, decode.loss_ce_1: 1.5696, decode.loss_mask_1: 0.2897, decode.loss_dice_1: 0.4146, decode.loss_ce_2: 1.5630, decode.loss_mask_2: 0.2787, decode.loss_dice_2: 0.4220, decode.loss_ce_3: 1.5675, decode.loss_mask_3: 0.2845, decode.loss_dice_3: 0.4244, decode.loss_ce_4: 1.5626, decode.loss_mask_4: 0.2741, decode.loss_dice_4: 0.4293, loss: 13.6238
2023-09-22 00:20:04,995 - mmseg - INFO - Iter [11850/160000]	lr: 9.259e-05, eta: 1 day, 0:55:40, time: 0.684, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6040, decode.loss_mask: 0.2643, decode.loss_dice: 0.4576, decode.loss_ce_0: 1.6005, decode.loss_mask_0: 0.2750, decode.loss_dice_0: 0.4584, decode.loss_ce_1: 1.6122, decode.loss_mask_1: 0.2569, decode.loss_dice_1: 0.4487, decode.loss_ce_2: 1.5881, decode.loss_mask_2: 0.2660, decode.loss_dice_2: 0.4523, decode.loss_ce_3: 1.6215, decode.loss_mask_3: 0.2656, decode.loss_dice_3: 0.4562, decode.loss_ce_4: 1.6100, decode.loss_mask_4: 0.2615, decode.loss_dice_4: 0.4528, loss: 13.9517
2023-09-22 00:20:40,136 - mmseg - INFO - Iter [11900/160000]	lr: 9.256e-05, eta: 1 day, 0:56:10, time: 0.703, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7482, decode.loss_mask: 0.3486, decode.loss_dice: 0.5129, decode.loss_ce_0: 1.7791, decode.loss_mask_0: 0.3523, decode.loss_dice_0: 0.5140, decode.loss_ce_1: 1.7643, decode.loss_mask_1: 0.3657, decode.loss_dice_1: 0.5100, decode.loss_ce_2: 1.7717, decode.loss_mask_2: 0.3583, decode.loss_dice_2: 0.5143, decode.loss_ce_3: 1.7488, decode.loss_mask_3: 0.3536, decode.loss_dice_3: 0.5199, decode.loss_ce_4: 1.7784, decode.loss_mask_4: 0.3503, decode.loss_dice_4: 0.5174, loss: 15.8081
2023-09-22 00:21:15,377 - mmseg - INFO - Iter [11950/160000]	lr: 9.253e-05, eta: 1 day, 0:56:41, time: 0.705, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8145, decode.loss_mask: 0.3883, decode.loss_dice: 0.5415, decode.loss_ce_0: 1.7933, decode.loss_mask_0: 0.3822, decode.loss_dice_0: 0.5386, decode.loss_ce_1: 1.8170, decode.loss_mask_1: 0.3986, decode.loss_dice_1: 0.5392, decode.loss_ce_2: 1.8152, decode.loss_mask_2: 0.3842, decode.loss_dice_2: 0.5306, decode.loss_ce_3: 1.7886, decode.loss_mask_3: 0.3888, decode.loss_dice_3: 0.5533, decode.loss_ce_4: 1.7888, decode.loss_mask_4: 0.3793, decode.loss_dice_4: 0.5319, loss: 16.3740
2023-09-22 00:21:51,168 - mmseg - INFO - Saving checkpoint at 12000 iterations
2023-09-22 00:21:54,810 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:21:54,810 - mmseg - INFO - Iter [12000/160000]	lr: 9.250e-05, eta: 1 day, 0:58:02, time: 0.789, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6943, decode.loss_mask: 0.3450, decode.loss_dice: 0.4629, decode.loss_ce_0: 1.7078, decode.loss_mask_0: 0.3264, decode.loss_dice_0: 0.4612, decode.loss_ce_1: 1.6769, decode.loss_mask_1: 0.3211, decode.loss_dice_1: 0.4582, decode.loss_ce_2: 1.6976, decode.loss_mask_2: 0.3433, decode.loss_dice_2: 0.4636, decode.loss_ce_3: 1.6904, decode.loss_mask_3: 0.3438, decode.loss_dice_3: 0.4658, decode.loss_ce_4: 1.6953, decode.loss_mask_4: 0.3373, decode.loss_dice_4: 0.4560, loss: 14.9467
2023-09-22 00:22:30,074 - mmseg - INFO - Iter [12050/160000]	lr: 9.247e-05, eta: 1 day, 0:58:32, time: 0.705, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6240, decode.loss_mask: 0.3337, decode.loss_dice: 0.5069, decode.loss_ce_0: 1.6331, decode.loss_mask_0: 0.2934, decode.loss_dice_0: 0.4915, decode.loss_ce_1: 1.6312, decode.loss_mask_1: 0.3079, decode.loss_dice_1: 0.4903, decode.loss_ce_2: 1.6342, decode.loss_mask_2: 0.3024, decode.loss_dice_2: 0.4939, decode.loss_ce_3: 1.6057, decode.loss_mask_3: 0.3082, decode.loss_dice_3: 0.4930, decode.loss_ce_4: 1.6619, decode.loss_mask_4: 0.3065, decode.loss_dice_4: 0.4949, loss: 14.6126
2023-09-22 00:23:04,153 - mmseg - INFO - Iter [12100/160000]	lr: 9.244e-05, eta: 1 day, 0:58:47, time: 0.682, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6559, decode.loss_mask: 0.3003, decode.loss_dice: 0.4357, decode.loss_ce_0: 1.6474, decode.loss_mask_0: 0.2931, decode.loss_dice_0: 0.4447, decode.loss_ce_1: 1.6343, decode.loss_mask_1: 0.2887, decode.loss_dice_1: 0.4368, decode.loss_ce_2: 1.6341, decode.loss_mask_2: 0.2891, decode.loss_dice_2: 0.4350, decode.loss_ce_3: 1.6397, decode.loss_mask_3: 0.3109, decode.loss_dice_3: 0.4409, decode.loss_ce_4: 1.6370, decode.loss_mask_4: 0.3000, decode.loss_dice_4: 0.4393, loss: 14.2628
2023-09-22 00:23:38,574 - mmseg - INFO - Iter [12150/160000]	lr: 9.241e-05, eta: 1 day, 0:59:06, time: 0.688, data_time: 0.011, memory: 13718, decode.loss_ce: 1.6516, decode.loss_mask: 0.3080, decode.loss_dice: 0.4419, decode.loss_ce_0: 1.6414, decode.loss_mask_0: 0.3143, decode.loss_dice_0: 0.4469, decode.loss_ce_1: 1.6640, decode.loss_mask_1: 0.3184, decode.loss_dice_1: 0.4521, decode.loss_ce_2: 1.6477, decode.loss_mask_2: 0.3116, decode.loss_dice_2: 0.4476, decode.loss_ce_3: 1.6354, decode.loss_mask_3: 0.3213, decode.loss_dice_3: 0.4512, decode.loss_ce_4: 1.6461, decode.loss_mask_4: 0.2994, decode.loss_dice_4: 0.4436, loss: 14.4424
2023-09-22 00:24:13,116 - mmseg - INFO - Iter [12200/160000]	lr: 9.238e-05, eta: 1 day, 0:59:25, time: 0.691, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7564, decode.loss_mask: 0.3134, decode.loss_dice: 0.4519, decode.loss_ce_0: 1.7589, decode.loss_mask_0: 0.3115, decode.loss_dice_0: 0.4583, decode.loss_ce_1: 1.7829, decode.loss_mask_1: 0.3306, decode.loss_dice_1: 0.4660, decode.loss_ce_2: 1.7473, decode.loss_mask_2: 0.3188, decode.loss_dice_2: 0.4535, decode.loss_ce_3: 1.7492, decode.loss_mask_3: 0.3364, decode.loss_dice_3: 0.4573, decode.loss_ce_4: 1.7373, decode.loss_mask_4: 0.3333, decode.loss_dice_4: 0.4510, loss: 15.2140
2023-09-22 00:24:47,244 - mmseg - INFO - Iter [12250/160000]	lr: 9.234e-05, eta: 1 day, 0:59:39, time: 0.683, data_time: 0.011, memory: 13718, decode.loss_ce: 1.8199, decode.loss_mask: 0.3552, decode.loss_dice: 0.5029, decode.loss_ce_0: 1.7808, decode.loss_mask_0: 0.3456, decode.loss_dice_0: 0.4985, decode.loss_ce_1: 1.8161, decode.loss_mask_1: 0.3439, decode.loss_dice_1: 0.4953, decode.loss_ce_2: 1.8072, decode.loss_mask_2: 0.3692, decode.loss_dice_2: 0.5095, decode.loss_ce_3: 1.8126, decode.loss_mask_3: 0.3530, decode.loss_dice_3: 0.4966, decode.loss_ce_4: 1.8556, decode.loss_mask_4: 0.3556, decode.loss_dice_4: 0.4994, loss: 16.0169
2023-09-22 00:25:24,166 - mmseg - INFO - Iter [12300/160000]	lr: 9.231e-05, eta: 1 day, 1:00:26, time: 0.738, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7949, decode.loss_mask: 0.3605, decode.loss_dice: 0.5165, decode.loss_ce_0: 1.7967, decode.loss_mask_0: 0.3425, decode.loss_dice_0: 0.5105, decode.loss_ce_1: 1.8307, decode.loss_mask_1: 0.3491, decode.loss_dice_1: 0.5107, decode.loss_ce_2: 1.8050, decode.loss_mask_2: 0.3514, decode.loss_dice_2: 0.5180, decode.loss_ce_3: 1.7987, decode.loss_mask_3: 0.3597, decode.loss_dice_3: 0.5105, decode.loss_ce_4: 1.8195, decode.loss_mask_4: 0.3567, decode.loss_dice_4: 0.5138, loss: 16.0456
2023-09-22 00:25:58,715 - mmseg - INFO - Iter [12350/160000]	lr: 9.228e-05, eta: 1 day, 1:00:45, time: 0.691, data_time: 0.010, memory: 13718, decode.loss_ce: 1.5594, decode.loss_mask: 0.3952, decode.loss_dice: 0.5004, decode.loss_ce_0: 1.6038, decode.loss_mask_0: 0.4230, decode.loss_dice_0: 0.5098, decode.loss_ce_1: 1.5641, decode.loss_mask_1: 0.4119, decode.loss_dice_1: 0.5097, decode.loss_ce_2: 1.5622, decode.loss_mask_2: 0.3810, decode.loss_dice_2: 0.4924, decode.loss_ce_3: 1.5787, decode.loss_mask_3: 0.4063, decode.loss_dice_3: 0.5047, decode.loss_ce_4: 1.5835, decode.loss_mask_4: 0.4076, decode.loss_dice_4: 0.5028, loss: 14.8965
2023-09-22 00:26:33,617 - mmseg - INFO - Iter [12400/160000]	lr: 9.225e-05, eta: 1 day, 1:01:07, time: 0.698, data_time: 0.012, memory: 13718, decode.loss_ce: 1.6481, decode.loss_mask: 0.3408, decode.loss_dice: 0.4913, decode.loss_ce_0: 1.6874, decode.loss_mask_0: 0.3821, decode.loss_dice_0: 0.4836, decode.loss_ce_1: 1.6816, decode.loss_mask_1: 0.3556, decode.loss_dice_1: 0.4939, decode.loss_ce_2: 1.6844, decode.loss_mask_2: 0.3337, decode.loss_dice_2: 0.4838, decode.loss_ce_3: 1.6492, decode.loss_mask_3: 0.3507, decode.loss_dice_3: 0.4870, decode.loss_ce_4: 1.6405, decode.loss_mask_4: 0.3348, decode.loss_dice_4: 0.4868, loss: 15.0153
2023-09-22 00:27:08,400 - mmseg - INFO - Iter [12450/160000]	lr: 9.222e-05, eta: 1 day, 1:01:27, time: 0.696, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7758, decode.loss_mask: 0.3475, decode.loss_dice: 0.5082, decode.loss_ce_0: 1.8312, decode.loss_mask_0: 0.4059, decode.loss_dice_0: 0.5073, decode.loss_ce_1: 1.7984, decode.loss_mask_1: 0.3383, decode.loss_dice_1: 0.5059, decode.loss_ce_2: 1.7742, decode.loss_mask_2: 0.3495, decode.loss_dice_2: 0.5094, decode.loss_ce_3: 1.7781, decode.loss_mask_3: 0.3581, decode.loss_dice_3: 0.5044, decode.loss_ce_4: 1.7846, decode.loss_mask_4: 0.3511, decode.loss_dice_4: 0.5058, loss: 15.9338
2023-09-22 00:27:43,628 - mmseg - INFO - Iter [12500/160000]	lr: 9.219e-05, eta: 1 day, 1:01:52, time: 0.705, data_time: 0.012, memory: 13718, decode.loss_ce: 1.8027, decode.loss_mask: 0.3365, decode.loss_dice: 0.5271, decode.loss_ce_0: 1.8464, decode.loss_mask_0: 0.3591, decode.loss_dice_0: 0.5415, decode.loss_ce_1: 1.8417, decode.loss_mask_1: 0.3343, decode.loss_dice_1: 0.5301, decode.loss_ce_2: 1.8507, decode.loss_mask_2: 0.3287, decode.loss_dice_2: 0.5328, decode.loss_ce_3: 1.8318, decode.loss_mask_3: 0.3359, decode.loss_dice_3: 0.5283, decode.loss_ce_4: 1.8336, decode.loss_mask_4: 0.3419, decode.loss_dice_4: 0.5291, loss: 16.2323
2023-09-22 00:28:17,989 - mmseg - INFO - Iter [12550/160000]	lr: 9.216e-05, eta: 1 day, 1:02:06, time: 0.687, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7455, decode.loss_mask: 0.2809, decode.loss_dice: 0.4442, decode.loss_ce_0: 1.7515, decode.loss_mask_0: 0.2911, decode.loss_dice_0: 0.4558, decode.loss_ce_1: 1.7224, decode.loss_mask_1: 0.2900, decode.loss_dice_1: 0.4587, decode.loss_ce_2: 1.7138, decode.loss_mask_2: 0.2819, decode.loss_dice_2: 0.4615, decode.loss_ce_3: 1.7132, decode.loss_mask_3: 0.2989, decode.loss_dice_3: 0.4515, decode.loss_ce_4: 1.7338, decode.loss_mask_4: 0.2799, decode.loss_dice_4: 0.4508, loss: 14.8255
2023-09-22 00:28:47,453 - mmseg - INFO - Iter [12600/160000]	lr: 9.213e-05, eta: 1 day, 1:01:22, time: 0.589, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6589, decode.loss_mask: 0.3065, decode.loss_dice: 0.4532, decode.loss_ce_0: 1.6546, decode.loss_mask_0: 0.3022, decode.loss_dice_0: 0.4569, decode.loss_ce_1: 1.6557, decode.loss_mask_1: 0.3165, decode.loss_dice_1: 0.4627, decode.loss_ce_2: 1.6385, decode.loss_mask_2: 0.2956, decode.loss_dice_2: 0.4540, decode.loss_ce_3: 1.6383, decode.loss_mask_3: 0.2966, decode.loss_dice_3: 0.4501, decode.loss_ce_4: 1.6380, decode.loss_mask_4: 0.2868, decode.loss_dice_4: 0.4529, loss: 14.4181
2023-09-22 00:29:18,405 - mmseg - INFO - Iter [12650/160000]	lr: 9.209e-05, eta: 1 day, 1:00:57, time: 0.619, data_time: 0.011, memory: 13718, decode.loss_ce: 1.7830, decode.loss_mask: 0.3448, decode.loss_dice: 0.4658, decode.loss_ce_0: 1.7487, decode.loss_mask_0: 0.3326, decode.loss_dice_0: 0.4762, decode.loss_ce_1: 1.7679, decode.loss_mask_1: 0.3364, decode.loss_dice_1: 0.4697, decode.loss_ce_2: 1.7495, decode.loss_mask_2: 0.3325, decode.loss_dice_2: 0.4681, decode.loss_ce_3: 1.7382, decode.loss_mask_3: 0.3444, decode.loss_dice_3: 0.4632, decode.loss_ce_4: 1.7704, decode.loss_mask_4: 0.3620, decode.loss_dice_4: 0.4672, loss: 15.4206
2023-09-22 00:29:48,681 - mmseg - INFO - Iter [12700/160000]	lr: 9.206e-05, eta: 1 day, 1:00:23, time: 0.606, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6601, decode.loss_mask: 0.3338, decode.loss_dice: 0.4827, decode.loss_ce_0: 1.6552, decode.loss_mask_0: 0.3256, decode.loss_dice_0: 0.4837, decode.loss_ce_1: 1.6323, decode.loss_mask_1: 0.3388, decode.loss_dice_1: 0.4806, decode.loss_ce_2: 1.6674, decode.loss_mask_2: 0.3308, decode.loss_dice_2: 0.4801, decode.loss_ce_3: 1.6762, decode.loss_mask_3: 0.3444, decode.loss_dice_3: 0.4873, decode.loss_ce_4: 1.6435, decode.loss_mask_4: 0.3379, decode.loss_dice_4: 0.4879, loss: 14.8483
2023-09-22 00:30:18,471 - mmseg - INFO - Iter [12750/160000]	lr: 9.203e-05, eta: 1 day, 0:59:43, time: 0.596, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6711, decode.loss_mask: 0.3184, decode.loss_dice: 0.4236, decode.loss_ce_0: 1.6229, decode.loss_mask_0: 0.2946, decode.loss_dice_0: 0.4334, decode.loss_ce_1: 1.6046, decode.loss_mask_1: 0.2928, decode.loss_dice_1: 0.4253, decode.loss_ce_2: 1.6130, decode.loss_mask_2: 0.2936, decode.loss_dice_2: 0.4275, decode.loss_ce_3: 1.6613, decode.loss_mask_3: 0.3032, decode.loss_dice_3: 0.4232, decode.loss_ce_4: 1.6348, decode.loss_mask_4: 0.2938, decode.loss_dice_4: 0.4235, loss: 14.1605
2023-09-22 00:30:48,315 - mmseg - INFO - Iter [12800/160000]	lr: 9.200e-05, eta: 1 day, 0:59:05, time: 0.597, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7101, decode.loss_mask: 0.2965, decode.loss_dice: 0.4557, decode.loss_ce_0: 1.6736, decode.loss_mask_0: 0.2936, decode.loss_dice_0: 0.4655, decode.loss_ce_1: 1.6811, decode.loss_mask_1: 0.2906, decode.loss_dice_1: 0.4638, decode.loss_ce_2: 1.6712, decode.loss_mask_2: 0.2998, decode.loss_dice_2: 0.4660, decode.loss_ce_3: 1.6889, decode.loss_mask_3: 0.2826, decode.loss_dice_3: 0.4563, decode.loss_ce_4: 1.6725, decode.loss_mask_4: 0.2948, decode.loss_dice_4: 0.4597, loss: 14.6225
2023-09-22 00:31:17,016 - mmseg - INFO - Iter [12850/160000]	lr: 9.197e-05, eta: 1 day, 0:58:13, time: 0.574, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6257, decode.loss_mask: 0.3093, decode.loss_dice: 0.4317, decode.loss_ce_0: 1.6010, decode.loss_mask_0: 0.2977, decode.loss_dice_0: 0.4351, decode.loss_ce_1: 1.6200, decode.loss_mask_1: 0.3073, decode.loss_dice_1: 0.4316, decode.loss_ce_2: 1.6394, decode.loss_mask_2: 0.2975, decode.loss_dice_2: 0.4340, decode.loss_ce_3: 1.6202, decode.loss_mask_3: 0.3070, decode.loss_dice_3: 0.4345, decode.loss_ce_4: 1.6245, decode.loss_mask_4: 0.3242, decode.loss_dice_4: 0.4367, loss: 14.1773
2023-09-22 00:31:43,092 - mmseg - INFO - Iter [12900/160000]	lr: 9.194e-05, eta: 1 day, 0:56:51, time: 0.522, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7031, decode.loss_mask: 0.3329, decode.loss_dice: 0.4703, decode.loss_ce_0: 1.7303, decode.loss_mask_0: 0.3474, decode.loss_dice_0: 0.4698, decode.loss_ce_1: 1.6976, decode.loss_mask_1: 0.3265, decode.loss_dice_1: 0.4661, decode.loss_ce_2: 1.7048, decode.loss_mask_2: 0.3116, decode.loss_dice_2: 0.4677, decode.loss_ce_3: 1.7033, decode.loss_mask_3: 0.3242, decode.loss_dice_3: 0.4670, decode.loss_ce_4: 1.7069, decode.loss_mask_4: 0.3107, decode.loss_dice_4: 0.4668, loss: 15.0070
2023-09-22 00:32:10,171 - mmseg - INFO - Iter [12950/160000]	lr: 9.191e-05, eta: 1 day, 0:55:42, time: 0.542, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7062, decode.loss_mask: 0.3533, decode.loss_dice: 0.4856, decode.loss_ce_0: 1.6839, decode.loss_mask_0: 0.3302, decode.loss_dice_0: 0.4786, decode.loss_ce_1: 1.6468, decode.loss_mask_1: 0.3468, decode.loss_dice_1: 0.4788, decode.loss_ce_2: 1.6846, decode.loss_mask_2: 0.3176, decode.loss_dice_2: 0.4754, decode.loss_ce_3: 1.6904, decode.loss_mask_3: 0.3424, decode.loss_dice_3: 0.4762, decode.loss_ce_4: 1.6940, decode.loss_mask_4: 0.3577, decode.loss_dice_4: 0.4806, loss: 15.0291
2023-09-22 00:32:38,842 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:32:38,843 - mmseg - INFO - Iter [13000/160000]	lr: 9.188e-05, eta: 1 day, 0:54:50, time: 0.573, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6821, decode.loss_mask: 0.3095, decode.loss_dice: 0.4805, decode.loss_ce_0: 1.7250, decode.loss_mask_0: 0.3044, decode.loss_dice_0: 0.4653, decode.loss_ce_1: 1.6899, decode.loss_mask_1: 0.3038, decode.loss_dice_1: 0.4549, decode.loss_ce_2: 1.7011, decode.loss_mask_2: 0.3034, decode.loss_dice_2: 0.4708, decode.loss_ce_3: 1.7113, decode.loss_mask_3: 0.3013, decode.loss_dice_3: 0.4679, decode.loss_ce_4: 1.7168, decode.loss_mask_4: 0.3013, decode.loss_dice_4: 0.4716, loss: 14.8610
2023-09-22 00:33:20,331 - mmseg - INFO - Iter [13050/160000]	lr: 9.184e-05, eta: 1 day, 0:56:23, time: 0.830, data_time: 0.275, memory: 13718, decode.loss_ce: 1.6343, decode.loss_mask: 0.2939, decode.loss_dice: 0.4375, decode.loss_ce_0: 1.6342, decode.loss_mask_0: 0.3257, decode.loss_dice_0: 0.4484, decode.loss_ce_1: 1.6385, decode.loss_mask_1: 0.3064, decode.loss_dice_1: 0.4309, decode.loss_ce_2: 1.6629, decode.loss_mask_2: 0.3084, decode.loss_dice_2: 0.4342, decode.loss_ce_3: 1.6370, decode.loss_mask_3: 0.2932, decode.loss_dice_3: 0.4324, decode.loss_ce_4: 1.6385, decode.loss_mask_4: 0.2971, decode.loss_dice_4: 0.4321, loss: 14.2856
2023-09-22 00:33:53,931 - mmseg - INFO - Iter [13100/160000]	lr: 9.181e-05, eta: 1 day, 0:56:27, time: 0.672, data_time: 0.146, memory: 13718, decode.loss_ce: 1.8239, decode.loss_mask: 0.3280, decode.loss_dice: 0.4717, decode.loss_ce_0: 1.8010, decode.loss_mask_0: 0.3131, decode.loss_dice_0: 0.4798, decode.loss_ce_1: 1.8119, decode.loss_mask_1: 0.3433, decode.loss_dice_1: 0.4778, decode.loss_ce_2: 1.8101, decode.loss_mask_2: 0.3116, decode.loss_dice_2: 0.4676, decode.loss_ce_3: 1.7900, decode.loss_mask_3: 0.3054, decode.loss_dice_3: 0.4717, decode.loss_ce_4: 1.8166, decode.loss_mask_4: 0.3132, decode.loss_dice_4: 0.4661, loss: 15.6029
2023-09-22 00:34:20,031 - mmseg - INFO - Iter [13150/160000]	lr: 9.178e-05, eta: 1 day, 0:55:07, time: 0.522, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7419, decode.loss_mask: 0.3551, decode.loss_dice: 0.4974, decode.loss_ce_0: 1.7347, decode.loss_mask_0: 0.3418, decode.loss_dice_0: 0.4916, decode.loss_ce_1: 1.7354, decode.loss_mask_1: 0.3454, decode.loss_dice_1: 0.4859, decode.loss_ce_2: 1.7500, decode.loss_mask_2: 0.3465, decode.loss_dice_2: 0.4936, decode.loss_ce_3: 1.7611, decode.loss_mask_3: 0.3418, decode.loss_dice_3: 0.4952, decode.loss_ce_4: 1.7629, decode.loss_mask_4: 0.3672, decode.loss_dice_4: 0.5033, loss: 15.5508
2023-09-22 00:34:46,580 - mmseg - INFO - Iter [13200/160000]	lr: 9.175e-05, eta: 1 day, 0:53:52, time: 0.531, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6620, decode.loss_mask: 0.3585, decode.loss_dice: 0.4598, decode.loss_ce_0: 1.6996, decode.loss_mask_0: 0.3466, decode.loss_dice_0: 0.4533, decode.loss_ce_1: 1.6551, decode.loss_mask_1: 0.3391, decode.loss_dice_1: 0.4506, decode.loss_ce_2: 1.6786, decode.loss_mask_2: 0.3480, decode.loss_dice_2: 0.4523, decode.loss_ce_3: 1.6723, decode.loss_mask_3: 0.3398, decode.loss_dice_3: 0.4498, decode.loss_ce_4: 1.6656, decode.loss_mask_4: 0.3463, decode.loss_dice_4: 0.4550, loss: 14.8324
2023-09-22 00:35:12,799 - mmseg - INFO - Iter [13250/160000]	lr: 9.172e-05, eta: 1 day, 0:52:33, time: 0.524, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7407, decode.loss_mask: 0.3484, decode.loss_dice: 0.4938, decode.loss_ce_0: 1.7713, decode.loss_mask_0: 0.3416, decode.loss_dice_0: 0.4774, decode.loss_ce_1: 1.7439, decode.loss_mask_1: 0.3401, decode.loss_dice_1: 0.4839, decode.loss_ce_2: 1.7463, decode.loss_mask_2: 0.3381, decode.loss_dice_2: 0.4868, decode.loss_ce_3: 1.7434, decode.loss_mask_3: 0.3316, decode.loss_dice_3: 0.4838, decode.loss_ce_4: 1.7685, decode.loss_mask_4: 0.3274, decode.loss_dice_4: 0.4851, loss: 15.4522
2023-09-22 00:35:38,609 - mmseg - INFO - Iter [13300/160000]	lr: 9.169e-05, eta: 1 day, 0:51:11, time: 0.516, data_time: 0.007, memory: 13718, decode.loss_ce: 1.6358, decode.loss_mask: 0.3010, decode.loss_dice: 0.4811, decode.loss_ce_0: 1.6629, decode.loss_mask_0: 0.3111, decode.loss_dice_0: 0.4820, decode.loss_ce_1: 1.6302, decode.loss_mask_1: 0.3012, decode.loss_dice_1: 0.4834, decode.loss_ce_2: 1.6455, decode.loss_mask_2: 0.3008, decode.loss_dice_2: 0.4868, decode.loss_ce_3: 1.6601, decode.loss_mask_3: 0.2859, decode.loss_dice_3: 0.4759, decode.loss_ce_4: 1.6482, decode.loss_mask_4: 0.3034, decode.loss_dice_4: 0.4826, loss: 14.5780
2023-09-22 00:36:04,530 - mmseg - INFO - Iter [13350/160000]	lr: 9.166e-05, eta: 1 day, 0:49:50, time: 0.518, data_time: 0.007, memory: 13718, decode.loss_ce: 1.6909, decode.loss_mask: 0.2824, decode.loss_dice: 0.4823, decode.loss_ce_0: 1.7346, decode.loss_mask_0: 0.2928, decode.loss_dice_0: 0.4756, decode.loss_ce_1: 1.6907, decode.loss_mask_1: 0.2877, decode.loss_dice_1: 0.4742, decode.loss_ce_2: 1.7375, decode.loss_mask_2: 0.2796, decode.loss_dice_2: 0.4728, decode.loss_ce_3: 1.7234, decode.loss_mask_3: 0.2768, decode.loss_dice_3: 0.4704, decode.loss_ce_4: 1.7093, decode.loss_mask_4: 0.2769, decode.loss_dice_4: 0.4824, loss: 14.8405
2023-09-22 00:36:30,472 - mmseg - INFO - Iter [13400/160000]	lr: 9.163e-05, eta: 1 day, 0:48:30, time: 0.519, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7136, decode.loss_mask: 0.2916, decode.loss_dice: 0.4553, decode.loss_ce_0: 1.7257, decode.loss_mask_0: 0.2954, decode.loss_dice_0: 0.4578, decode.loss_ce_1: 1.6980, decode.loss_mask_1: 0.2803, decode.loss_dice_1: 0.4579, decode.loss_ce_2: 1.7451, decode.loss_mask_2: 0.2830, decode.loss_dice_2: 0.4466, decode.loss_ce_3: 1.7485, decode.loss_mask_3: 0.3015, decode.loss_dice_3: 0.4584, decode.loss_ce_4: 1.7374, decode.loss_mask_4: 0.2970, decode.loss_dice_4: 0.4616, loss: 14.8547
2023-09-22 00:37:02,074 - mmseg - INFO - Iter [13450/160000]	lr: 9.159e-05, eta: 1 day, 0:48:12, time: 0.632, data_time: 0.009, memory: 13718, decode.loss_ce: 1.7756, decode.loss_mask: 0.3476, decode.loss_dice: 0.4668, decode.loss_ce_0: 1.7720, decode.loss_mask_0: 0.3506, decode.loss_dice_0: 0.4665, decode.loss_ce_1: 1.7804, decode.loss_mask_1: 0.3461, decode.loss_dice_1: 0.4639, decode.loss_ce_2: 1.7986, decode.loss_mask_2: 0.3598, decode.loss_dice_2: 0.4582, decode.loss_ce_3: 1.7740, decode.loss_mask_3: 0.3694, decode.loss_dice_3: 0.4777, decode.loss_ce_4: 1.7608, decode.loss_mask_4: 0.3425, decode.loss_dice_4: 0.4726, loss: 15.5829
2023-09-22 00:37:31,010 - mmseg - INFO - Iter [13500/160000]	lr: 9.156e-05, eta: 1 day, 0:47:25, time: 0.579, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7650, decode.loss_mask: 0.3157, decode.loss_dice: 0.4689, decode.loss_ce_0: 1.7781, decode.loss_mask_0: 0.3073, decode.loss_dice_0: 0.4755, decode.loss_ce_1: 1.7440, decode.loss_mask_1: 0.3074, decode.loss_dice_1: 0.4678, decode.loss_ce_2: 1.7657, decode.loss_mask_2: 0.3037, decode.loss_dice_2: 0.4713, decode.loss_ce_3: 1.7510, decode.loss_mask_3: 0.3115, decode.loss_dice_3: 0.4713, decode.loss_ce_4: 1.7599, decode.loss_mask_4: 0.3153, decode.loss_dice_4: 0.4704, loss: 15.2497
2023-09-22 00:38:00,215 - mmseg - INFO - Iter [13550/160000]	lr: 9.153e-05, eta: 1 day, 0:46:41, time: 0.584, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7437, decode.loss_mask: 0.2977, decode.loss_dice: 0.4640, decode.loss_ce_0: 1.7007, decode.loss_mask_0: 0.2929, decode.loss_dice_0: 0.4595, decode.loss_ce_1: 1.6936, decode.loss_mask_1: 0.2909, decode.loss_dice_1: 0.4550, decode.loss_ce_2: 1.7092, decode.loss_mask_2: 0.2961, decode.loss_dice_2: 0.4519, decode.loss_ce_3: 1.7244, decode.loss_mask_3: 0.2996, decode.loss_dice_3: 0.4571, decode.loss_ce_4: 1.7171, decode.loss_mask_4: 0.2930, decode.loss_dice_4: 0.4608, loss: 14.8072
2023-09-22 00:38:28,526 - mmseg - INFO - Iter [13600/160000]	lr: 9.150e-05, eta: 1 day, 0:45:48, time: 0.566, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6376, decode.loss_mask: 0.3274, decode.loss_dice: 0.4140, decode.loss_ce_0: 1.6448, decode.loss_mask_0: 0.3107, decode.loss_dice_0: 0.4204, decode.loss_ce_1: 1.6248, decode.loss_mask_1: 0.3132, decode.loss_dice_1: 0.4172, decode.loss_ce_2: 1.6457, decode.loss_mask_2: 0.3301, decode.loss_dice_2: 0.4177, decode.loss_ce_3: 1.6792, decode.loss_mask_3: 0.3417, decode.loss_dice_3: 0.4180, decode.loss_ce_4: 1.6390, decode.loss_mask_4: 0.3125, decode.loss_dice_4: 0.4149, loss: 14.3088
2023-09-22 00:38:54,461 - mmseg - INFO - Iter [13650/160000]	lr: 9.147e-05, eta: 1 day, 0:44:29, time: 0.519, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7808, decode.loss_mask: 0.2766, decode.loss_dice: 0.4617, decode.loss_ce_0: 1.7918, decode.loss_mask_0: 0.2635, decode.loss_dice_0: 0.4608, decode.loss_ce_1: 1.7900, decode.loss_mask_1: 0.2602, decode.loss_dice_1: 0.4602, decode.loss_ce_2: 1.7833, decode.loss_mask_2: 0.2656, decode.loss_dice_2: 0.4559, decode.loss_ce_3: 1.7775, decode.loss_mask_3: 0.2592, decode.loss_dice_3: 0.4610, decode.loss_ce_4: 1.7774, decode.loss_mask_4: 0.2584, decode.loss_dice_4: 0.4610, loss: 15.0449
2023-09-22 00:39:20,547 - mmseg - INFO - Iter [13700/160000]	lr: 9.144e-05, eta: 1 day, 0:43:12, time: 0.522, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6635, decode.loss_mask: 0.3070, decode.loss_dice: 0.4539, decode.loss_ce_0: 1.6654, decode.loss_mask_0: 0.3061, decode.loss_dice_0: 0.4522, decode.loss_ce_1: 1.6499, decode.loss_mask_1: 0.2975, decode.loss_dice_1: 0.4527, decode.loss_ce_2: 1.6766, decode.loss_mask_2: 0.3121, decode.loss_dice_2: 0.4471, decode.loss_ce_3: 1.6833, decode.loss_mask_3: 0.3138, decode.loss_dice_3: 0.4549, decode.loss_ce_4: 1.6775, decode.loss_mask_4: 0.3081, decode.loss_dice_4: 0.4493, loss: 14.5709
2023-09-22 00:39:46,419 - mmseg - INFO - Iter [13750/160000]	lr: 9.141e-05, eta: 1 day, 0:41:53, time: 0.517, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6487, decode.loss_mask: 0.3390, decode.loss_dice: 0.4707, decode.loss_ce_0: 1.6648, decode.loss_mask_0: 0.3272, decode.loss_dice_0: 0.4616, decode.loss_ce_1: 1.6333, decode.loss_mask_1: 0.3414, decode.loss_dice_1: 0.4697, decode.loss_ce_2: 1.6715, decode.loss_mask_2: 0.3277, decode.loss_dice_2: 0.4562, decode.loss_ce_3: 1.6544, decode.loss_mask_3: 0.3203, decode.loss_dice_3: 0.4638, decode.loss_ce_4: 1.6643, decode.loss_mask_4: 0.3205, decode.loss_dice_4: 0.4713, loss: 14.7067
2023-09-22 00:40:12,169 - mmseg - INFO - Iter [13800/160000]	lr: 9.138e-05, eta: 1 day, 0:40:33, time: 0.515, data_time: 0.007, memory: 13718, decode.loss_ce: 1.6333, decode.loss_mask: 0.2863, decode.loss_dice: 0.4571, decode.loss_ce_0: 1.6687, decode.loss_mask_0: 0.2917, decode.loss_dice_0: 0.4557, decode.loss_ce_1: 1.6555, decode.loss_mask_1: 0.2843, decode.loss_dice_1: 0.4588, decode.loss_ce_2: 1.6696, decode.loss_mask_2: 0.2977, decode.loss_dice_2: 0.4592, decode.loss_ce_3: 1.6241, decode.loss_mask_3: 0.2933, decode.loss_dice_3: 0.4620, decode.loss_ce_4: 1.6156, decode.loss_mask_4: 0.2952, decode.loss_dice_4: 0.4639, loss: 14.3717
2023-09-22 00:40:43,792 - mmseg - INFO - Iter [13850/160000]	lr: 9.134e-05, eta: 1 day, 0:40:16, time: 0.632, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8315, decode.loss_mask: 0.3353, decode.loss_dice: 0.4897, decode.loss_ce_0: 1.8605, decode.loss_mask_0: 0.3373, decode.loss_dice_0: 0.4865, decode.loss_ce_1: 1.8399, decode.loss_mask_1: 0.3290, decode.loss_dice_1: 0.4906, decode.loss_ce_2: 1.8174, decode.loss_mask_2: 0.3613, decode.loss_dice_2: 0.5006, decode.loss_ce_3: 1.8313, decode.loss_mask_3: 0.3426, decode.loss_dice_3: 0.4980, decode.loss_ce_4: 1.8412, decode.loss_mask_4: 0.3251, decode.loss_dice_4: 0.4864, loss: 16.0042
2023-09-22 00:41:12,155 - mmseg - INFO - Iter [13900/160000]	lr: 9.131e-05, eta: 1 day, 0:39:25, time: 0.567, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5574, decode.loss_mask: 0.3094, decode.loss_dice: 0.4416, decode.loss_ce_0: 1.5799, decode.loss_mask_0: 0.3173, decode.loss_dice_0: 0.4373, decode.loss_ce_1: 1.5974, decode.loss_mask_1: 0.3303, decode.loss_dice_1: 0.4446, decode.loss_ce_2: 1.5638, decode.loss_mask_2: 0.3117, decode.loss_dice_2: 0.4327, decode.loss_ce_3: 1.5571, decode.loss_mask_3: 0.3264, decode.loss_dice_3: 0.4395, decode.loss_ce_4: 1.5717, decode.loss_mask_4: 0.3141, decode.loss_dice_4: 0.4285, loss: 13.9607
2023-09-22 00:41:40,390 - mmseg - INFO - Iter [13950/160000]	lr: 9.128e-05, eta: 1 day, 0:38:32, time: 0.565, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5868, decode.loss_mask: 0.2613, decode.loss_dice: 0.4273, decode.loss_ce_0: 1.5843, decode.loss_mask_0: 0.2657, decode.loss_dice_0: 0.4316, decode.loss_ce_1: 1.5596, decode.loss_mask_1: 0.2675, decode.loss_dice_1: 0.4311, decode.loss_ce_2: 1.5878, decode.loss_mask_2: 0.2654, decode.loss_dice_2: 0.4246, decode.loss_ce_3: 1.5568, decode.loss_mask_3: 0.2641, decode.loss_dice_3: 0.4242, decode.loss_ce_4: 1.5653, decode.loss_mask_4: 0.2666, decode.loss_dice_4: 0.4221, loss: 13.5921
2023-09-22 00:42:08,580 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:42:08,580 - mmseg - INFO - Iter [14000/160000]	lr: 9.125e-05, eta: 1 day, 0:37:39, time: 0.564, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7061, decode.loss_mask: 0.2860, decode.loss_dice: 0.4880, decode.loss_ce_0: 1.7186, decode.loss_mask_0: 0.2809, decode.loss_dice_0: 0.4927, decode.loss_ce_1: 1.6936, decode.loss_mask_1: 0.2854, decode.loss_dice_1: 0.5002, decode.loss_ce_2: 1.7223, decode.loss_mask_2: 0.3069, decode.loss_dice_2: 0.4901, decode.loss_ce_3: 1.7084, decode.loss_mask_3: 0.2951, decode.loss_dice_3: 0.4933, decode.loss_ce_4: 1.7009, decode.loss_mask_4: 0.2820, decode.loss_dice_4: 0.4881, loss: 14.9387
2023-09-22 00:42:34,391 - mmseg - INFO - Iter [14050/160000]	lr: 9.122e-05, eta: 1 day, 0:36:21, time: 0.516, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6996, decode.loss_mask: 0.2846, decode.loss_dice: 0.4590, decode.loss_ce_0: 1.7868, decode.loss_mask_0: 0.2801, decode.loss_dice_0: 0.4627, decode.loss_ce_1: 1.7266, decode.loss_mask_1: 0.2910, decode.loss_dice_1: 0.4679, decode.loss_ce_2: 1.7854, decode.loss_mask_2: 0.2868, decode.loss_dice_2: 0.4574, decode.loss_ce_3: 1.7220, decode.loss_mask_3: 0.2825, decode.loss_dice_3: 0.4590, decode.loss_ce_4: 1.7095, decode.loss_mask_4: 0.2835, decode.loss_dice_4: 0.4632, loss: 14.9076
2023-09-22 00:43:04,834 - mmseg - INFO - Iter [14100/160000]	lr: 9.119e-05, eta: 1 day, 0:35:52, time: 0.609, data_time: 0.007, memory: 13718, decode.loss_ce: 1.7532, decode.loss_mask: 0.3124, decode.loss_dice: 0.4708, decode.loss_ce_0: 1.7634, decode.loss_mask_0: 0.3100, decode.loss_dice_0: 0.4685, decode.loss_ce_1: 1.7284, decode.loss_mask_1: 0.3128, decode.loss_dice_1: 0.4654, decode.loss_ce_2: 1.7333, decode.loss_mask_2: 0.2946, decode.loss_dice_2: 0.4625, decode.loss_ce_3: 1.7249, decode.loss_mask_3: 0.3082, decode.loss_dice_3: 0.4739, decode.loss_ce_4: 1.7354, decode.loss_mask_4: 0.2985, decode.loss_dice_4: 0.4636, loss: 15.0799
2023-09-22 00:43:33,894 - mmseg - INFO - Iter [14150/160000]	lr: 9.116e-05, eta: 1 day, 0:35:08, time: 0.581, data_time: 0.007, memory: 13718, decode.loss_ce: 1.5394, decode.loss_mask: 0.3158, decode.loss_dice: 0.4362, decode.loss_ce_0: 1.5402, decode.loss_mask_0: 0.3130, decode.loss_dice_0: 0.4365, decode.loss_ce_1: 1.5479, decode.loss_mask_1: 0.2991, decode.loss_dice_1: 0.4306, decode.loss_ce_2: 1.5573, decode.loss_mask_2: 0.3184, decode.loss_dice_2: 0.4296, decode.loss_ce_3: 1.5241, decode.loss_mask_3: 0.3116, decode.loss_dice_3: 0.4405, decode.loss_ce_4: 1.5201, decode.loss_mask_4: 0.3110, decode.loss_dice_4: 0.4299, loss: 13.7012
2023-09-22 00:44:02,669 - mmseg - INFO - Iter [14200/160000]	lr: 9.113e-05, eta: 1 day, 0:34:22, time: 0.575, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6567, decode.loss_mask: 0.3129, decode.loss_dice: 0.4904, decode.loss_ce_0: 1.6695, decode.loss_mask_0: 0.3088, decode.loss_dice_0: 0.4882, decode.loss_ce_1: 1.6850, decode.loss_mask_1: 0.3174, decode.loss_dice_1: 0.4840, decode.loss_ce_2: 1.6459, decode.loss_mask_2: 0.3077, decode.loss_dice_2: 0.4852, decode.loss_ce_3: 1.6622, decode.loss_mask_3: 0.3197, decode.loss_dice_3: 0.4852, decode.loss_ce_4: 1.6622, decode.loss_mask_4: 0.3200, decode.loss_dice_4: 0.4827, loss: 14.7837
2023-09-22 00:44:31,701 - mmseg - INFO - Iter [14250/160000]	lr: 9.109e-05, eta: 1 day, 0:33:38, time: 0.581, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6106, decode.loss_mask: 0.3369, decode.loss_dice: 0.4431, decode.loss_ce_0: 1.6479, decode.loss_mask_0: 0.3257, decode.loss_dice_0: 0.4425, decode.loss_ce_1: 1.6064, decode.loss_mask_1: 0.3350, decode.loss_dice_1: 0.4505, decode.loss_ce_2: 1.6468, decode.loss_mask_2: 0.3381, decode.loss_dice_2: 0.4482, decode.loss_ce_3: 1.6201, decode.loss_mask_3: 0.3313, decode.loss_dice_3: 0.4451, decode.loss_ce_4: 1.6319, decode.loss_mask_4: 0.3414, decode.loss_dice_4: 0.4444, loss: 14.4460
2023-09-22 00:44:57,716 - mmseg - INFO - Iter [14300/160000]	lr: 9.106e-05, eta: 1 day, 0:32:24, time: 0.520, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7370, decode.loss_mask: 0.2842, decode.loss_dice: 0.4482, decode.loss_ce_0: 1.7516, decode.loss_mask_0: 0.2814, decode.loss_dice_0: 0.4562, decode.loss_ce_1: 1.7521, decode.loss_mask_1: 0.2867, decode.loss_dice_1: 0.4582, decode.loss_ce_2: 1.7702, decode.loss_mask_2: 0.3039, decode.loss_dice_2: 0.4724, decode.loss_ce_3: 1.7229, decode.loss_mask_3: 0.2776, decode.loss_dice_3: 0.4527, decode.loss_ce_4: 1.7362, decode.loss_mask_4: 0.2848, decode.loss_dice_4: 0.4490, loss: 14.9252
2023-09-22 00:45:23,242 - mmseg - INFO - Iter [14350/160000]	lr: 9.103e-05, eta: 1 day, 0:31:05, time: 0.510, data_time: 0.007, memory: 13718, decode.loss_ce: 1.5964, decode.loss_mask: 0.3019, decode.loss_dice: 0.4415, decode.loss_ce_0: 1.5809, decode.loss_mask_0: 0.3057, decode.loss_dice_0: 0.4424, decode.loss_ce_1: 1.5924, decode.loss_mask_1: 0.3085, decode.loss_dice_1: 0.4418, decode.loss_ce_2: 1.6122, decode.loss_mask_2: 0.3045, decode.loss_dice_2: 0.4344, decode.loss_ce_3: 1.6111, decode.loss_mask_3: 0.2996, decode.loss_dice_3: 0.4486, decode.loss_ce_4: 1.5936, decode.loss_mask_4: 0.3069, decode.loss_dice_4: 0.4417, loss: 14.0642
2023-09-22 00:45:49,047 - mmseg - INFO - Iter [14400/160000]	lr: 9.100e-05, eta: 1 day, 0:29:49, time: 0.516, data_time: 0.007, memory: 13718, decode.loss_ce: 1.7335, decode.loss_mask: 0.3288, decode.loss_dice: 0.4948, decode.loss_ce_0: 1.7567, decode.loss_mask_0: 0.3228, decode.loss_dice_0: 0.4819, decode.loss_ce_1: 1.7537, decode.loss_mask_1: 0.3221, decode.loss_dice_1: 0.4827, decode.loss_ce_2: 1.7686, decode.loss_mask_2: 0.3206, decode.loss_dice_2: 0.4823, decode.loss_ce_3: 1.7490, decode.loss_mask_3: 0.3279, decode.loss_dice_3: 0.4882, decode.loss_ce_4: 1.7735, decode.loss_mask_4: 0.3254, decode.loss_dice_4: 0.4828, loss: 15.3952
2023-09-22 00:46:14,850 - mmseg - INFO - Iter [14450/160000]	lr: 9.097e-05, eta: 1 day, 0:28:33, time: 0.516, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6779, decode.loss_mask: 0.3044, decode.loss_dice: 0.4726, decode.loss_ce_0: 1.6910, decode.loss_mask_0: 0.3064, decode.loss_dice_0: 0.4721, decode.loss_ce_1: 1.7284, decode.loss_mask_1: 0.3122, decode.loss_dice_1: 0.4734, decode.loss_ce_2: 1.6886, decode.loss_mask_2: 0.3060, decode.loss_dice_2: 0.4713, decode.loss_ce_3: 1.6976, decode.loss_mask_3: 0.2969, decode.loss_dice_3: 0.4679, decode.loss_ce_4: 1.7134, decode.loss_mask_4: 0.3034, decode.loss_dice_4: 0.4722, loss: 14.8557
2023-09-22 00:46:40,477 - mmseg - INFO - Iter [14500/160000]	lr: 9.094e-05, eta: 1 day, 0:27:17, time: 0.513, data_time: 0.007, memory: 13718, decode.loss_ce: 1.5784, decode.loss_mask: 0.3402, decode.loss_dice: 0.4399, decode.loss_ce_0: 1.5970, decode.loss_mask_0: 0.3262, decode.loss_dice_0: 0.4407, decode.loss_ce_1: 1.5879, decode.loss_mask_1: 0.3187, decode.loss_dice_1: 0.4399, decode.loss_ce_2: 1.5861, decode.loss_mask_2: 0.3138, decode.loss_dice_2: 0.4262, decode.loss_ce_3: 1.5873, decode.loss_mask_3: 0.3339, decode.loss_dice_3: 0.4319, decode.loss_ce_4: 1.5848, decode.loss_mask_4: 0.3235, decode.loss_dice_4: 0.4315, loss: 14.0880
2023-09-22 00:47:06,510 - mmseg - INFO - Iter [14550/160000]	lr: 9.091e-05, eta: 1 day, 0:26:04, time: 0.521, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6684, decode.loss_mask: 0.3295, decode.loss_dice: 0.4845, decode.loss_ce_0: 1.7385, decode.loss_mask_0: 0.3401, decode.loss_dice_0: 0.4859, decode.loss_ce_1: 1.6884, decode.loss_mask_1: 0.3402, decode.loss_dice_1: 0.4928, decode.loss_ce_2: 1.6983, decode.loss_mask_2: 0.3200, decode.loss_dice_2: 0.4842, decode.loss_ce_3: 1.6753, decode.loss_mask_3: 0.3394, decode.loss_dice_3: 0.4904, decode.loss_ce_4: 1.7376, decode.loss_mask_4: 0.3428, decode.loss_dice_4: 0.4876, loss: 15.1440
2023-09-22 00:47:34,152 - mmseg - INFO - Iter [14600/160000]	lr: 9.088e-05, eta: 1 day, 0:25:08, time: 0.553, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7340, decode.loss_mask: 0.2743, decode.loss_dice: 0.4893, decode.loss_ce_0: 1.7299, decode.loss_mask_0: 0.2801, decode.loss_dice_0: 0.4909, decode.loss_ce_1: 1.7279, decode.loss_mask_1: 0.2739, decode.loss_dice_1: 0.4917, decode.loss_ce_2: 1.7590, decode.loss_mask_2: 0.2796, decode.loss_dice_2: 0.4827, decode.loss_ce_3: 1.7322, decode.loss_mask_3: 0.2727, decode.loss_dice_3: 0.4946, decode.loss_ce_4: 1.7567, decode.loss_mask_4: 0.2796, decode.loss_dice_4: 0.4971, loss: 15.0463
2023-09-22 00:48:01,146 - mmseg - INFO - Iter [14650/160000]	lr: 9.084e-05, eta: 1 day, 0:24:06, time: 0.540, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6860, decode.loss_mask: 0.3425, decode.loss_dice: 0.4505, decode.loss_ce_0: 1.6839, decode.loss_mask_0: 0.3235, decode.loss_dice_0: 0.4581, decode.loss_ce_1: 1.6757, decode.loss_mask_1: 0.3363, decode.loss_dice_1: 0.4535, decode.loss_ce_2: 1.6836, decode.loss_mask_2: 0.3322, decode.loss_dice_2: 0.4554, decode.loss_ce_3: 1.6639, decode.loss_mask_3: 0.3093, decode.loss_dice_3: 0.4543, decode.loss_ce_4: 1.6855, decode.loss_mask_4: 0.3326, decode.loss_dice_4: 0.4544, loss: 14.7812
2023-09-22 00:48:28,521 - mmseg - INFO - Iter [14700/160000]	lr: 9.081e-05, eta: 1 day, 0:23:07, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7228, decode.loss_mask: 0.3509, decode.loss_dice: 0.4499, decode.loss_ce_0: 1.7430, decode.loss_mask_0: 0.3089, decode.loss_dice_0: 0.4528, decode.loss_ce_1: 1.7399, decode.loss_mask_1: 0.3206, decode.loss_dice_1: 0.4475, decode.loss_ce_2: 1.7170, decode.loss_mask_2: 0.3310, decode.loss_dice_2: 0.4543, decode.loss_ce_3: 1.7247, decode.loss_mask_3: 0.3133, decode.loss_dice_3: 0.4491, decode.loss_ce_4: 1.7273, decode.loss_mask_4: 0.3078, decode.loss_dice_4: 0.4473, loss: 15.0078
2023-09-22 00:48:56,905 - mmseg - INFO - Iter [14750/160000]	lr: 9.078e-05, eta: 1 day, 0:22:19, time: 0.568, data_time: 0.010, memory: 13718, decode.loss_ce: 1.7480, decode.loss_mask: 0.2886, decode.loss_dice: 0.4600, decode.loss_ce_0: 1.7875, decode.loss_mask_0: 0.2927, decode.loss_dice_0: 0.4603, decode.loss_ce_1: 1.7779, decode.loss_mask_1: 0.2951, decode.loss_dice_1: 0.4585, decode.loss_ce_2: 1.7873, decode.loss_mask_2: 0.2980, decode.loss_dice_2: 0.4558, decode.loss_ce_3: 1.7510, decode.loss_mask_3: 0.2835, decode.loss_dice_3: 0.4546, decode.loss_ce_4: 1.7721, decode.loss_mask_4: 0.2824, decode.loss_dice_4: 0.4616, loss: 15.1147
2023-09-22 00:49:23,456 - mmseg - INFO - Iter [14800/160000]	lr: 9.075e-05, eta: 1 day, 0:21:13, time: 0.531, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6337, decode.loss_mask: 0.2785, decode.loss_dice: 0.4633, decode.loss_ce_0: 1.6674, decode.loss_mask_0: 0.2875, decode.loss_dice_0: 0.4566, decode.loss_ce_1: 1.6598, decode.loss_mask_1: 0.3057, decode.loss_dice_1: 0.4592, decode.loss_ce_2: 1.6518, decode.loss_mask_2: 0.2852, decode.loss_dice_2: 0.4570, decode.loss_ce_3: 1.6541, decode.loss_mask_3: 0.2812, decode.loss_dice_3: 0.4617, decode.loss_ce_4: 1.6411, decode.loss_mask_4: 0.2794, decode.loss_dice_4: 0.4652, loss: 14.3884
2023-09-22 00:49:49,622 - mmseg - INFO - Iter [14850/160000]	lr: 9.072e-05, eta: 1 day, 0:20:04, time: 0.523, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7302, decode.loss_mask: 0.3009, decode.loss_dice: 0.4716, decode.loss_ce_0: 1.7875, decode.loss_mask_0: 0.3061, decode.loss_dice_0: 0.4682, decode.loss_ce_1: 1.7506, decode.loss_mask_1: 0.3041, decode.loss_dice_1: 0.4680, decode.loss_ce_2: 1.7894, decode.loss_mask_2: 0.2971, decode.loss_dice_2: 0.4700, decode.loss_ce_3: 1.7536, decode.loss_mask_3: 0.2968, decode.loss_dice_3: 0.4701, decode.loss_ce_4: 1.7484, decode.loss_mask_4: 0.2963, decode.loss_dice_4: 0.4739, loss: 15.1828
2023-09-22 00:50:41,069 - mmseg - INFO - Iter [14900/160000]	lr: 9.069e-05, eta: 1 day, 0:23:01, time: 1.029, data_time: 0.501, memory: 13718, decode.loss_ce: 1.5209, decode.loss_mask: 0.3294, decode.loss_dice: 0.4407, decode.loss_ce_0: 1.5422, decode.loss_mask_0: 0.3543, decode.loss_dice_0: 0.4545, decode.loss_ce_1: 1.5157, decode.loss_mask_1: 0.3370, decode.loss_dice_1: 0.4598, decode.loss_ce_2: 1.5192, decode.loss_mask_2: 0.3379, decode.loss_dice_2: 0.4538, decode.loss_ce_3: 1.5429, decode.loss_mask_3: 0.3575, decode.loss_dice_3: 0.4546, decode.loss_ce_4: 1.5287, decode.loss_mask_4: 0.3180, decode.loss_dice_4: 0.4497, loss: 13.9169
2023-09-22 00:51:07,599 - mmseg - INFO - Iter [14950/160000]	lr: 9.066e-05, eta: 1 day, 0:21:54, time: 0.531, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7285, decode.loss_mask: 0.3125, decode.loss_dice: 0.4700, decode.loss_ce_0: 1.7371, decode.loss_mask_0: 0.3042, decode.loss_dice_0: 0.4754, decode.loss_ce_1: 1.7107, decode.loss_mask_1: 0.2973, decode.loss_dice_1: 0.4821, decode.loss_ce_2: 1.7039, decode.loss_mask_2: 0.2986, decode.loss_dice_2: 0.4757, decode.loss_ce_3: 1.7436, decode.loss_mask_3: 0.3116, decode.loss_dice_3: 0.4763, decode.loss_ce_4: 1.7480, decode.loss_mask_4: 0.2981, decode.loss_dice_4: 0.4698, loss: 15.0433
2023-09-22 00:51:33,278 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 00:51:33,278 - mmseg - INFO - Iter [15000/160000]	lr: 9.063e-05, eta: 1 day, 0:20:40, time: 0.514, data_time: 0.007, memory: 13718, decode.loss_ce: 1.7268, decode.loss_mask: 0.2891, decode.loss_dice: 0.4619, decode.loss_ce_0: 1.7204, decode.loss_mask_0: 0.2808, decode.loss_dice_0: 0.4666, decode.loss_ce_1: 1.7154, decode.loss_mask_1: 0.2768, decode.loss_dice_1: 0.4717, decode.loss_ce_2: 1.7205, decode.loss_mask_2: 0.2919, decode.loss_dice_2: 0.4673, decode.loss_ce_3: 1.7119, decode.loss_mask_3: 0.2893, decode.loss_dice_3: 0.4649, decode.loss_ce_4: 1.7229, decode.loss_mask_4: 0.2872, decode.loss_dice_4: 0.4674, loss: 14.8327
2023-09-22 00:52:01,174 - mmseg - INFO - Iter [15050/160000]	lr: 9.059e-05, eta: 1 day, 0:19:47, time: 0.558, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6053, decode.loss_mask: 0.2896, decode.loss_dice: 0.4336, decode.loss_ce_0: 1.6040, decode.loss_mask_0: 0.2854, decode.loss_dice_0: 0.4413, decode.loss_ce_1: 1.6025, decode.loss_mask_1: 0.2905, decode.loss_dice_1: 0.4440, decode.loss_ce_2: 1.6070, decode.loss_mask_2: 0.2820, decode.loss_dice_2: 0.4322, decode.loss_ce_3: 1.5839, decode.loss_mask_3: 0.2926, decode.loss_dice_3: 0.4374, decode.loss_ce_4: 1.5988, decode.loss_mask_4: 0.2927, decode.loss_dice_4: 0.4375, loss: 13.9604
2023-09-22 00:52:29,113 - mmseg - INFO - Iter [15100/160000]	lr: 9.056e-05, eta: 1 day, 0:18:55, time: 0.559, data_time: 0.010, memory: 13718, decode.loss_ce: 1.6772, decode.loss_mask: 0.2839, decode.loss_dice: 0.4639, decode.loss_ce_0: 1.7183, decode.loss_mask_0: 0.2807, decode.loss_dice_0: 0.4726, decode.loss_ce_1: 1.7412, decode.loss_mask_1: 0.2898, decode.loss_dice_1: 0.4766, decode.loss_ce_2: 1.7076, decode.loss_mask_2: 0.2770, decode.loss_dice_2: 0.4753, decode.loss_ce_3: 1.6925, decode.loss_mask_3: 0.2819, decode.loss_dice_3: 0.4691, decode.loss_ce_4: 1.6853, decode.loss_mask_4: 0.2776, decode.loss_dice_4: 0.4713, loss: 14.7418
2023-09-22 00:52:57,047 - mmseg - INFO - Iter [15150/160000]	lr: 9.053e-05, eta: 1 day, 0:18:03, time: 0.559, data_time: 0.009, memory: 13718, decode.loss_ce: 1.5683, decode.loss_mask: 0.2829, decode.loss_dice: 0.3844, decode.loss_ce_0: 1.5950, decode.loss_mask_0: 0.2680, decode.loss_dice_0: 0.3864, decode.loss_ce_1: 1.5890, decode.loss_mask_1: 0.2855, decode.loss_dice_1: 0.3955, decode.loss_ce_2: 1.5816, decode.loss_mask_2: 0.2687, decode.loss_dice_2: 0.3945, decode.loss_ce_3: 1.5667, decode.loss_mask_3: 0.2683, decode.loss_dice_3: 0.3885, decode.loss_ce_4: 1.5713, decode.loss_mask_4: 0.2717, decode.loss_dice_4: 0.3953, loss: 13.4614
2023-09-22 00:53:23,821 - mmseg - INFO - Iter [15200/160000]	lr: 9.050e-05, eta: 1 day, 0:17:01, time: 0.535, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6161, decode.loss_mask: 0.3407, decode.loss_dice: 0.4308, decode.loss_ce_0: 1.5953, decode.loss_mask_0: 0.4081, decode.loss_dice_0: 0.4396, decode.loss_ce_1: 1.5934, decode.loss_mask_1: 0.3752, decode.loss_dice_1: 0.4432, decode.loss_ce_2: 1.5879, decode.loss_mask_2: 0.3118, decode.loss_dice_2: 0.4329, decode.loss_ce_3: 1.6065, decode.loss_mask_3: 0.3225, decode.loss_dice_3: 0.4293, decode.loss_ce_4: 1.6029, decode.loss_mask_4: 0.3028, decode.loss_dice_4: 0.4276, loss: 14.2667
2023-09-22 00:53:50,548 - mmseg - INFO - Iter [15250/160000]	lr: 9.047e-05, eta: 1 day, 0:15:57, time: 0.535, data_time: 0.009, memory: 13718, decode.loss_ce: 1.5344, decode.loss_mask: 0.2950, decode.loss_dice: 0.4113, decode.loss_ce_0: 1.5924, decode.loss_mask_0: 0.2830, decode.loss_dice_0: 0.4129, decode.loss_ce_1: 1.5185, decode.loss_mask_1: 0.2927, decode.loss_dice_1: 0.4175, decode.loss_ce_2: 1.5159, decode.loss_mask_2: 0.2830, decode.loss_dice_2: 0.4111, decode.loss_ce_3: 1.5156, decode.loss_mask_3: 0.3034, decode.loss_dice_3: 0.4186, decode.loss_ce_4: 1.4979, decode.loss_mask_4: 0.2838, decode.loss_dice_4: 0.4037, loss: 13.3907
2023-09-22 00:54:17,604 - mmseg - INFO - Iter [15300/160000]	lr: 9.044e-05, eta: 1 day, 0:14:58, time: 0.541, data_time: 0.009, memory: 13718, decode.loss_ce: 1.6649, decode.loss_mask: 0.2965, decode.loss_dice: 0.4507, decode.loss_ce_0: 1.6891, decode.loss_mask_0: 0.3093, decode.loss_dice_0: 0.4515, decode.loss_ce_1: 1.6576, decode.loss_mask_1: 0.3024, decode.loss_dice_1: 0.4502, decode.loss_ce_2: 1.6539, decode.loss_mask_2: 0.2904, decode.loss_dice_2: 0.4419, decode.loss_ce_3: 1.6425, decode.loss_mask_3: 0.3101, decode.loss_dice_3: 0.4512, decode.loss_ce_4: 1.6529, decode.loss_mask_4: 0.3073, decode.loss_dice_4: 0.4536, loss: 14.4759
2023-09-22 00:54:44,932 - mmseg - INFO - Iter [15350/160000]	lr: 9.041e-05, eta: 1 day, 0:14:01, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5587, decode.loss_mask: 0.2727, decode.loss_dice: 0.4360, decode.loss_ce_0: 1.6218, decode.loss_mask_0: 0.3051, decode.loss_dice_0: 0.4416, decode.loss_ce_1: 1.5921, decode.loss_mask_1: 0.2960, decode.loss_dice_1: 0.4468, decode.loss_ce_2: 1.5862, decode.loss_mask_2: 0.2850, decode.loss_dice_2: 0.4344, decode.loss_ce_3: 1.5751, decode.loss_mask_3: 0.2833, decode.loss_dice_3: 0.4311, decode.loss_ce_4: 1.5481, decode.loss_mask_4: 0.2728, decode.loss_dice_4: 0.4303, loss: 13.8173
2023-09-22 00:55:12,246 - mmseg - INFO - Iter [15400/160000]	lr: 9.038e-05, eta: 1 day, 0:13:04, time: 0.546, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6013, decode.loss_mask: 0.3024, decode.loss_dice: 0.4205, decode.loss_ce_0: 1.6246, decode.loss_mask_0: 0.2969, decode.loss_dice_0: 0.4288, decode.loss_ce_1: 1.6348, decode.loss_mask_1: 0.2931, decode.loss_dice_1: 0.4301, decode.loss_ce_2: 1.6128, decode.loss_mask_2: 0.2875, decode.loss_dice_2: 0.4270, decode.loss_ce_3: 1.6073, decode.loss_mask_3: 0.3109, decode.loss_dice_3: 0.4205, decode.loss_ce_4: 1.6114, decode.loss_mask_4: 0.3019, decode.loss_dice_4: 0.4188, loss: 14.0307
2023-09-22 00:55:39,802 - mmseg - INFO - Iter [15450/160000]	lr: 9.034e-05, eta: 1 day, 0:12:10, time: 0.551, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6207, decode.loss_mask: 0.3512, decode.loss_dice: 0.4408, decode.loss_ce_0: 1.6105, decode.loss_mask_0: 0.3422, decode.loss_dice_0: 0.4538, decode.loss_ce_1: 1.5665, decode.loss_mask_1: 0.3132, decode.loss_dice_1: 0.4480, decode.loss_ce_2: 1.5785, decode.loss_mask_2: 0.3268, decode.loss_dice_2: 0.4514, decode.loss_ce_3: 1.5961, decode.loss_mask_3: 0.3496, decode.loss_dice_3: 0.4547, decode.loss_ce_4: 1.6458, decode.loss_mask_4: 0.3207, decode.loss_dice_4: 0.4470, loss: 14.3176
2023-09-22 00:56:05,978 - mmseg - INFO - Iter [15500/160000]	lr: 9.031e-05, eta: 1 day, 0:11:03, time: 0.524, data_time: 0.008, memory: 13718, decode.loss_ce: 1.4828, decode.loss_mask: 0.2779, decode.loss_dice: 0.3948, decode.loss_ce_0: 1.5197, decode.loss_mask_0: 0.2840, decode.loss_dice_0: 0.4074, decode.loss_ce_1: 1.4615, decode.loss_mask_1: 0.2732, decode.loss_dice_1: 0.3959, decode.loss_ce_2: 1.5067, decode.loss_mask_2: 0.2641, decode.loss_dice_2: 0.3959, decode.loss_ce_3: 1.5162, decode.loss_mask_3: 0.2757, decode.loss_dice_3: 0.3983, decode.loss_ce_4: 1.5255, decode.loss_mask_4: 0.2741, decode.loss_dice_4: 0.3964, loss: 13.0503
2023-09-22 00:56:32,615 - mmseg - INFO - Iter [15550/160000]	lr: 9.028e-05, eta: 1 day, 0:10:00, time: 0.533, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7326, decode.loss_mask: 0.2853, decode.loss_dice: 0.4751, decode.loss_ce_0: 1.7268, decode.loss_mask_0: 0.2836, decode.loss_dice_0: 0.4770, decode.loss_ce_1: 1.7329, decode.loss_mask_1: 0.2799, decode.loss_dice_1: 0.4739, decode.loss_ce_2: 1.7594, decode.loss_mask_2: 0.2921, decode.loss_dice_2: 0.4654, decode.loss_ce_3: 1.7550, decode.loss_mask_3: 0.2910, decode.loss_dice_3: 0.4758, decode.loss_ce_4: 1.7507, decode.loss_mask_4: 0.2807, decode.loss_dice_4: 0.4702, loss: 15.0073
2023-09-22 00:57:00,184 - mmseg - INFO - Iter [15600/160000]	lr: 9.025e-05, eta: 1 day, 0:09:06, time: 0.551, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6759, decode.loss_mask: 0.2549, decode.loss_dice: 0.4382, decode.loss_ce_0: 1.6737, decode.loss_mask_0: 0.2555, decode.loss_dice_0: 0.4465, decode.loss_ce_1: 1.6697, decode.loss_mask_1: 0.2692, decode.loss_dice_1: 0.4473, decode.loss_ce_2: 1.6607, decode.loss_mask_2: 0.2488, decode.loss_dice_2: 0.4402, decode.loss_ce_3: 1.6640, decode.loss_mask_3: 0.2530, decode.loss_dice_3: 0.4366, decode.loss_ce_4: 1.7010, decode.loss_mask_4: 0.2527, decode.loss_dice_4: 0.4381, loss: 14.2259
2023-09-22 00:57:27,873 - mmseg - INFO - Iter [15650/160000]	lr: 9.022e-05, eta: 1 day, 0:08:14, time: 0.554, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5833, decode.loss_mask: 0.2973, decode.loss_dice: 0.3999, decode.loss_ce_0: 1.5982, decode.loss_mask_0: 0.3150, decode.loss_dice_0: 0.4076, decode.loss_ce_1: 1.5973, decode.loss_mask_1: 0.3141, decode.loss_dice_1: 0.4124, decode.loss_ce_2: 1.6085, decode.loss_mask_2: 0.3092, decode.loss_dice_2: 0.4030, decode.loss_ce_3: 1.6363, decode.loss_mask_3: 0.3100, decode.loss_dice_3: 0.4054, decode.loss_ce_4: 1.6166, decode.loss_mask_4: 0.3068, decode.loss_dice_4: 0.4043, loss: 13.9250
2023-09-22 00:57:55,109 - mmseg - INFO - Iter [15700/160000]	lr: 9.019e-05, eta: 1 day, 0:07:18, time: 0.545, data_time: 0.008, memory: 13718, decode.loss_ce: 1.8015, decode.loss_mask: 0.3123, decode.loss_dice: 0.4821, decode.loss_ce_0: 1.8152, decode.loss_mask_0: 0.3053, decode.loss_dice_0: 0.4942, decode.loss_ce_1: 1.7944, decode.loss_mask_1: 0.3058, decode.loss_dice_1: 0.4930, decode.loss_ce_2: 1.8273, decode.loss_mask_2: 0.3041, decode.loss_dice_2: 0.4793, decode.loss_ce_3: 1.8301, decode.loss_mask_3: 0.3406, decode.loss_dice_3: 0.4917, decode.loss_ce_4: 1.8272, decode.loss_mask_4: 0.3162, decode.loss_dice_4: 0.4838, loss: 15.7040
2023-09-22 00:58:21,188 - mmseg - INFO - Iter [15750/160000]	lr: 9.016e-05, eta: 1 day, 0:06:11, time: 0.522, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5998, decode.loss_mask: 0.2687, decode.loss_dice: 0.4265, decode.loss_ce_0: 1.5858, decode.loss_mask_0: 0.2682, decode.loss_dice_0: 0.4271, decode.loss_ce_1: 1.5978, decode.loss_mask_1: 0.2831, decode.loss_dice_1: 0.4317, decode.loss_ce_2: 1.5975, decode.loss_mask_2: 0.2721, decode.loss_dice_2: 0.4211, decode.loss_ce_3: 1.5946, decode.loss_mask_3: 0.2676, decode.loss_dice_3: 0.4295, decode.loss_ce_4: 1.5967, decode.loss_mask_4: 0.2715, decode.loss_dice_4: 0.4249, loss: 13.7641
2023-09-22 00:58:47,342 - mmseg - INFO - Iter [15800/160000]	lr: 9.013e-05, eta: 1 day, 0:05:05, time: 0.523, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6827, decode.loss_mask: 0.3433, decode.loss_dice: 0.4424, decode.loss_ce_0: 1.7195, decode.loss_mask_0: 0.3269, decode.loss_dice_0: 0.4429, decode.loss_ce_1: 1.6920, decode.loss_mask_1: 0.3378, decode.loss_dice_1: 0.4512, decode.loss_ce_2: 1.6864, decode.loss_mask_2: 0.3378, decode.loss_dice_2: 0.4433, decode.loss_ce_3: 1.6584, decode.loss_mask_3: 0.3235, decode.loss_dice_3: 0.4526, decode.loss_ce_4: 1.6631, decode.loss_mask_4: 0.3442, decode.loss_dice_4: 0.4452, loss: 14.7932
2023-09-22 00:59:13,724 - mmseg - INFO - Iter [15850/160000]	lr: 9.009e-05, eta: 1 day, 0:04:01, time: 0.528, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6964, decode.loss_mask: 0.3217, decode.loss_dice: 0.4696, decode.loss_ce_0: 1.7127, decode.loss_mask_0: 0.3452, decode.loss_dice_0: 0.4797, decode.loss_ce_1: 1.7442, decode.loss_mask_1: 0.3273, decode.loss_dice_1: 0.4762, decode.loss_ce_2: 1.7253, decode.loss_mask_2: 0.3284, decode.loss_dice_2: 0.4719, decode.loss_ce_3: 1.6926, decode.loss_mask_3: 0.3361, decode.loss_dice_3: 0.4757, decode.loss_ce_4: 1.6823, decode.loss_mask_4: 0.3249, decode.loss_dice_4: 0.4754, loss: 15.0856
2023-09-22 00:59:39,960 - mmseg - INFO - Iter [15900/160000]	lr: 9.006e-05, eta: 1 day, 0:02:57, time: 0.525, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6708, decode.loss_mask: 0.2767, decode.loss_dice: 0.4547, decode.loss_ce_0: 1.6962, decode.loss_mask_0: 0.3050, decode.loss_dice_0: 0.4493, decode.loss_ce_1: 1.7086, decode.loss_mask_1: 0.2838, decode.loss_dice_1: 0.4519, decode.loss_ce_2: 1.6842, decode.loss_mask_2: 0.2718, decode.loss_dice_2: 0.4430, decode.loss_ce_3: 1.6700, decode.loss_mask_3: 0.2765, decode.loss_dice_3: 0.4514, decode.loss_ce_4: 1.6698, decode.loss_mask_4: 0.2772, decode.loss_dice_4: 0.4474, loss: 14.4882
2023-09-22 01:00:05,957 - mmseg - INFO - Iter [15950/160000]	lr: 9.003e-05, eta: 1 day, 0:01:50, time: 0.520, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6937, decode.loss_mask: 0.2495, decode.loss_dice: 0.4330, decode.loss_ce_0: 1.6757, decode.loss_mask_0: 0.2666, decode.loss_dice_0: 0.4343, decode.loss_ce_1: 1.6724, decode.loss_mask_1: 0.2530, decode.loss_dice_1: 0.4297, decode.loss_ce_2: 1.6908, decode.loss_mask_2: 0.2564, decode.loss_dice_2: 0.4281, decode.loss_ce_3: 1.6737, decode.loss_mask_3: 0.2722, decode.loss_dice_3: 0.4368, decode.loss_ce_4: 1.6736, decode.loss_mask_4: 0.2619, decode.loss_dice_4: 0.4290, loss: 14.2302
2023-09-22 01:00:32,542 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-09-22 01:00:35,975 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-09-22 01:00:35,975 - mmseg - INFO - Iter [16000/160000]	lr: 9.000e-05, eta: 1 day, 0:01:20, time: 0.600, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5960, decode.loss_mask: 0.3266, decode.loss_dice: 0.4449, decode.loss_ce_0: 1.5844, decode.loss_mask_0: 0.3410, decode.loss_dice_0: 0.4404, decode.loss_ce_1: 1.5786, decode.loss_mask_1: 0.3363, decode.loss_dice_1: 0.4436, decode.loss_ce_2: 1.5806, decode.loss_mask_2: 0.3409, decode.loss_dice_2: 0.4467, decode.loss_ce_3: 1.5790, decode.loss_mask_3: 0.3498, decode.loss_dice_3: 0.4419, decode.loss_ce_4: 1.6023, decode.loss_mask_4: 0.3507, decode.loss_dice_4: 0.4425, loss: 14.2261
2023-09-22 01:01:02,797 - mmseg - INFO - Iter [16050/160000]	lr: 8.997e-05, eta: 1 day, 0:00:21, time: 0.536, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6079, decode.loss_mask: 0.3446, decode.loss_dice: 0.4848, decode.loss_ce_0: 1.6254, decode.loss_mask_0: 0.3571, decode.loss_dice_0: 0.4882, decode.loss_ce_1: 1.5807, decode.loss_mask_1: 0.3332, decode.loss_dice_1: 0.4874, decode.loss_ce_2: 1.5839, decode.loss_mask_2: 0.3340, decode.loss_dice_2: 0.4785, decode.loss_ce_3: 1.5945, decode.loss_mask_3: 0.3344, decode.loss_dice_3: 0.4852, decode.loss_ce_4: 1.6042, decode.loss_mask_4: 0.3202, decode.loss_dice_4: 0.4823, loss: 14.5265
2023-09-22 01:01:30,258 - mmseg - INFO - Iter [16100/160000]	lr: 8.994e-05, eta: 23:59:28, time: 0.549, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6637, decode.loss_mask: 0.2707, decode.loss_dice: 0.4716, decode.loss_ce_0: 1.6811, decode.loss_mask_0: 0.2728, decode.loss_dice_0: 0.4743, decode.loss_ce_1: 1.6436, decode.loss_mask_1: 0.2789, decode.loss_dice_1: 0.4789, decode.loss_ce_2: 1.6851, decode.loss_mask_2: 0.2812, decode.loss_dice_2: 0.4721, decode.loss_ce_3: 1.6718, decode.loss_mask_3: 0.2745, decode.loss_dice_3: 0.4737, decode.loss_ce_4: 1.6732, decode.loss_mask_4: 0.2783, decode.loss_dice_4: 0.4751, loss: 14.5206
2023-09-22 01:01:56,485 - mmseg - INFO - Iter [16150/160000]	lr: 8.991e-05, eta: 23:58:25, time: 0.525, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6642, decode.loss_mask: 0.3226, decode.loss_dice: 0.4841, decode.loss_ce_0: 1.6817, decode.loss_mask_0: 0.3111, decode.loss_dice_0: 0.4808, decode.loss_ce_1: 1.6726, decode.loss_mask_1: 0.3213, decode.loss_dice_1: 0.4749, decode.loss_ce_2: 1.6757, decode.loss_mask_2: 0.3209, decode.loss_dice_2: 0.4838, decode.loss_ce_3: 1.6801, decode.loss_mask_3: 0.3105, decode.loss_dice_3: 0.4787, decode.loss_ce_4: 1.6715, decode.loss_mask_4: 0.3104, decode.loss_dice_4: 0.4810, loss: 14.8256
2023-09-22 01:02:22,324 - mmseg - INFO - Iter [16200/160000]	lr: 8.988e-05, eta: 23:57:18, time: 0.517, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5470, decode.loss_mask: 0.2601, decode.loss_dice: 0.4295, decode.loss_ce_0: 1.5582, decode.loss_mask_0: 0.2568, decode.loss_dice_0: 0.4274, decode.loss_ce_1: 1.5560, decode.loss_mask_1: 0.2596, decode.loss_dice_1: 0.4332, decode.loss_ce_2: 1.5356, decode.loss_mask_2: 0.2626, decode.loss_dice_2: 0.4378, decode.loss_ce_3: 1.5551, decode.loss_mask_3: 0.2703, decode.loss_dice_3: 0.4328, decode.loss_ce_4: 1.5582, decode.loss_mask_4: 0.2695, decode.loss_dice_4: 0.4225, loss: 13.4726
2023-09-22 01:02:49,048 - mmseg - INFO - Iter [16250/160000]	lr: 8.984e-05, eta: 23:56:19, time: 0.534, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6779, decode.loss_mask: 0.3171, decode.loss_dice: 0.4818, decode.loss_ce_0: 1.7015, decode.loss_mask_0: 0.3212, decode.loss_dice_0: 0.4826, decode.loss_ce_1: 1.7073, decode.loss_mask_1: 0.3290, decode.loss_dice_1: 0.4785, decode.loss_ce_2: 1.7051, decode.loss_mask_2: 0.3435, decode.loss_dice_2: 0.4782, decode.loss_ce_3: 1.6839, decode.loss_mask_3: 0.3062, decode.loss_dice_3: 0.4745, decode.loss_ce_4: 1.7043, decode.loss_mask_4: 0.3229, decode.loss_dice_4: 0.4804, loss: 14.9960
2023-09-22 01:03:16,342 - mmseg - INFO - Iter [16300/160000]	lr: 8.981e-05, eta: 23:55:25, time: 0.546, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6067, decode.loss_mask: 0.2977, decode.loss_dice: 0.4374, decode.loss_ce_0: 1.6099, decode.loss_mask_0: 0.3099, decode.loss_dice_0: 0.4410, decode.loss_ce_1: 1.5986, decode.loss_mask_1: 0.3097, decode.loss_dice_1: 0.4390, decode.loss_ce_2: 1.6125, decode.loss_mask_2: 0.3017, decode.loss_dice_2: 0.4414, decode.loss_ce_3: 1.6033, decode.loss_mask_3: 0.2868, decode.loss_dice_3: 0.4365, decode.loss_ce_4: 1.6071, decode.loss_mask_4: 0.2971, decode.loss_dice_4: 0.4337, loss: 14.0701
2023-09-22 01:03:43,711 - mmseg - INFO - Iter [16350/160000]	lr: 8.978e-05, eta: 23:54:32, time: 0.547, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6522, decode.loss_mask: 0.3005, decode.loss_dice: 0.4154, decode.loss_ce_0: 1.6903, decode.loss_mask_0: 0.3086, decode.loss_dice_0: 0.4231, decode.loss_ce_1: 1.6317, decode.loss_mask_1: 0.2947, decode.loss_dice_1: 0.4198, decode.loss_ce_2: 1.6332, decode.loss_mask_2: 0.3056, decode.loss_dice_2: 0.4265, decode.loss_ce_3: 1.6516, decode.loss_mask_3: 0.2940, decode.loss_dice_3: 0.4273, decode.loss_ce_4: 1.6526, decode.loss_mask_4: 0.2965, decode.loss_dice_4: 0.4274, loss: 14.2511
2023-09-22 01:04:10,622 - mmseg - INFO - Iter [16400/160000]	lr: 8.975e-05, eta: 23:53:36, time: 0.538, data_time: 0.008, memory: 13718, decode.loss_ce: 1.7911, decode.loss_mask: 0.2776, decode.loss_dice: 0.4673, decode.loss_ce_0: 1.8279, decode.loss_mask_0: 0.2722, decode.loss_dice_0: 0.4689, decode.loss_ce_1: 1.8043, decode.loss_mask_1: 0.2751, decode.loss_dice_1: 0.4779, decode.loss_ce_2: 1.7891, decode.loss_mask_2: 0.2729, decode.loss_dice_2: 0.4825, decode.loss_ce_3: 1.7652, decode.loss_mask_3: 0.2700, decode.loss_dice_3: 0.4733, decode.loss_ce_4: 1.7403, decode.loss_mask_4: 0.2652, decode.loss_dice_4: 0.4762, loss: 15.1968
2023-09-22 01:04:36,538 - mmseg - INFO - Iter [16450/160000]	lr: 8.972e-05, eta: 23:52:31, time: 0.518, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6334, decode.loss_mask: 0.3315, decode.loss_dice: 0.4412, decode.loss_ce_0: 1.6384, decode.loss_mask_0: 0.3280, decode.loss_dice_0: 0.4323, decode.loss_ce_1: 1.6332, decode.loss_mask_1: 0.3244, decode.loss_dice_1: 0.4332, decode.loss_ce_2: 1.6091, decode.loss_mask_2: 0.3335, decode.loss_dice_2: 0.4500, decode.loss_ce_3: 1.6126, decode.loss_mask_3: 0.3163, decode.loss_dice_3: 0.4348, decode.loss_ce_4: 1.6170, decode.loss_mask_4: 0.3197, decode.loss_dice_4: 0.4417, loss: 14.3303
2023-09-22 01:05:02,451 - mmseg - INFO - Iter [16500/160000]	lr: 8.969e-05, eta: 23:51:26, time: 0.518, data_time: 0.008, memory: 13718, decode.loss_ce: 1.5602, decode.loss_mask: 0.2974, decode.loss_dice: 0.4465, decode.loss_ce_0: 1.6083, decode.loss_mask_0: 0.2749, decode.loss_dice_0: 0.4332, decode.loss_ce_1: 1.5980, decode.loss_mask_1: 0.2858, decode.loss_dice_1: 0.4416, decode.loss_ce_2: 1.5711, decode.loss_mask_2: 0.2786, decode.loss_dice_2: 0.4452, decode.loss_ce_3: 1.5730, decode.loss_mask_3: 0.2847, decode.loss_dice_3: 0.4429, decode.loss_ce_4: 1.5740, decode.loss_mask_4: 0.2785, decode.loss_dice_4: 0.4371, loss: 13.8309
2023-09-22 01:05:28,492 - mmseg - INFO - Iter [16550/160000]	lr: 8.966e-05, eta: 23:50:22, time: 0.521, data_time: 0.007, memory: 13718, decode.loss_ce: 1.5548, decode.loss_mask: 0.2964, decode.loss_dice: 0.4127, decode.loss_ce_0: 1.5852, decode.loss_mask_0: 0.3030, decode.loss_dice_0: 0.4251, decode.loss_ce_1: 1.5477, decode.loss_mask_1: 0.3028, decode.loss_dice_1: 0.4154, decode.loss_ce_2: 1.5786, decode.loss_mask_2: 0.3133, decode.loss_dice_2: 0.4172, decode.loss_ce_3: 1.5329, decode.loss_mask_3: 0.3057, decode.loss_dice_3: 0.4253, decode.loss_ce_4: 1.5282, decode.loss_mask_4: 0.3058, decode.loss_dice_4: 0.4217, loss: 13.6717
2023-09-22 01:05:54,493 - mmseg - INFO - Iter [16600/160000]	lr: 8.963e-05, eta: 23:49:18, time: 0.520, data_time: 0.008, memory: 13718, decode.loss_ce: 1.4704, decode.loss_mask: 0.3404, decode.loss_dice: 0.4672, decode.loss_ce_0: 1.4633, decode.loss_mask_0: 0.3265, decode.loss_dice_0: 0.4645, decode.loss_ce_1: 1.4774, decode.loss_mask_1: 0.3444, decode.loss_dice_1: 0.4628, decode.loss_ce_2: 1.4703, decode.loss_mask_2: 0.3421, decode.loss_dice_2: 0.4618, decode.loss_ce_3: 1.4785, decode.loss_mask_3: 0.3590, decode.loss_dice_3: 0.4678, decode.loss_ce_4: 1.4637, decode.loss_mask_4: 0.3431, decode.loss_dice_4: 0.4584, loss: 13.6618
2023-09-22 01:06:20,553 - mmseg - INFO - Iter [16650/160000]	lr: 8.959e-05, eta: 23:48:15, time: 0.521, data_time: 0.008, memory: 13718, decode.loss_ce: 1.6845, decode.loss_mask: 0.3059, decode.loss_dice: 0.4819, decode.loss_ce_0: 1.6850, decode.loss_mask_0: 0.3232, decode.loss_dice_0: 0.4948, decode.loss_ce_1: 1.6767, decode.loss_mask_1: 0.3115, decode.loss_dice_1: 0.4871, decode.loss_ce_2: 1.6746, decode.loss_mask_2: 0.3014, decode.loss_dice_2: 0.4882, decode.loss_ce_3: 1.6962, decode.loss_mask_3: 0.3111, decode.loss_dice_3: 0.4940, decode.loss_ce_4: 1.6909, decode.loss_mask_4: 0.3007, decode.loss_dice_4: 0.4906, loss: 14.8986
2023-09-22 01:06:51,738 - mmseg - INFO - Iter [16700/160000]	lr: 8.956e-05, eta: 23:47:57, time: 0.624, data_time: 0.110, memory: 13718, decode.loss_ce: 1.6176, decode.loss_mask: 0.2937, decode.loss_dice: 0.4591, decode.loss_ce_0: 1.6042, decode.loss_mask_0: 0.2964, decode.loss_dice_0: 0.4606, decode.loss_ce_1: 1.5916, decode.loss_mask_1: 0.2910, decode.loss_dice_1: 0.4657, decode.loss_ce_2: 1.6111, decode.loss_mask_2: 0.2908, decode.loss_dice_2: 0.4666, decode.loss_ce_3: 1.6051, decode.loss_mask_3: 0.2906, decode.loss_dice_3: 0.4610, decode.loss_ce_4: 1.6208, decode.loss_mask_4: 0.2924, decode.loss_dice_4: 0.4638, loss: 14.1821
