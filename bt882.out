nohup: ignoring input
2023-08-08 05:30:46,316 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.7.r11.7/compiler.31442593_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.2
MMCV: 1.2.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.7
MMSegmentation: 0.11.0+91fb694
------------------------------------------------------------

2023-08-08 05:30:46,317 - mmseg - INFO - Distributed training: True
2023-08-08 05:30:46,451 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder_clips',
    pretrained='/home/lixinhao/original/mit_b2.pth',
    backbone=dict(type='mit_b2', style='pytorch'),
    decode_head=dict(
        type='SegFormerHead_clips',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=124,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(embed_dim=256),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        num_infer=5,
        num_clips=4,
        hypercorre=True,
        backbone='b2'),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'VSPWDataset2'
data_root = 'data/vspw/VSPW_480p'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (480, 480)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='Resize',
        img_scale=(853, 480),
        ratio_range=(0.5, 2.0),
        process_clips=True),
    dict(type='RandomCrop_clips', crop_size=(480, 480), cat_max_ratio=0.75),
    dict(type='RandomFlip_clips', prob=0.5),
    dict(type='PhotoMetricDistortion_clips'),
    dict(
        type='Normalize_clips',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad_clips', size=(480, 480), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle_clips'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(853, 480),
        flip=False,
        transforms=[
            dict(type='AlignedResize_clips', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip_clips'),
            dict(
                type='Normalize_clips',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor_clips', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='RepeatDataset',
        times=50,
        dataset=dict(
            type='VSPWDataset2',
            data_root='data/vspw/VSPW_480p',
            img_dir='images/training',
            ann_dir='annotations/training',
            split='train',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', reduce_zero_label=True),
                dict(
                    type='Resize',
                    img_scale=(853, 480),
                    ratio_range=(0.5, 2.0),
                    process_clips=True),
                dict(
                    type='RandomCrop_clips',
                    crop_size=(480, 480),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip_clips', prob=0.5),
                dict(type='PhotoMetricDistortion_clips'),
                dict(
                    type='Normalize_clips',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(
                    type='Pad_clips',
                    size=(480, 480),
                    pad_val=0,
                    seg_pad_val=255),
                dict(type='DefaultFormatBundle_clips'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ],
            dilation=[-9, -6, -3])),
    val=dict(
        type='VSPWDataset2',
        data_root='data/vspw/VSPW_480p',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        split='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(853, 480),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize_clips',
                        keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip_clips'),
                    dict(
                        type='Normalize_clips',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor_clips', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        dilation=[-9, -6, -3]),
    test=dict(
        type='VSPWDataset2',
        data_root='data/vspw/VSPW_480p',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        split='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(853, 480),
                flip=False,
                transforms=[
                    dict(
                        type='AlignedResize_clips',
                        keep_ratio=True,
                        size_divisor=32),
                    dict(type='RandomFlip_clips'),
                    dict(
                        type='Normalize_clips',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor_clips', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        dilation=[-9, -6, -3]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = 'model_path/vspw2/work_dirs_4g_b9/latest.pth'
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=9e-06,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            head=dict(lr_mult=10.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=4000)
evaluation = dict(interval=160000, metric='mIoU')
work_dir = 'model_path/vspw2/work_dirs_4g_b8_2/'
gpu_ids = range(0, 1)

2023-08-08 05:30:47,453 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: head.weight, head.bias

2023-08-08 05:30:47,454 - mmseg - INFO - EncoderDecoder_clips(
  (backbone): mit_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          )
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): SegFormerHead_clips(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(128, 124, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (net): SegFormerHead_clipsNet(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss()
      (conv_seg): Conv2d(128, 124, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (linear_c4): MLP(
        (proj): Linear(in_features=512, out_features=256, bias=True)
      )
      (linear_c3): MLP(
        (proj): Linear(in_features=320, out_features=256, bias=True)
      )
      (linear_c2): MLP(
        (proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (linear_c1): MLP(
        (proj): Linear(in_features=64, out_features=256, bias=True)
      )
      (pooling_mhsa_c1): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
      )
      (pooling_mhsa_c2): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
      )
      (pooling_mhsa_c3): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
        )
      )
      (pooling_mhsa_c4): pooling_mhsa(
        (pools): ModuleList()
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (d_convs): ModuleList(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        )
      )
      (pooling_linear): Linear(in_features=1024, out_features=256, bias=True)
      (linear_fuse): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (linear_pred): Conv2d(256, 124, kernel_size=(1, 1), stride=(1, 1))
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (deco1): small_decoder2(
        (smalldecoder): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(256, 124, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (deco2): small_decoder2(
        (smalldecoder): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (deco3): small_decoder2(
        (smalldecoder): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (deco4): small_decoder2(
        (smalldecoder): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(512, 124, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (hypercorre_module): hypercorre_topk2(
        (q1): Linear(in_features=64, out_features=64, bias=True)
        (q2): Linear(in_features=128, out_features=128, bias=True)
        (q3): Linear(in_features=320, out_features=320, bias=True)
        (q4): Linear(in_features=512, out_features=512, bias=True)
        (k1): Linear(in_features=64, out_features=64, bias=True)
        (k2): Linear(in_features=128, out_features=128, bias=True)
        (k3): Linear(in_features=320, out_features=320, bias=True)
        (k4): Linear(in_features=512, out_features=512, bias=True)
        (i4): Linear(in_features=64, out_features=64, bias=True)
        (i3): Linear(in_features=128, out_features=128, bias=True)
        (i2): Linear(in_features=320, out_features=320, bias=True)
        (i1): Linear(in_features=512, out_features=512, bias=True)
        (iv4): Linear(in_features=64, out_features=64, bias=True)
        (iv3): Linear(in_features=128, out_features=128, bias=True)
        (iv2): Linear(in_features=320, out_features=320, bias=True)
        (iv1): Linear(in_features=512, out_features=512, bias=True)
        (pooling_mhsa_fk4): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          )
        )
        (pooling_mhsa_fk3): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          )
        )
        (pooling_mhsa_fk2): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          )
        )
        (pooling_mhsa_fk1): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
        )
        (pooling_mhsa_sk4): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          )
        )
        (pooling_mhsa_sk3): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          )
        )
        (pooling_mhsa_sk2): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          )
        )
        (pooling_mhsa_sk1): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
        )
        (pooling_mhsa_f4): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          )
        )
        (pooling_mhsa_f3): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          )
        )
        (pooling_mhsa_f2): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
          )
        )
        (pooling_mhsa_f1): pooling_mhsa(
          (pools): ModuleList()
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (d_convs): ModuleList(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
        )
        (f4): Linear(in_features=64, out_features=64, bias=True)
        (f3): Linear(in_features=128, out_features=128, bias=True)
        (f2): Linear(in_features=320, out_features=320, bias=True)
        (f1): Linear(in_features=512, out_features=512, bias=True)
        (v4): Linear(in_features=64, out_features=64, bias=True)
        (v3): Linear(in_features=128, out_features=128, bias=True)
        (v2): Linear(in_features=320, out_features=320, bias=True)
        (v1): Linear(in_features=512, out_features=512, bias=True)
        (fs4): Linear(in_features=64, out_features=64, bias=True)
        (fs3): Linear(in_features=128, out_features=128, bias=True)
        (fs2): Linear(in_features=320, out_features=320, bias=True)
        (fs1): Linear(in_features=512, out_features=512, bias=True)
        (vs4): Linear(in_features=64, out_features=64, bias=True)
        (vs3): Linear(in_features=128, out_features=128, bias=True)
        (vs2): Linear(in_features=320, out_features=320, bias=True)
        (vs1): Linear(in_features=512, out_features=512, bias=True)
        (pk4): Linear(in_features=64, out_features=64, bias=True)
        (pk3): Linear(in_features=128, out_features=128, bias=True)
        (pk2): Linear(in_features=320, out_features=320, bias=True)
        (pk1): Linear(in_features=512, out_features=512, bias=True)
        (f4p): Linear(in_features=64, out_features=64, bias=True)
        (f3p): Linear(in_features=128, out_features=128, bias=True)
        (f2p): Linear(in_features=320, out_features=320, bias=True)
        (f1p): Linear(in_features=512, out_features=512, bias=True)
        (pooling_proj_linear): Linear(in_features=1024, out_features=256, bias=True)
        (pooling_proj_linear_1): Linear(in_features=1024, out_features=256, bias=True)
        (pooling_proj_linear_2): Linear(in_features=1024, out_features=256, bias=True)
        (pooling_proj_linear_3): Linear(in_features=1024, out_features=256, bias=True)
        (hpn): HPNLearner_topk2(
          (encoder_layer4): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer4to3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3to2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
        )
        (hpn1): HPNLearner_topk2(
          (encoder_layer4): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer4to3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3to2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
        )
        (hpn2): HPNLearner_topk2(
          (encoder_layer4): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer4to3): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (encoder_layer3to2): Sequential(
            (0): CenterPivotConv4d_half(
              (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): GroupNorm(1, 1, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
        )
        (linear1): Linear(in_features=512, out_features=512, bias=True)
        (linear2): Linear(in_features=512, out_features=512, bias=True)
      )
      (refine_block): Sequential(
        (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (sr2): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
      (sr3): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
      (sr1_feat): Conv2d(256, 256, kernel_size=(4, 4), stride=(4, 4))
      (dropout1): Dropout2d(p=0.3, inplace=False)
      (dropout2): Dropout2d(p=0.3, inplace=False)
      (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (conv_layer_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_layer_2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_layer_3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_layer_4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv_down_sample1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (memory): FeatureMemory(
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (linear3): Linear(in_features=512, out_features=512, bias=True)
      (initlinear): Linear(in_features=512, out_features=512, bias=True)
      (initlinear2): Linear(in_features=512, out_features=512, bias=True)
      (initlinear3): Linear(in_features=512, out_features=512, bias=True)
      (average_pooling): AdaptiveAvgPool2d(output_size=4)
    )
  )
)
2023-08-08 05:30:47,464 - mmseg - INFO - 
Number of parameters (in millions): 67.856
2023-08-08 05:30:47,469 - mmseg - INFO - 
Number of parameters (in millions): 24.196
2023-08-08 05:30:47,471 - mmseg - INFO - Number of parameters (in millions) for decoder: 43.660

flip video:  True
flip video:  True
flip video:  True
flip video:  True
flip video:  True
2023-08-08 05:30:51,921 - mmseg - INFO - load checkpoint from model_path/vspw2/work_dirs_4g_b9/latest.pth
flip video:  True
flip video:  True
flip video:  True
2023-08-08 05:30:58,845 - mmseg - WARNING - The model and loaded state dict do not match exactly

size mismatch for decode_head.memory.memory: copying a param with shape torch.Size([1, 512, 4, 4]) from checkpoint, the shape in current model is torch.Size([1, 512, 15, 15]).
2023-08-08 05:30:58,959 - mmseg - INFO - resumed from epoch: 5, iter 152000
2023-08-08 05:30:58,963 - mmseg - INFO - Start running, host: lixinhao@user, work_dir: /datadisk/lixinhao/vss/model_path/vspw2/work_dirs_4g_b8_2
2023-08-08 05:30:58,963 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
[W reducer.cpp:346] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [2048, 1, 3, 3], strides() = [9, 9, 3, 1] (function operator())
[W reducer.cpp:346] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [2048, 1, 3, 3], strides() = [9, 9, 3, 1] (function operator())
[W reducer.cpp:346] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [2048, 1, 3, 3], strides() = [9, 9, 3, 1] (function operator())
[W reducer.cpp:346] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [2048, 1, 3, 3], strides() = [9, 9, 3, 1] (function operator())
2023-08-08 05:31:58,593 - mmseg - INFO - Iter [152050/160000]	lr: 4.472e-07, eta: 2:11:31, time: 0.993, data_time: 0.020, memory: 16557, decode.loss_seg: 0.2839, decode.acc_seg: 77.5466, loss: 0.2839
2023-08-08 05:32:45,446 - mmseg - INFO - Iter [152100/160000]	lr: 4.444e-07, eta: 2:07:02, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2986, decode.acc_seg: 78.4550, loss: 0.2986
2023-08-08 05:33:32,502 - mmseg - INFO - Iter [152150/160000]	lr: 4.416e-07, eta: 2:05:12, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2791, decode.acc_seg: 78.3253, loss: 0.2791
2023-08-08 05:34:19,570 - mmseg - INFO - Iter [152200/160000]	lr: 4.388e-07, eta: 2:03:53, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2718, decode.acc_seg: 77.8530, loss: 0.2718
2023-08-08 05:35:06,637 - mmseg - INFO - Iter [152250/160000]	lr: 4.360e-07, eta: 2:02:48, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3308, decode.acc_seg: 77.3745, loss: 0.3308
2023-08-08 05:35:53,706 - mmseg - INFO - Iter [152300/160000]	lr: 4.332e-07, eta: 2:01:48, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2819, decode.acc_seg: 77.1039, loss: 0.2819
2023-08-08 05:36:40,435 - mmseg - INFO - Iter [152350/160000]	lr: 4.304e-07, eta: 2:00:45, time: 0.935, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2981, decode.acc_seg: 77.0598, loss: 0.2981
2023-08-08 05:37:27,550 - mmseg - INFO - Iter [152400/160000]	lr: 4.276e-07, eta: 1:59:53, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2815, decode.acc_seg: 77.1025, loss: 0.2815
2023-08-08 05:38:14,618 - mmseg - INFO - Iter [152450/160000]	lr: 4.247e-07, eta: 1:59:01, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2648, decode.acc_seg: 77.0421, loss: 0.2648
2023-08-08 05:39:01,585 - mmseg - INFO - Iter [152500/160000]	lr: 4.219e-07, eta: 1:58:09, time: 0.940, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2734, decode.acc_seg: 77.1052, loss: 0.2734
2023-08-08 05:39:48,673 - mmseg - INFO - Iter [152550/160000]	lr: 4.191e-07, eta: 1:57:19, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2832, decode.acc_seg: 78.4485, loss: 0.2832
2023-08-08 05:40:35,517 - mmseg - INFO - Iter [152600/160000]	lr: 4.163e-07, eta: 1:56:27, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2903, decode.acc_seg: 78.5022, loss: 0.2903
2023-08-08 05:41:22,490 - mmseg - INFO - Iter [152650/160000]	lr: 4.135e-07, eta: 1:55:37, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2878, decode.acc_seg: 79.1515, loss: 0.2878
2023-08-08 05:42:09,537 - mmseg - INFO - Iter [152700/160000]	lr: 4.107e-07, eta: 1:54:48, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3014, decode.acc_seg: 78.3996, loss: 0.3014
2023-08-08 05:42:56,382 - mmseg - INFO - Iter [152750/160000]	lr: 4.079e-07, eta: 1:53:57, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2940, decode.acc_seg: 80.6105, loss: 0.2940
2023-08-08 05:43:43,240 - mmseg - INFO - Iter [152800/160000]	lr: 4.051e-07, eta: 1:53:08, time: 0.938, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2602, decode.acc_seg: 76.7674, loss: 0.2602
2023-08-08 05:44:30,218 - mmseg - INFO - Iter [152850/160000]	lr: 4.022e-07, eta: 1:52:19, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2787, decode.acc_seg: 78.3178, loss: 0.2787
2023-08-08 05:45:17,015 - mmseg - INFO - Iter [152900/160000]	lr: 3.994e-07, eta: 1:51:30, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2732, decode.acc_seg: 78.8428, loss: 0.2732
2023-08-08 05:46:04,184 - mmseg - INFO - Iter [152950/160000]	lr: 3.966e-07, eta: 1:50:43, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2885, decode.acc_seg: 79.5232, loss: 0.2885
2023-08-08 05:46:51,332 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 05:46:51,333 - mmseg - INFO - Iter [153000/160000]	lr: 3.938e-07, eta: 1:49:56, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2868, decode.acc_seg: 78.9315, loss: 0.2868
2023-08-08 05:47:38,334 - mmseg - INFO - Iter [153050/160000]	lr: 3.910e-07, eta: 1:49:08, time: 0.940, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2816, decode.acc_seg: 78.8391, loss: 0.2816
2023-08-08 05:48:25,460 - mmseg - INFO - Iter [153100/160000]	lr: 3.882e-07, eta: 1:48:21, time: 0.942, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2932, decode.acc_seg: 75.8566, loss: 0.2932
2023-08-08 05:49:12,835 - mmseg - INFO - Iter [153150/160000]	lr: 3.854e-07, eta: 1:47:35, time: 0.947, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2931, decode.acc_seg: 78.4170, loss: 0.2931
2023-08-08 05:49:59,959 - mmseg - INFO - Iter [153200/160000]	lr: 3.826e-07, eta: 1:46:48, time: 0.943, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2682, decode.acc_seg: 79.1503, loss: 0.2682
2023-08-08 05:50:46,501 - mmseg - INFO - Iter [153250/160000]	lr: 3.797e-07, eta: 1:45:58, time: 0.931, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2887, decode.acc_seg: 79.0062, loss: 0.2887
2023-08-08 05:51:33,398 - mmseg - INFO - Iter [153300/160000]	lr: 3.769e-07, eta: 1:45:10, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2804, decode.acc_seg: 78.2900, loss: 0.2804
2023-08-08 05:52:20,407 - mmseg - INFO - Iter [153350/160000]	lr: 3.741e-07, eta: 1:44:22, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2883, decode.acc_seg: 77.8615, loss: 0.2883
2023-08-08 05:53:07,163 - mmseg - INFO - Iter [153400/160000]	lr: 3.713e-07, eta: 1:43:34, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2920, decode.acc_seg: 78.8084, loss: 0.2920
2023-08-08 05:53:54,269 - mmseg - INFO - Iter [153450/160000]	lr: 3.685e-07, eta: 1:42:47, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2822, decode.acc_seg: 78.5348, loss: 0.2822
2023-08-08 05:54:41,298 - mmseg - INFO - Iter [153500/160000]	lr: 3.657e-07, eta: 1:42:00, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2694, decode.acc_seg: 80.0794, loss: 0.2694
2023-08-08 05:55:28,222 - mmseg - INFO - Iter [153550/160000]	lr: 3.629e-07, eta: 1:41:12, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2903, decode.acc_seg: 76.5811, loss: 0.2903
2023-08-08 05:56:14,950 - mmseg - INFO - Iter [153600/160000]	lr: 3.601e-07, eta: 1:40:23, time: 0.934, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2598, decode.acc_seg: 79.0333, loss: 0.2598
2023-08-08 05:57:02,308 - mmseg - INFO - Iter [153650/160000]	lr: 3.572e-07, eta: 1:39:37, time: 0.947, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2761, decode.acc_seg: 78.6263, loss: 0.2761
2023-08-08 05:57:49,271 - mmseg - INFO - Iter [153700/160000]	lr: 3.544e-07, eta: 1:38:50, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2556, decode.acc_seg: 78.1341, loss: 0.2556
2023-08-08 05:58:36,528 - mmseg - INFO - Iter [153750/160000]	lr: 3.516e-07, eta: 1:38:04, time: 0.945, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2709, decode.acc_seg: 80.5002, loss: 0.2709
2023-08-08 05:59:23,651 - mmseg - INFO - Iter [153800/160000]	lr: 3.488e-07, eta: 1:37:17, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2920, decode.acc_seg: 78.5058, loss: 0.2920
2023-08-08 06:00:10,553 - mmseg - INFO - Iter [153850/160000]	lr: 3.460e-07, eta: 1:36:29, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2865, decode.acc_seg: 78.2157, loss: 0.2865
2023-08-08 06:00:57,342 - mmseg - INFO - Iter [153900/160000]	lr: 3.432e-07, eta: 1:35:41, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2953, decode.acc_seg: 77.7872, loss: 0.2953
2023-08-08 06:01:44,042 - mmseg - INFO - Iter [153950/160000]	lr: 3.404e-07, eta: 1:34:53, time: 0.934, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2527, decode.acc_seg: 77.7860, loss: 0.2527
2023-08-08 06:02:31,121 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 06:02:31,121 - mmseg - INFO - Iter [154000/160000]	lr: 3.376e-07, eta: 1:34:06, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3113, decode.acc_seg: 76.6217, loss: 0.3113
2023-08-08 06:03:18,314 - mmseg - INFO - Iter [154050/160000]	lr: 3.347e-07, eta: 1:33:19, time: 0.944, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3161, decode.acc_seg: 77.7441, loss: 0.3161
2023-08-08 06:04:05,231 - mmseg - INFO - Iter [154100/160000]	lr: 3.319e-07, eta: 1:32:32, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2869, decode.acc_seg: 78.2972, loss: 0.2869
2023-08-08 06:04:52,125 - mmseg - INFO - Iter [154150/160000]	lr: 3.291e-07, eta: 1:31:44, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2726, decode.acc_seg: 78.2757, loss: 0.2726
2023-08-08 06:05:39,085 - mmseg - INFO - Iter [154200/160000]	lr: 3.263e-07, eta: 1:30:57, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2860, decode.acc_seg: 78.2715, loss: 0.2860
2023-08-08 06:06:25,947 - mmseg - INFO - Iter [154250/160000]	lr: 3.235e-07, eta: 1:30:09, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2733, decode.acc_seg: 80.2551, loss: 0.2733
2023-08-08 06:07:13,206 - mmseg - INFO - Iter [154300/160000]	lr: 3.207e-07, eta: 1:29:23, time: 0.946, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3020, decode.acc_seg: 76.4443, loss: 0.3020
2023-08-08 06:08:00,109 - mmseg - INFO - Iter [154350/160000]	lr: 3.179e-07, eta: 1:28:36, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2554, decode.acc_seg: 80.6086, loss: 0.2554
2023-08-08 06:08:47,227 - mmseg - INFO - Iter [154400/160000]	lr: 3.151e-07, eta: 1:27:49, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3074, decode.acc_seg: 78.0292, loss: 0.3074
2023-08-08 06:09:34,542 - mmseg - INFO - Iter [154450/160000]	lr: 3.122e-07, eta: 1:27:02, time: 0.946, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2616, decode.acc_seg: 76.7926, loss: 0.2616
2023-08-08 06:10:21,269 - mmseg - INFO - Iter [154500/160000]	lr: 3.094e-07, eta: 1:26:15, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3238, decode.acc_seg: 77.0141, loss: 0.3238
2023-08-08 06:11:08,217 - mmseg - INFO - Iter [154550/160000]	lr: 3.066e-07, eta: 1:25:27, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2699, decode.acc_seg: 77.0000, loss: 0.2699
2023-08-08 06:11:54,960 - mmseg - INFO - Iter [154600/160000]	lr: 3.038e-07, eta: 1:24:40, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2789, decode.acc_seg: 77.8930, loss: 0.2789
2023-08-08 06:12:41,847 - mmseg - INFO - Iter [154650/160000]	lr: 3.010e-07, eta: 1:23:52, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2651, decode.acc_seg: 76.9380, loss: 0.2651
2023-08-08 06:13:28,902 - mmseg - INFO - Iter [154700/160000]	lr: 2.982e-07, eta: 1:23:05, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3015, decode.acc_seg: 77.6867, loss: 0.3015
2023-08-08 06:14:15,761 - mmseg - INFO - Iter [154750/160000]	lr: 2.954e-07, eta: 1:22:18, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2704, decode.acc_seg: 78.1159, loss: 0.2704
2023-08-08 06:15:02,545 - mmseg - INFO - Iter [154800/160000]	lr: 2.926e-07, eta: 1:21:30, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2704, decode.acc_seg: 78.0723, loss: 0.2704
2023-08-08 06:15:49,332 - mmseg - INFO - Iter [154850/160000]	lr: 2.897e-07, eta: 1:20:43, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2681, decode.acc_seg: 77.9226, loss: 0.2681
2023-08-08 06:16:36,391 - mmseg - INFO - Iter [154900/160000]	lr: 2.869e-07, eta: 1:19:56, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2772, decode.acc_seg: 78.2864, loss: 0.2772
2023-08-08 06:17:23,262 - mmseg - INFO - Iter [154950/160000]	lr: 2.841e-07, eta: 1:19:09, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3169, decode.acc_seg: 78.2362, loss: 0.3169
2023-08-08 06:18:10,156 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 06:18:10,156 - mmseg - INFO - Iter [155000/160000]	lr: 2.813e-07, eta: 1:18:21, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2849, decode.acc_seg: 76.6748, loss: 0.2849
2023-08-08 06:18:56,994 - mmseg - INFO - Iter [155050/160000]	lr: 2.785e-07, eta: 1:17:34, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2738, decode.acc_seg: 79.5220, loss: 0.2738
2023-08-08 06:19:43,990 - mmseg - INFO - Iter [155100/160000]	lr: 2.757e-07, eta: 1:16:47, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2755, decode.acc_seg: 79.2659, loss: 0.2755
2023-08-08 06:20:30,743 - mmseg - INFO - Iter [155150/160000]	lr: 2.729e-07, eta: 1:16:00, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2792, decode.acc_seg: 77.8997, loss: 0.2792
2023-08-08 06:21:17,777 - mmseg - INFO - Iter [155200/160000]	lr: 2.701e-07, eta: 1:15:13, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2930, decode.acc_seg: 77.4970, loss: 0.2930
2023-08-08 06:22:04,731 - mmseg - INFO - Iter [155250/160000]	lr: 2.672e-07, eta: 1:14:26, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2383, decode.acc_seg: 78.5410, loss: 0.2383
2023-08-08 06:22:51,626 - mmseg - INFO - Iter [155300/160000]	lr: 2.644e-07, eta: 1:13:38, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2623, decode.acc_seg: 78.8704, loss: 0.2623
2023-08-08 06:23:38,830 - mmseg - INFO - Iter [155350/160000]	lr: 2.616e-07, eta: 1:12:52, time: 0.945, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2796, decode.acc_seg: 78.2090, loss: 0.2796
2023-08-08 06:24:26,168 - mmseg - INFO - Iter [155400/160000]	lr: 2.588e-07, eta: 1:12:05, time: 0.946, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3108, decode.acc_seg: 76.5429, loss: 0.3108
2023-08-08 06:25:13,228 - mmseg - INFO - Iter [155450/160000]	lr: 2.560e-07, eta: 1:11:18, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2864, decode.acc_seg: 76.4596, loss: 0.2864
2023-08-08 06:26:00,266 - mmseg - INFO - Iter [155500/160000]	lr: 2.532e-07, eta: 1:10:31, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2650, decode.acc_seg: 76.3005, loss: 0.2650
2023-08-08 06:26:47,130 - mmseg - INFO - Iter [155550/160000]	lr: 2.504e-07, eta: 1:09:44, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2999, decode.acc_seg: 76.3730, loss: 0.2999
2023-08-08 06:27:34,012 - mmseg - INFO - Iter [155600/160000]	lr: 2.476e-07, eta: 1:08:57, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2912, decode.acc_seg: 77.1029, loss: 0.2912
2023-08-08 06:28:20,854 - mmseg - INFO - Iter [155650/160000]	lr: 2.447e-07, eta: 1:08:10, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2713, decode.acc_seg: 76.6983, loss: 0.2713
2023-08-08 06:29:07,893 - mmseg - INFO - Iter [155700/160000]	lr: 2.419e-07, eta: 1:07:23, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2923, decode.acc_seg: 79.4585, loss: 0.2923
2023-08-08 06:29:55,029 - mmseg - INFO - Iter [155750/160000]	lr: 2.391e-07, eta: 1:06:36, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2866, decode.acc_seg: 77.9170, loss: 0.2866
2023-08-08 06:30:41,939 - mmseg - INFO - Iter [155800/160000]	lr: 2.363e-07, eta: 1:05:49, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2686, decode.acc_seg: 78.4580, loss: 0.2686
2023-08-08 06:31:28,954 - mmseg - INFO - Iter [155850/160000]	lr: 2.335e-07, eta: 1:05:02, time: 0.940, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2813, decode.acc_seg: 79.6397, loss: 0.2813
2023-08-08 06:32:15,905 - mmseg - INFO - Iter [155900/160000]	lr: 2.307e-07, eta: 1:04:14, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2816, decode.acc_seg: 77.6836, loss: 0.2816
2023-08-08 06:33:02,777 - mmseg - INFO - Iter [155950/160000]	lr: 2.279e-07, eta: 1:03:27, time: 0.937, data_time: 0.008, memory: 16557, decode.loss_seg: 0.2952, decode.acc_seg: 77.5324, loss: 0.2952
2023-08-08 06:33:49,875 - mmseg - INFO - Saving checkpoint at 156000 iterations
2023-08-08 06:33:50,852 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 06:33:50,852 - mmseg - INFO - Iter [156000/160000]	lr: 2.251e-07, eta: 1:02:41, time: 0.961, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2745, decode.acc_seg: 78.7622, loss: 0.2745
2023-08-08 06:34:37,568 - mmseg - INFO - Iter [156050/160000]	lr: 2.222e-07, eta: 1:01:54, time: 0.934, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2543, decode.acc_seg: 78.1446, loss: 0.2543
2023-08-08 06:35:24,485 - mmseg - INFO - Iter [156100/160000]	lr: 2.194e-07, eta: 1:01:07, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2724, decode.acc_seg: 78.0672, loss: 0.2724
2023-08-08 06:36:11,994 - mmseg - INFO - Iter [156150/160000]	lr: 2.166e-07, eta: 1:00:20, time: 0.949, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2570, decode.acc_seg: 77.2944, loss: 0.2570
2023-08-08 06:36:58,844 - mmseg - INFO - Iter [156200/160000]	lr: 2.138e-07, eta: 0:59:33, time: 0.938, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2892, decode.acc_seg: 78.2478, loss: 0.2892
2023-08-08 06:37:45,808 - mmseg - INFO - Iter [156250/160000]	lr: 2.110e-07, eta: 0:58:46, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2717, decode.acc_seg: 79.6368, loss: 0.2717
2023-08-08 06:38:32,634 - mmseg - INFO - Iter [156300/160000]	lr: 2.082e-07, eta: 0:57:59, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2968, decode.acc_seg: 77.0294, loss: 0.2968
2023-08-08 06:39:19,405 - mmseg - INFO - Iter [156350/160000]	lr: 2.054e-07, eta: 0:57:12, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2914, decode.acc_seg: 79.2520, loss: 0.2914
2023-08-08 06:40:06,458 - mmseg - INFO - Iter [156400/160000]	lr: 2.026e-07, eta: 0:56:25, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2602, decode.acc_seg: 78.0706, loss: 0.2602
2023-08-08 06:40:53,305 - mmseg - INFO - Iter [156450/160000]	lr: 1.997e-07, eta: 0:55:38, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2887, decode.acc_seg: 78.4876, loss: 0.2887
2023-08-08 06:41:40,250 - mmseg - INFO - Iter [156500/160000]	lr: 1.969e-07, eta: 0:54:50, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2898, decode.acc_seg: 79.5243, loss: 0.2898
2023-08-08 06:42:27,312 - mmseg - INFO - Iter [156550/160000]	lr: 1.941e-07, eta: 0:54:04, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3037, decode.acc_seg: 77.6208, loss: 0.3037
2023-08-08 06:43:14,307 - mmseg - INFO - Iter [156600/160000]	lr: 1.913e-07, eta: 0:53:16, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2601, decode.acc_seg: 81.0270, loss: 0.2601
2023-08-08 06:44:01,123 - mmseg - INFO - Iter [156650/160000]	lr: 1.885e-07, eta: 0:52:29, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3147, decode.acc_seg: 78.2748, loss: 0.3147
2023-08-08 06:44:48,072 - mmseg - INFO - Iter [156700/160000]	lr: 1.857e-07, eta: 0:51:42, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2959, decode.acc_seg: 78.1654, loss: 0.2959
2023-08-08 06:45:34,812 - mmseg - INFO - Iter [156750/160000]	lr: 1.829e-07, eta: 0:50:55, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2603, decode.acc_seg: 79.4407, loss: 0.2603
2023-08-08 06:46:21,994 - mmseg - INFO - Iter [156800/160000]	lr: 1.801e-07, eta: 0:50:08, time: 0.944, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2813, decode.acc_seg: 78.4542, loss: 0.2813
2023-08-08 06:47:09,063 - mmseg - INFO - Iter [156850/160000]	lr: 1.772e-07, eta: 0:49:21, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2858, decode.acc_seg: 78.8429, loss: 0.2858
2023-08-08 06:47:56,144 - mmseg - INFO - Iter [156900/160000]	lr: 1.744e-07, eta: 0:48:34, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2758, decode.acc_seg: 78.3552, loss: 0.2758
2023-08-08 06:48:43,360 - mmseg - INFO - Iter [156950/160000]	lr: 1.716e-07, eta: 0:47:47, time: 0.944, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2461, decode.acc_seg: 79.6951, loss: 0.2461
2023-08-08 06:49:30,317 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 06:49:30,318 - mmseg - INFO - Iter [157000/160000]	lr: 1.688e-07, eta: 0:47:00, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2795, decode.acc_seg: 78.3335, loss: 0.2795
2023-08-08 06:50:17,249 - mmseg - INFO - Iter [157050/160000]	lr: 1.660e-07, eta: 0:46:13, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2606, decode.acc_seg: 78.2031, loss: 0.2606
2023-08-08 06:51:04,332 - mmseg - INFO - Iter [157100/160000]	lr: 1.632e-07, eta: 0:45:26, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2849, decode.acc_seg: 77.6557, loss: 0.2849
2023-08-08 06:51:51,230 - mmseg - INFO - Iter [157150/160000]	lr: 1.604e-07, eta: 0:44:39, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3027, decode.acc_seg: 78.0014, loss: 0.3027
2023-08-08 06:52:38,045 - mmseg - INFO - Iter [157200/160000]	lr: 1.576e-07, eta: 0:43:52, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2589, decode.acc_seg: 79.2948, loss: 0.2589
2023-08-08 06:53:25,082 - mmseg - INFO - Iter [157250/160000]	lr: 1.547e-07, eta: 0:43:05, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2929, decode.acc_seg: 77.4423, loss: 0.2929
2023-08-08 06:54:11,916 - mmseg - INFO - Iter [157300/160000]	lr: 1.519e-07, eta: 0:42:18, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2970, decode.acc_seg: 78.4398, loss: 0.2970
2023-08-08 06:54:58,760 - mmseg - INFO - Iter [157350/160000]	lr: 1.491e-07, eta: 0:41:31, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2734, decode.acc_seg: 79.2808, loss: 0.2734
2023-08-08 06:55:45,635 - mmseg - INFO - Iter [157400/160000]	lr: 1.463e-07, eta: 0:40:44, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2646, decode.acc_seg: 79.7903, loss: 0.2646
2023-08-08 06:56:32,691 - mmseg - INFO - Iter [157450/160000]	lr: 1.435e-07, eta: 0:39:57, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2666, decode.acc_seg: 78.2761, loss: 0.2666
2023-08-08 06:57:19,541 - mmseg - INFO - Iter [157500/160000]	lr: 1.407e-07, eta: 0:39:10, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3064, decode.acc_seg: 77.5726, loss: 0.3064
2023-08-08 06:58:06,210 - mmseg - INFO - Iter [157550/160000]	lr: 1.379e-07, eta: 0:38:23, time: 0.934, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2951, decode.acc_seg: 79.3704, loss: 0.2951
2023-08-08 06:58:53,098 - mmseg - INFO - Iter [157600/160000]	lr: 1.351e-07, eta: 0:37:36, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2663, decode.acc_seg: 78.9900, loss: 0.2663
2023-08-08 06:59:40,169 - mmseg - INFO - Iter [157650/160000]	lr: 1.322e-07, eta: 0:36:49, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2885, decode.acc_seg: 77.9841, loss: 0.2885
2023-08-08 07:00:27,236 - mmseg - INFO - Iter [157700/160000]	lr: 1.294e-07, eta: 0:36:02, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3011, decode.acc_seg: 79.1419, loss: 0.3011
2023-08-08 07:01:14,301 - mmseg - INFO - Iter [157750/160000]	lr: 1.266e-07, eta: 0:35:15, time: 0.942, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2544, decode.acc_seg: 79.7872, loss: 0.2544
2023-08-08 07:02:01,653 - mmseg - INFO - Iter [157800/160000]	lr: 1.238e-07, eta: 0:34:28, time: 0.947, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2937, decode.acc_seg: 76.7774, loss: 0.2937
2023-08-08 07:02:48,652 - mmseg - INFO - Iter [157850/160000]	lr: 1.210e-07, eta: 0:33:41, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2871, decode.acc_seg: 78.5347, loss: 0.2871
2023-08-08 07:03:35,820 - mmseg - INFO - Iter [157900/160000]	lr: 1.182e-07, eta: 0:32:54, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2865, decode.acc_seg: 77.8183, loss: 0.2865
2023-08-08 07:04:22,711 - mmseg - INFO - Iter [157950/160000]	lr: 1.154e-07, eta: 0:32:07, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2839, decode.acc_seg: 79.3352, loss: 0.2839
2023-08-08 07:05:09,635 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 07:05:09,635 - mmseg - INFO - Iter [158000/160000]	lr: 1.126e-07, eta: 0:31:20, time: 0.939, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2824, decode.acc_seg: 77.7739, loss: 0.2824
2023-08-08 07:05:56,713 - mmseg - INFO - Iter [158050/160000]	lr: 1.097e-07, eta: 0:30:33, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2715, decode.acc_seg: 77.1071, loss: 0.2715
2023-08-08 07:06:43,745 - mmseg - INFO - Iter [158100/160000]	lr: 1.069e-07, eta: 0:29:46, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2920, decode.acc_seg: 76.9422, loss: 0.2920
2023-08-08 07:07:30,506 - mmseg - INFO - Iter [158150/160000]	lr: 1.041e-07, eta: 0:28:59, time: 0.935, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2842, decode.acc_seg: 78.9899, loss: 0.2842
2023-08-08 07:08:17,723 - mmseg - INFO - Iter [158200/160000]	lr: 1.013e-07, eta: 0:28:12, time: 0.944, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2703, decode.acc_seg: 79.7889, loss: 0.2703
2023-08-08 07:09:05,170 - mmseg - INFO - Iter [158250/160000]	lr: 9.849e-08, eta: 0:27:25, time: 0.949, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2929, decode.acc_seg: 79.2790, loss: 0.2929
2023-08-08 07:09:51,880 - mmseg - INFO - Iter [158300/160000]	lr: 9.568e-08, eta: 0:26:38, time: 0.934, data_time: 0.008, memory: 16557, decode.loss_seg: 0.2890, decode.acc_seg: 76.6275, loss: 0.2890
2023-08-08 07:10:38,604 - mmseg - INFO - Iter [158350/160000]	lr: 9.287e-08, eta: 0:25:51, time: 0.934, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2785, decode.acc_seg: 79.0798, loss: 0.2785
2023-08-08 07:11:25,739 - mmseg - INFO - Iter [158400/160000]	lr: 9.006e-08, eta: 0:25:04, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2641, decode.acc_seg: 79.0798, loss: 0.2641
2023-08-08 07:12:12,475 - mmseg - INFO - Iter [158450/160000]	lr: 8.724e-08, eta: 0:24:17, time: 0.935, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2962, decode.acc_seg: 78.1916, loss: 0.2962
2023-08-08 07:12:59,944 - mmseg - INFO - Iter [158500/160000]	lr: 8.443e-08, eta: 0:23:30, time: 0.949, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2708, decode.acc_seg: 77.2518, loss: 0.2708
2023-08-08 07:13:46,791 - mmseg - INFO - Iter [158550/160000]	lr: 8.162e-08, eta: 0:22:43, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3085, decode.acc_seg: 77.8974, loss: 0.3085
2023-08-08 07:14:33,862 - mmseg - INFO - Iter [158600/160000]	lr: 7.881e-08, eta: 0:21:56, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2709, decode.acc_seg: 77.7375, loss: 0.2709
2023-08-08 07:15:20,895 - mmseg - INFO - Iter [158650/160000]	lr: 7.599e-08, eta: 0:21:09, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2733, decode.acc_seg: 78.8025, loss: 0.2733
2023-08-08 07:16:08,232 - mmseg - INFO - Iter [158700/160000]	lr: 7.318e-08, eta: 0:20:22, time: 0.947, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2602, decode.acc_seg: 78.3620, loss: 0.2602
2023-08-08 07:16:55,389 - mmseg - INFO - Iter [158750/160000]	lr: 7.037e-08, eta: 0:19:35, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2647, decode.acc_seg: 77.7251, loss: 0.2647
2023-08-08 07:17:42,291 - mmseg - INFO - Iter [158800/160000]	lr: 6.756e-08, eta: 0:18:48, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2529, decode.acc_seg: 79.0280, loss: 0.2529
2023-08-08 07:18:29,168 - mmseg - INFO - Iter [158850/160000]	lr: 6.474e-08, eta: 0:18:01, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.3063, decode.acc_seg: 77.4340, loss: 0.3063
2023-08-08 07:19:16,238 - mmseg - INFO - Iter [158900/160000]	lr: 6.193e-08, eta: 0:17:14, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2780, decode.acc_seg: 78.3688, loss: 0.2780
2023-08-08 07:20:03,476 - mmseg - INFO - Iter [158950/160000]	lr: 5.912e-08, eta: 0:16:27, time: 0.944, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2684, decode.acc_seg: 78.0093, loss: 0.2684
2023-08-08 07:20:50,588 - mmseg - INFO - Exp name: mrcfa.b2.480x480.vspw2_hypercorr.160k.py
2023-08-08 07:20:50,589 - mmseg - INFO - Iter [159000/160000]	lr: 5.631e-08, eta: 0:15:40, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2942, decode.acc_seg: 79.4177, loss: 0.2942
2023-08-08 07:21:37,435 - mmseg - INFO - Iter [159050/160000]	lr: 5.349e-08, eta: 0:14:53, time: 0.937, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2906, decode.acc_seg: 77.2934, loss: 0.2906
2023-08-08 07:22:24,454 - mmseg - INFO - Iter [159100/160000]	lr: 5.068e-08, eta: 0:14:06, time: 0.940, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2759, decode.acc_seg: 76.2569, loss: 0.2759
2023-08-08 07:23:11,563 - mmseg - INFO - Iter [159150/160000]	lr: 4.787e-08, eta: 0:13:19, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2825, decode.acc_seg: 76.8262, loss: 0.2825
2023-08-08 07:23:58,130 - mmseg - INFO - Iter [159200/160000]	lr: 4.506e-08, eta: 0:12:32, time: 0.931, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2912, decode.acc_seg: 78.3522, loss: 0.2912
2023-08-08 07:24:44,917 - mmseg - INFO - Iter [159250/160000]	lr: 4.224e-08, eta: 0:11:45, time: 0.936, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2877, decode.acc_seg: 78.4853, loss: 0.2877
2023-08-08 07:25:32,058 - mmseg - INFO - Iter [159300/160000]	lr: 3.943e-08, eta: 0:10:58, time: 0.943, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2938, decode.acc_seg: 77.6661, loss: 0.2938
2023-08-08 07:26:18,944 - mmseg - INFO - Iter [159350/160000]	lr: 3.662e-08, eta: 0:10:11, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2732, decode.acc_seg: 78.8517, loss: 0.2732
2023-08-08 07:27:06,077 - mmseg - INFO - Iter [159400/160000]	lr: 3.381e-08, eta: 0:09:24, time: 0.943, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2443, decode.acc_seg: 78.8212, loss: 0.2443
2023-08-08 07:27:53,148 - mmseg - INFO - Iter [159450/160000]	lr: 3.099e-08, eta: 0:08:37, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2819, decode.acc_seg: 78.9572, loss: 0.2819
2023-08-08 07:28:40,204 - mmseg - INFO - Iter [159500/160000]	lr: 2.818e-08, eta: 0:07:50, time: 0.941, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2594, decode.acc_seg: 77.5112, loss: 0.2594
2023-08-08 07:29:27,295 - mmseg - INFO - Iter [159550/160000]	lr: 2.537e-08, eta: 0:07:03, time: 0.942, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2377, decode.acc_seg: 79.5997, loss: 0.2377
2023-08-08 07:30:14,221 - mmseg - INFO - Iter [159600/160000]	lr: 2.256e-08, eta: 0:06:16, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2735, decode.acc_seg: 79.4743, loss: 0.2735
2023-08-08 07:31:01,114 - mmseg - INFO - Iter [159650/160000]	lr: 1.974e-08, eta: 0:05:29, time: 0.938, data_time: 0.009, memory: 16557, decode.loss_seg: 0.2888, decode.acc_seg: 76.2729, loss: 0.2888
2023-08-08 07:31:47,998 - mmseg - INFO - Iter [159700/160000]	lr: 1.693e-08, eta: 0:04:42, time: 0.938, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2780, decode.acc_seg: 78.9422, loss: 0.2780
2023-08-08 07:32:34,845 - mmseg - INFO - Iter [159750/160000]	lr: 1.412e-08, eta: 0:03:55, time: 0.937, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2603, decode.acc_seg: 78.2117, loss: 0.2603
2023-08-08 07:33:21,684 - mmseg - INFO - Iter [159800/160000]	lr: 1.131e-08, eta: 0:03:08, time: 0.937, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2902, decode.acc_seg: 76.5220, loss: 0.2902
2023-08-08 07:34:08,893 - mmseg - INFO - Iter [159850/160000]	lr: 8.494e-09, eta: 0:02:21, time: 0.944, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2567, decode.acc_seg: 79.9801, loss: 0.2567
2023-08-08 07:34:55,883 - mmseg - INFO - Iter [159900/160000]	lr: 5.681e-09, eta: 0:01:34, time: 0.940, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2618, decode.acc_seg: 76.7151, loss: 0.2618
2023-08-08 07:35:42,851 - mmseg - INFO - Iter [159950/160000]	lr: 2.869e-09, eta: 0:00:47, time: 0.939, data_time: 0.010, memory: 16557, decode.loss_seg: 0.2863, decode.acc_seg: 79.3615, loss: 0.2863
2023-08-08 07:36:30,059 - mmseg - INFO - Saving checkpoint at 160000 iterations
[                                                  ] 0/24392, elapsed: 0s, ETA:Traceback (most recent call last):
  File "./tools/train.py", line 188, in <module>
    main()
  File "./tools/train.py", line 184, in main
    meta=meta)
  File "/datadisk/lixinhao/vss/mmseg/apis/train.py", line 116, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 190, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 125, in train
    self.call_hook('after_train_iter')
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/base_runner.py", line 307, in call_hook
    getattr(hook, fn_name)(self)
  File "/datadisk/lixinhao/vss/mmseg/core/evaluation/eval_hooks.py", line 89, in after_train_iter
    gpu_collect=self.gpu_collect)
  File "/datadisk/lixinhao/vss/mmseg/apis/test.py", line 145, in multi_gpu_test
    result = model(memory,return_loss=False, rescale=True, **data)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 84, in new_func
    return old_func(*args, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 127, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 109, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 591, in simple_test
    seg_logit = self.inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 557, in inference
    seg_logit = self.whole_inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 522, in whole_inference
    seg_logit = self.encode_decode(img, img_meta, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 373, in encode_decode
    out = self._decode_head_forward_test(x, img_metas, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 396, in _decode_head_forward_test
    seg_logits = self.decode_head.forward_test(x, img_metas, self.test_cfg, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/decode_head.py", line 454, in forward_test
    return self.forward(inputs, batch_size, num_clips,memory)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/segformer_interval.py", line 126, in forward
    memoryFeature = self.memory(mode ='update_memory',feats=inputs[-1][int((i/num_infer-1)*num_infer):int((i/num_infer)*num_infer),:])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 109, in forward
    return self.update_memory(feats)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 75, in update_memory
    feats = feats.reshape(B,cx,hx*wx).permute(0,2,1)
RuntimeError: shape '[1, 512, 405]' is invalid for input of size 8192
Traceback (most recent call last):
  File "./tools/train.py", line 188, in <module>
    main()
  File "./tools/train.py", line 184, in main
    meta=meta)
  File "/datadisk/lixinhao/vss/mmseg/apis/train.py", line 116, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 190, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 125, in train
    self.call_hook('after_train_iter')
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/base_runner.py", line 307, in call_hook
    getattr(hook, fn_name)(self)
  File "/datadisk/lixinhao/vss/mmseg/core/evaluation/eval_hooks.py", line 89, in after_train_iter
    gpu_collect=self.gpu_collect)
  File "/datadisk/lixinhao/vss/mmseg/apis/test.py", line 145, in multi_gpu_test
    result = model(memory,return_loss=False, rescale=True, **data)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 84, in new_func
    return old_func(*args, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 127, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 109, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 591, in simple_test
    seg_logit = self.inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 557, in inference
    seg_logit = self.whole_inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 522, in whole_inference
    seg_logit = self.encode_decode(img, img_meta, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 373, in encode_decode
    out = self._decode_head_forward_test(x, img_metas, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 396, in _decode_head_forward_test
    seg_logits = self.decode_head.forward_test(x, img_metas, self.test_cfg, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/decode_head.py", line 454, in forward_test
    return self.forward(inputs, batch_size, num_clips,memory)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/segformer_interval.py", line 126, in forward
    memoryFeature = self.memory(mode ='update_memory',feats=inputs[-1][int((i/num_infer-1)*num_infer):int((i/num_infer)*num_infer),:])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 109, in forward
    return self.update_memory(feats)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 75, in update_memory
    feats = feats.reshape(B,cx,hx*wx).permute(0,2,1)
RuntimeError: shape '[1, 512, 405]' is invalid for input of size 8192
[                             ] 1/24392, 0.1 task/s, elapsed: 11s, ETA: 262104s[                             ] 2/24392, 0.2 task/s, elapsed: 11s, ETA: 131051s[                              ] 3/24392, 0.3 task/s, elapsed: 11s, ETA: 87364s[                              ] 4/24392, 0.4 task/s, elapsed: 11s, ETA: 65521s[                              ] 5/24392, 0.4 task/s, elapsed: 11s, ETA: 55847s[                              ] 6/24392, 0.5 task/s, elapsed: 11s, ETA: 46538s[                              ] 7/24392, 0.6 task/s, elapsed: 11s, ETA: 39888s[                              ] 8/24392, 0.7 task/s, elapsed: 11s, ETA: 34901sTraceback (most recent call last):
  File "./tools/train.py", line 188, in <module>
    main()
  File "./tools/train.py", line 184, in main
    meta=meta)
  File "/datadisk/lixinhao/vss/mmseg/apis/train.py", line 116, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 190, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 125, in train
    self.call_hook('after_train_iter')
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/base_runner.py", line 307, in call_hook
    getattr(hook, fn_name)(self)
  File "/datadisk/lixinhao/vss/mmseg/core/evaluation/eval_hooks.py", line 89, in after_train_iter
    gpu_collect=self.gpu_collect)
  File "/datadisk/lixinhao/vss/mmseg/apis/test.py", line 145, in multi_gpu_test
    result = model(memory,return_loss=False, rescale=True, **data)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 84, in new_func
    return old_func(*args, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 127, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 109, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 591, in simple_test
    seg_logit = self.inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 557, in inference
    seg_logit = self.whole_inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 522, in whole_inference
    seg_logit = self.encode_decode(img, img_meta, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 373, in encode_decode
    out = self._decode_head_forward_test(x, img_metas, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 396, in _decode_head_forward_test
    seg_logits = self.decode_head.forward_test(x, img_metas, self.test_cfg, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/decode_head.py", line 454, in forward_test
    return self.forward(inputs, batch_size, num_clips,memory)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/segformer_interval.py", line 126, in forward
    memoryFeature = self.memory(mode ='update_memory',feats=inputs[-1][int((i/num_infer-1)*num_infer):int((i/num_infer)*num_infer),:])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 109, in forward
    return self.update_memory(feats)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 75, in update_memory
    feats = feats.reshape(B,cx,hx*wx).permute(0,2,1)
RuntimeError: shape '[1, 512, 405]' is invalid for input of size 8192
[                              ] 9/24392, 0.7 task/s, elapsed: 12s, ETA: 32734s[                             ] 10/24392, 0.8 task/s, elapsed: 12s, ETA: 29459s[                             ] 11/24392, 0.9 task/s, elapsed: 12s, ETA: 26780s[                             ] 12/24392, 1.0 task/s, elapsed: 12s, ETA: 24548sTraceback (most recent call last):
  File "./tools/train.py", line 188, in <module>
    main()
  File "./tools/train.py", line 184, in main
    meta=meta)
  File "/datadisk/lixinhao/vss/mmseg/apis/train.py", line 116, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 190, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py", line 125, in train
    self.call_hook('after_train_iter')
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/base_runner.py", line 307, in call_hook
    getattr(hook, fn_name)(self)
  File "/datadisk/lixinhao/vss/mmseg/core/evaluation/eval_hooks.py", line 89, in after_train_iter
    gpu_collect=self.gpu_collect)
  File "/datadisk/lixinhao/vss/mmseg/apis/test.py", line 145, in multi_gpu_test
    result = model(memory,return_loss=False, rescale=True, **data)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 84, in new_func
    return old_func(*args, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 127, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/base.py", line 109, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 591, in simple_test
    seg_logit = self.inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 557, in inference
    seg_logit = self.whole_inference(img, img_meta, rescale, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 522, in whole_inference
    seg_logit = self.encode_decode(img, img_meta, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 373, in encode_decode
    out = self._decode_head_forward_test(x, img_metas, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/segmentors/encoder_decoder.py", line 396, in _decode_head_forward_test
    seg_logits = self.decode_head.forward_test(x, img_metas, self.test_cfg, batch_size, num_clips)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/decode_head.py", line 454, in forward_test
    return self.forward(inputs, batch_size, num_clips,memory)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/segformer_interval.py", line 126, in forward
    memoryFeature = self.memory(mode ='update_memory',feats=inputs[-1][int((i/num_infer-1)*num_infer):int((i/num_infer)*num_infer),:])
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 109, in forward
    return self.update_memory(feats)
  File "/datadisk/lixinhao/vss/mmseg/models/decode_heads/memory.py", line 75, in update_memory
    feats = feats.reshape(B,cx,hx*wx).permute(0,2,1)
RuntimeError: shape '[1, 512, 405]' is invalid for input of size 8192
Traceback (most recent call last):
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/lixinhao/anaconda3/envs/vss/lib/python3.7/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/lixinhao/anaconda3/envs/vss/bin/python', '-u', './tools/train.py', '--local_rank=3', 'local_configs/mrcfa/B2/mrcfa.b2.480x480.vspw2_hypercorr.160k.py', '--launcher', 'pytorch', '--work-dir', 'model_path/vspw2/work_dirs_4g_b8_2/', '--resume-from', 'model_path/vspw2/work_dirs_4g_b9/latest.pth']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
